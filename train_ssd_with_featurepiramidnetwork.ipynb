{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from utils.ssd import make_vgg, make_extras, L2Norm, make_loc_conf, DBox\n",
    "\n",
    "# import stuff\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from itertools import product as product\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "N = range(10)\n",
    "Z = range(10,20)\n",
    "for i,ii in zip(reversed(Z), reversed(N)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FPN(sources, fpnconv):\n",
    "    mode = \"nearest\"\n",
    "    # make layers\n",
    "    sources[5] = fpnconv[0](sources[5])\n",
    "    x = nn.functional.interpolate(sources[5], size=[3,3], mode=mode)\n",
    "    \n",
    "    sources[4] = fpnconv[1](sources[4]) + x\n",
    "    x = nn.functional.interpolate(sources[4], size=[5,5], mode=mode)\n",
    "    \n",
    "    sources[3] = fpnconv[2](sources[3]) + x\n",
    "    x = nn.functional.interpolate(sources[3], size=[10,10], mode=mode)\n",
    "    \n",
    "    sources[2] = fpnconv[3](sources[2]) + x\n",
    "    x = nn.functional.interpolate(sources[2], size=[19,19], mode=mode)\n",
    "    \n",
    "    sources[1] = fpnconv[4](sources[1]) + x\n",
    "    x = nn.functional.interpolate(sources[1], size=[38,38], mode=mode)\n",
    "    \n",
    "    sources[0] = fpnconv[5](sources[0]) + x\n",
    "    \n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loc_conf(num_classes=21, bbox_aspect_num=[4, 6, 6, 6, 4, 4]):\n",
    "\n",
    "    loc_layers = []\n",
    "    conf_layers = []\n",
    "\n",
    "    # VGGの22層目、conv4_3（source1）に対する畳み込み層\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[0]\n",
    "                             * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[0]\n",
    "                              * num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    # VGGの最終層（source2）に対する畳み込み層\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[1]\n",
    "                             * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[1]\n",
    "                              * num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    # extraの（source3）に対する畳み込み層\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[2]\n",
    "                             * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[2]\n",
    "                              * num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    # extraの（source4）に対する畳み込み層\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[3]\n",
    "                             * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[3]\n",
    "                              * num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    # extraの（source5）に対する畳み込み層\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[4]\n",
    "                             * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[4]\n",
    "                              * num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    # extraの（source6）に対する畳み込み層\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[5]\n",
    "                             * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[5]\n",
    "                              * num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    return nn.ModuleList(loc_layers), nn.ModuleList(conf_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPNSSD(nn.Module):\n",
    "    def __init__(self, phase, cfg):\n",
    "        super(FPNSSD, self).__init__()\n",
    "        \n",
    "        self.phase = phase\n",
    "        self.num_classes = cfg[\"num_classes\"]\n",
    "        \n",
    "        # call SSD network\n",
    "        self.vgg = make_vgg()\n",
    "        self.extras = make_extras()\n",
    "        self.L2Norm = L2Norm()\n",
    "        self.loc, self.conf = make_loc_conf(self.num_classes, cfg[\"bbox_aspect_num\"])\n",
    "        \n",
    "        #self.FPN = FPN()\n",
    "        \n",
    "        mode = \"nearest\"\n",
    "        self.upsamplers = [\n",
    "            [38,38], [19,19], [10,10], [5,5], [3,3]\n",
    "            ]\n",
    "        \n",
    "        self.fpnconv = nn.ModuleList([\n",
    "            nn.Conv2d(256, 256, kernel_size=1),\n",
    "            nn.Conv2d(256, 256, kernel_size=1),\n",
    "            nn.Conv2d(256, 256, kernel_size=1),\n",
    "            nn.Conv2d(512, 256, kernel_size=1),\n",
    "            nn.Conv2d(1024, 256, kernel_size=1),\n",
    "            nn.Conv2d(512, 256, kernel_size=1),\n",
    "        ])\n",
    "        \n",
    "        # make Dbox\n",
    "        dbox = DBox(cfg)\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dbox_list = dbox.make_dbox_list()\n",
    "        \n",
    "        # use Detect if inference\n",
    "        if phase == \"inference\":\n",
    "            self.detect = Detect()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        sources = list()\n",
    "        loc = list()\n",
    "        conf = list()\n",
    "        \n",
    "        # VGGのconv4_3まで計算\n",
    "        for k in range(23):\n",
    "            x = self.vgg[k](x)\n",
    "        \n",
    "        # conv4_3の出力をL2Normに入力。source1をsourceに追加\n",
    "        source1 = self.L2Norm(x)\n",
    "        sources.append(source1)\n",
    "        \n",
    "        # VGGを最後まで計算しsource2を取得\n",
    "        for k in range(23, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "        \n",
    "        sources.append(x)\n",
    "        \n",
    "        # extra層の計算を行う。\n",
    "        # source3-6に結果を格納。\n",
    "        for k, v in enumerate(self.extras):\n",
    "            x = F.relu(v(x), inplace = True)\n",
    "            if k % 2 == 1:\n",
    "                sources.append(x)\n",
    "        \n",
    "        # source1 38x38\n",
    "        # source2 19x19\n",
    "        # source3 10x10\n",
    "        # source4 5x5\n",
    "        # source5 3x3\n",
    "        # source6 1x1\n",
    "        \n",
    "        ## feature piramidレイヤを作成する。\n",
    "        sources = FPN(sources, self.fpnconv)\n",
    "        \n",
    "        # source 1-6にそれぞれ対応するconvを適応しconfとlocを得る。\n",
    "        for (x, l, c) in zip(sources, self.loc, self.conf):\n",
    "            # Permuteは要素の順番を入れ替え\n",
    "            loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "        \n",
    "        # convの出力は[batch, 4*anker, fh, fw]なので整形しなければならない。\n",
    "        # まず[batch, fh, fw, anker]に整形\n",
    "        \n",
    "        # locとconfの形を変形\n",
    "        # locのサイズは、torch.Size([batch_num, 34928])\n",
    "        # confのサイズはtorch.Size([batch_num, 183372])になる\n",
    "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)\n",
    "        conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)\n",
    "        \n",
    "        # さらにlocとconfの形を整える\n",
    "        # locのサイズは、torch.Size([batch_num, 8732, 4])\n",
    "        # confのサイズは、torch.Size([batch_num, 8732, 21])\n",
    "        loc = loc.view(loc.size(0), -1, 4)\n",
    "        conf = conf.view(conf.size(0), -1, self.num_classes)\n",
    "        # これで後段の処理につっこめるかたちになる。\n",
    "        \n",
    "        output = (loc, conf, self.dbox_list)\n",
    "        \n",
    "        if self.phase == \"inference\":\n",
    "            # Detectのforward\n",
    "            return self.detect(output[0], output[1], output[2].to(self.device))\n",
    "        else:\n",
    "            return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSD300の設定\n",
    "ssd_cfg = {\n",
    "    'num_classes': 21,  # 背景クラスを含めた合計クラス数\n",
    "    'input_size': 300,  # 画像の入力サイズ\n",
    "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 出力するDBoxのアスペクト比の種類\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],  # 各sourceの画像サイズ\n",
    "    'steps': [8, 16, 32, 64, 100, 300],  # DBOXの大きさを決める\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],  # DBOXの大きさを決める\n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315],  # DBOXの大きさを決める\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "}\n",
    "\n",
    "net = FPNSSD(phase=\"train\", cfg=ssd_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPNSSD(\n",
      "  (vgg): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "    (32): ReLU(inplace)\n",
      "    (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (34): ReLU(inplace)\n",
      "  )\n",
      "  (extras): ModuleList(\n",
      "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (L2Norm): L2Norm()\n",
      "  (loc): ModuleList(\n",
      "    (0): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conf): ModuleList(\n",
      "    (0): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (fpnconv): ModuleList(\n",
      "    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using vgg weights\n",
      "using: cuda:0\n",
      "set weights!\n"
     ]
    }
   ],
   "source": [
    "# SSDのweightsを設定\n",
    "print(\"using vgg weights\")\n",
    "vgg_weights = torch.load(\"./weights/vgg16_reducedfc.pth\")\n",
    "net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "import torch.nn.init as init\n",
    "\n",
    "# 初期値を適応\n",
    "net.extras.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)\n",
    "\n",
    "# GPUが使えるか確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using:\", device)\n",
    "\n",
    "print(\"set weights!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.focalloss import FocalLoss\n",
    "from utils.ssd_model import match\n",
    "from utils.ssd_model import MultiBoxLoss\n",
    "\n",
    "# define loss\n",
    "criterion = MultiBoxLoss(jaccard_thresh=0.5,neg_pos=3, device=device)\n",
    "\n",
    "# optim\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_lr(epoch):\n",
    "    lr = 1e-3\n",
    "    for i,lr_decay_epoch in enumerate([120,180]):\n",
    "        if epoch >= lr_decay_epoch:\n",
    "            lr *= 0.1\n",
    "    return lr\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = get_current_lr(epoch)\n",
    "    print(\"lr is:\", lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainlist:  16551\n",
      "vallist:  4952\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "from utils.dataset import VOCDataset, DatasetTransform, make_datapath_list, Anno_xml2list, od_collate_fn\n",
    "# load files\n",
    "# set your VOCdevkit path!\n",
    "vocpath = \"../VOCdevkit/VOC2007\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(vocpath)\n",
    "\n",
    "vocpath = \"../VOCdevkit/VOC2012\"\n",
    "train_img_list2, train_anno_list2, _, _ = make_datapath_list(vocpath)\n",
    "\n",
    "train_img_list.extend(train_img_list2)\n",
    "train_anno_list.extend(train_anno_list2)\n",
    "\n",
    "print(\"trainlist: \", len(train_img_list))\n",
    "print(\"vallist: \", len(val_img_list))\n",
    "\n",
    "# make Dataset\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "color_mean = (104, 117, 123)  # (BGR)の色の平均値\n",
    "input_size = 300  # 画像のinputサイズを300×300にする\n",
    "\n",
    "## DatasetTransformを適応\n",
    "transform = DatasetTransform(input_size, color_mean)\n",
    "transform_anno = Anno_xml2list(voc_classes)\n",
    "\n",
    "# Dataloaderに入れるデータセットファイル。\n",
    "# ゲットで叩くと画像とGTを前処理して出力してくれる。\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase = \"train\", transform=transform, transform_anno = transform_anno)\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DatasetTransform(\n",
    "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn, num_workers=8)\n",
    "\n",
    "val_dataloader = data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=od_collate_fn, num_workers=8)\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, epoch):\n",
    "    filename = 'weights/ssd_fpn_300_'+str(epoch+1)+'.pth'\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"used device：\", device)\n",
    "\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0  # epochの損失和\n",
    "    epoch_val_loss = 0.0  # epochの損失和\n",
    "    logs = []\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs+1):\n",
    "        \n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "        \n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "                print('（train）')\n",
    "            else:\n",
    "                if((epoch+1) % 10 == 0):\n",
    "                    net.eval()   # モデルを検証モードに\n",
    "                    print('-------------')\n",
    "                    print('（val）')\n",
    "                else:\n",
    "                    # 検証は10回に1回だけ行う\n",
    "                    continue\n",
    "\n",
    "            # データローダーからminibatchずつ取り出すループ\n",
    "            for images, targets in dataloaders_dict[phase]:\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                images = images.to(device)\n",
    "                targets = [ann.to(device)\n",
    "                           for ann in targets]  # リストの各要素のテンソルをGPUへ\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # 順伝搬（forward）計算\n",
    "                    outputs = net(images)\n",
    "\n",
    "                    # 損失の計算\n",
    "                    loc_data, conf_data, dbox_list = outputs\n",
    "                    # 要素数を把握\n",
    "                    num_batch = loc_data.size(0)  # ミニバッチのサイズ\n",
    "                    num_dbox = loc_data.size(1)  # DBoxの数 = 8732\n",
    "                    num_classes = conf_data.size(2)  # クラス数 = 21\n",
    "                    # get target\n",
    "                    conf_t_label = torch.LongTensor(num_batch, num_dbox).to(device)\n",
    "                    loc_t = torch.Tensor(num_batch, num_dbox, 4).to(device)                    \n",
    "                    for idx in range(num_batch):  # ミニバッチでループ\n",
    "                        # 現在のミニバッチの正解アノテーションのBBoxとラベルを取得\n",
    "                        truths = targets[idx][:, :-1].to(device)  # BBox\n",
    "                        # ラベル [物体1のラベル, 物体2のラベル, …]\n",
    "                        labels = targets[idx][:, -1].to(device)\n",
    "\n",
    "                        # デフォルトボックスを新たな変数で用意\n",
    "                        dbox = dbox_list.to(device)\n",
    "\n",
    "                        # 関数matchを実行し、loc_tとconf_t_labelの内容を更新する\n",
    "                        # （詳細）\n",
    "                        # loc_t:各DBoxに一番近い正解のBBoxの位置情報が上書きされる\n",
    "                        # conf_t_label：各DBoxに一番近いBBoxのラベルが上書きされる\n",
    "                        # ただし、一番近いBBoxとのjaccard overlapが0.5より小さい場合は\n",
    "                        # 正解BBoxのラベルconf_t_labelは背景クラスの0とする\n",
    "                        variance = [0.1, 0.2]\n",
    "                        # このvarianceはDBoxからBBoxに補正計算する際に使用する式の係数です\n",
    "                        match(0.5, truths, dbox,\n",
    "                              variance, labels, loc_t, conf_t_label, idx)\n",
    "                    \n",
    "                    # compute focal loss\n",
    "                    #loss_l, loss_c = criterion(loc_data, loc_t, conf_data, conf_t_label)\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()  # 勾配の計算\n",
    "\n",
    "                        # 勾配が大きくなりすぎると計算が不安定になるので、clipで最大でも勾配2.0に留める\n",
    "                        nn.utils.clip_grad_value_(\n",
    "                            net.parameters(), clip_value=2.0)\n",
    "\n",
    "                        optimizer.step()  # パラメータ更新\n",
    "\n",
    "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
    "                                iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "\n",
    "                    # 検証時\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item()\n",
    "\n",
    "        # epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
    "            epoch+1, epoch_train_loss, epoch_val_loss))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        # ログを保存\n",
    "        log_epoch = {'epoch': epoch+1,\n",
    "                     'train_loss': epoch_train_loss, 'val_loss': epoch_val_loss}\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"log_output.csv\")\n",
    "\n",
    "        epoch_train_loss = 0.0  # epochの損失和\n",
    "        epoch_val_loss = 0.0  # epochの損失和\n",
    "\n",
    "        # ネットワークを保存する\n",
    "        if ((epoch+1) % 10 == 0):\n",
    "            save_checkpoint({\n",
    "            'epoch': epoch +1,\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, epoch)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used device： cuda:0\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 1/200\n",
      "-------------\n",
      "（train）\n",
      "イテレーション 10 || Loss: 3.9452 || 10iter: 7.1056 sec.\n",
      "イテレーション 20 || Loss: 4.0003 || 10iter: 5.5501 sec.\n",
      "イテレーション 30 || Loss: 3.3053 || 10iter: 5.6181 sec.\n",
      "イテレーション 40 || Loss: 3.7027 || 10iter: 5.6020 sec.\n",
      "イテレーション 50 || Loss: 4.1493 || 10iter: 5.6336 sec.\n",
      "イテレーション 60 || Loss: 3.9259 || 10iter: 5.7089 sec.\n",
      "イテレーション 70 || Loss: 4.0375 || 10iter: 5.5935 sec.\n",
      "イテレーション 80 || Loss: 3.9287 || 10iter: 5.6231 sec.\n",
      "イテレーション 90 || Loss: 4.8472 || 10iter: 5.6302 sec.\n",
      "イテレーション 100 || Loss: 4.1358 || 10iter: 5.5893 sec.\n",
      "イテレーション 110 || Loss: 3.8377 || 10iter: 5.6391 sec.\n",
      "イテレーション 120 || Loss: 3.8065 || 10iter: 5.6155 sec.\n",
      "イテレーション 130 || Loss: 4.3254 || 10iter: 5.6417 sec.\n",
      "イテレーション 140 || Loss: 4.1040 || 10iter: 5.6162 sec.\n",
      "イテレーション 150 || Loss: 4.2332 || 10iter: 5.6097 sec.\n",
      "イテレーション 160 || Loss: 4.0288 || 10iter: 5.6263 sec.\n",
      "イテレーション 170 || Loss: 3.9026 || 10iter: 5.6099 sec.\n",
      "イテレーション 180 || Loss: 4.2253 || 10iter: 5.5858 sec.\n",
      "イテレーション 190 || Loss: 4.1644 || 10iter: 5.6004 sec.\n",
      "イテレーション 200 || Loss: 4.2046 || 10iter: 5.5652 sec.\n",
      "イテレーション 210 || Loss: 4.2118 || 10iter: 5.5963 sec.\n",
      "イテレーション 220 || Loss: 4.3700 || 10iter: 5.5848 sec.\n",
      "イテレーション 230 || Loss: 3.8415 || 10iter: 5.5754 sec.\n",
      "イテレーション 240 || Loss: 3.7480 || 10iter: 5.6028 sec.\n",
      "イテレーション 250 || Loss: 3.8642 || 10iter: 5.6226 sec.\n",
      "イテレーション 260 || Loss: 4.0263 || 10iter: 5.6305 sec.\n",
      "イテレーション 270 || Loss: 4.1664 || 10iter: 5.6216 sec.\n",
      "イテレーション 280 || Loss: 3.5165 || 10iter: 5.6807 sec.\n",
      "イテレーション 290 || Loss: 4.0905 || 10iter: 5.6104 sec.\n",
      "イテレーション 300 || Loss: 3.6741 || 10iter: 5.6054 sec.\n",
      "イテレーション 310 || Loss: 4.3650 || 10iter: 5.6248 sec.\n",
      "イテレーション 320 || Loss: 3.7171 || 10iter: 5.6434 sec.\n",
      "イテレーション 330 || Loss: 4.4036 || 10iter: 5.6603 sec.\n",
      "イテレーション 340 || Loss: 3.5666 || 10iter: 5.6626 sec.\n",
      "イテレーション 350 || Loss: 4.1174 || 10iter: 5.6148 sec.\n",
      "イテレーション 360 || Loss: 3.6235 || 10iter: 5.5865 sec.\n",
      "イテレーション 370 || Loss: 4.1474 || 10iter: 5.6762 sec.\n",
      "イテレーション 380 || Loss: 4.4673 || 10iter: 5.6758 sec.\n",
      "イテレーション 390 || Loss: 4.0756 || 10iter: 5.6286 sec.\n",
      "イテレーション 400 || Loss: 3.9008 || 10iter: 5.6324 sec.\n",
      "イテレーション 410 || Loss: 3.9875 || 10iter: 5.6741 sec.\n",
      "イテレーション 420 || Loss: 3.8791 || 10iter: 5.6195 sec.\n",
      "イテレーション 430 || Loss: 3.6402 || 10iter: 5.6268 sec.\n",
      "イテレーション 440 || Loss: 3.5965 || 10iter: 5.6539 sec.\n",
      "イテレーション 450 || Loss: 3.9114 || 10iter: 5.6277 sec.\n",
      "イテレーション 460 || Loss: 4.1229 || 10iter: 5.6099 sec.\n",
      "イテレーション 470 || Loss: 3.8339 || 10iter: 5.6094 sec.\n",
      "イテレーション 480 || Loss: 4.1342 || 10iter: 5.6543 sec.\n",
      "イテレーション 490 || Loss: 3.5568 || 10iter: 5.6373 sec.\n",
      "イテレーション 500 || Loss: 4.2406 || 10iter: 5.7470 sec.\n",
      "イテレーション 510 || Loss: 4.4740 || 10iter: 5.6334 sec.\n",
      "-------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:2051.3506 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  306.4685 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 2/200\n",
      "-------------\n",
      "（train）\n",
      "イテレーション 520 || Loss: 3.8797 || 10iter: 2.6274 sec.\n",
      "イテレーション 530 || Loss: 4.4049 || 10iter: 5.5824 sec.\n",
      "イテレーション 540 || Loss: 4.1195 || 10iter: 5.5617 sec.\n",
      "イテレーション 550 || Loss: 3.8690 || 10iter: 5.6396 sec.\n",
      "イテレーション 560 || Loss: 3.8485 || 10iter: 5.7087 sec.\n",
      "イテレーション 570 || Loss: 3.7000 || 10iter: 5.6405 sec.\n",
      "イテレーション 580 || Loss: 4.7905 || 10iter: 5.6229 sec.\n",
      "イテレーション 590 || Loss: 3.8534 || 10iter: 5.6152 sec.\n",
      "イテレーション 600 || Loss: 3.7955 || 10iter: 5.6224 sec.\n",
      "イテレーション 610 || Loss: 3.6715 || 10iter: 5.5967 sec.\n",
      "イテレーション 620 || Loss: 3.3838 || 10iter: 5.6357 sec.\n",
      "イテレーション 630 || Loss: 4.1843 || 10iter: 5.6295 sec.\n",
      "イテレーション 640 || Loss: 4.3294 || 10iter: 5.6172 sec.\n",
      "イテレーション 650 || Loss: 3.8299 || 10iter: 5.6251 sec.\n",
      "イテレーション 660 || Loss: 3.8027 || 10iter: 5.6654 sec.\n",
      "イテレーション 670 || Loss: 3.4524 || 10iter: 5.6073 sec.\n",
      "イテレーション 680 || Loss: 3.9107 || 10iter: 5.6270 sec.\n",
      "イテレーション 690 || Loss: 3.5244 || 10iter: 5.6301 sec.\n",
      "イテレーション 700 || Loss: 3.6119 || 10iter: 5.5997 sec.\n",
      "イテレーション 710 || Loss: 3.8770 || 10iter: 5.6390 sec.\n",
      "イテレーション 720 || Loss: 4.0650 || 10iter: 5.6231 sec.\n",
      "イテレーション 730 || Loss: 3.5758 || 10iter: 5.5986 sec.\n",
      "イテレーション 740 || Loss: 3.6687 || 10iter: 5.6065 sec.\n",
      "イテレーション 750 || Loss: 3.7224 || 10iter: 5.6575 sec.\n",
      "イテレーション 760 || Loss: 3.7300 || 10iter: 5.6476 sec.\n",
      "イテレーション 770 || Loss: 3.6070 || 10iter: 5.6249 sec.\n",
      "イテレーション 780 || Loss: 3.9918 || 10iter: 5.6848 sec.\n",
      "イテレーション 790 || Loss: 4.0595 || 10iter: 5.6137 sec.\n",
      "イテレーション 800 || Loss: 4.0522 || 10iter: 5.6435 sec.\n",
      "イテレーション 810 || Loss: 3.7280 || 10iter: 5.5953 sec.\n",
      "イテレーション 820 || Loss: 3.7951 || 10iter: 5.6105 sec.\n",
      "イテレーション 830 || Loss: 4.0009 || 10iter: 5.6144 sec.\n",
      "イテレーション 840 || Loss: 4.1880 || 10iter: 5.6291 sec.\n",
      "イテレーション 850 || Loss: 4.1592 || 10iter: 5.6288 sec.\n",
      "イテレーション 860 || Loss: 3.4583 || 10iter: 5.6756 sec.\n",
      "イテレーション 870 || Loss: 3.7403 || 10iter: 5.6255 sec.\n",
      "イテレーション 880 || Loss: 3.8220 || 10iter: 5.6471 sec.\n",
      "イテレーション 890 || Loss: 3.8263 || 10iter: 5.7077 sec.\n",
      "イテレーション 900 || Loss: 3.7871 || 10iter: 5.6442 sec.\n",
      "イテレーション 910 || Loss: 4.4220 || 10iter: 5.5931 sec.\n",
      "イテレーション 920 || Loss: 4.0179 || 10iter: 5.6887 sec.\n",
      "イテレーション 930 || Loss: 4.1010 || 10iter: 5.6429 sec.\n",
      "イテレーション 940 || Loss: 3.7307 || 10iter: 5.6747 sec.\n",
      "イテレーション 950 || Loss: 4.1748 || 10iter: 5.6448 sec.\n",
      "イテレーション 960 || Loss: 3.4397 || 10iter: 5.6282 sec.\n",
      "イテレーション 970 || Loss: 4.2856 || 10iter: 5.6197 sec.\n",
      "イテレーション 980 || Loss: 4.1850 || 10iter: 5.7332 sec.\n",
      "イテレーション 990 || Loss: 4.1541 || 10iter: 5.6671 sec.\n",
      "イテレーション 1000 || Loss: 3.6516 || 10iter: 5.6196 sec.\n",
      "イテレーション 1010 || Loss: 3.4958 || 10iter: 5.6618 sec.\n",
      "イテレーション 1020 || Loss: 4.0135 || 10iter: 5.6527 sec.\n",
      "イテレーション 1030 || Loss: 3.3910 || 10iter: 5.5966 sec.\n",
      "-------------\n",
      "epoch 2 || Epoch_TRAIN_Loss:2009.2067 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  307.0664 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 3/200\n",
      "-------------\n",
      "（train）\n",
      "イテレーション 1040 || Loss: 3.9306 || 10iter: 3.9237 sec.\n",
      "イテレーション 1050 || Loss: 4.0715 || 10iter: 5.5654 sec.\n",
      "イテレーション 1060 || Loss: 4.1700 || 10iter: 5.6223 sec.\n",
      "イテレーション 1070 || Loss: 3.7629 || 10iter: 5.7040 sec.\n",
      "イテレーション 1080 || Loss: 3.3950 || 10iter: 5.6669 sec.\n",
      "イテレーション 1090 || Loss: 3.8219 || 10iter: 5.0778 sec.\n",
      "イテレーション 1100 || Loss: 3.7196 || 10iter: 4.6259 sec.\n",
      "イテレーション 1110 || Loss: 4.0870 || 10iter: 4.6165 sec.\n",
      "イテレーション 1120 || Loss: 3.6984 || 10iter: 4.5954 sec.\n",
      "イテレーション 1130 || Loss: 4.3963 || 10iter: 4.6110 sec.\n",
      "イテレーション 1140 || Loss: 3.9604 || 10iter: 4.5164 sec.\n",
      "イテレーション 1150 || Loss: 3.6070 || 10iter: 4.5127 sec.\n",
      "イテレーション 1160 || Loss: 3.8553 || 10iter: 4.5188 sec.\n",
      "イテレーション 1170 || Loss: 3.4951 || 10iter: 4.5302 sec.\n",
      "イテレーション 1180 || Loss: 3.9635 || 10iter: 4.5641 sec.\n",
      "イテレーション 1190 || Loss: 4.0926 || 10iter: 4.5297 sec.\n",
      "イテレーション 1200 || Loss: 3.5066 || 10iter: 4.5020 sec.\n",
      "イテレーション 1210 || Loss: 4.0203 || 10iter: 4.5263 sec.\n",
      "イテレーション 1220 || Loss: 4.1415 || 10iter: 4.5046 sec.\n",
      "イテレーション 1230 || Loss: 3.9155 || 10iter: 4.5119 sec.\n",
      "イテレーション 1240 || Loss: 3.8683 || 10iter: 4.4998 sec.\n",
      "イテレーション 1250 || Loss: 4.0159 || 10iter: 4.5016 sec.\n",
      "イテレーション 1260 || Loss: 4.0684 || 10iter: 4.5421 sec.\n",
      "イテレーション 1270 || Loss: 3.8447 || 10iter: 4.5399 sec.\n",
      "イテレーション 1280 || Loss: 4.1847 || 10iter: 4.4820 sec.\n",
      "イテレーション 1290 || Loss: 3.4683 || 10iter: 4.5119 sec.\n",
      "イテレーション 1300 || Loss: 3.9147 || 10iter: 4.5033 sec.\n",
      "イテレーション 1310 || Loss: 4.2213 || 10iter: 4.5114 sec.\n",
      "イテレーション 1320 || Loss: 4.0986 || 10iter: 4.5223 sec.\n",
      "イテレーション 1330 || Loss: 3.8804 || 10iter: 4.5623 sec.\n",
      "イテレーション 1340 || Loss: 3.9692 || 10iter: 4.4857 sec.\n",
      "イテレーション 1350 || Loss: 3.8204 || 10iter: 4.4888 sec.\n",
      "イテレーション 1360 || Loss: 3.8735 || 10iter: 4.5025 sec.\n",
      "イテレーション 1370 || Loss: 3.8690 || 10iter: 4.5314 sec.\n",
      "イテレーション 1380 || Loss: 4.1777 || 10iter: 4.6691 sec.\n",
      "イテレーション 1390 || Loss: 3.7924 || 10iter: 4.4920 sec.\n",
      "イテレーション 1400 || Loss: 4.1042 || 10iter: 4.5826 sec.\n",
      "イテレーション 1410 || Loss: 3.4886 || 10iter: 4.6253 sec.\n",
      "イテレーション 1420 || Loss: 3.6193 || 10iter: 4.5256 sec.\n",
      "イテレーション 1430 || Loss: 3.8302 || 10iter: 4.5241 sec.\n",
      "イテレーション 1440 || Loss: 3.4319 || 10iter: 4.4867 sec.\n",
      "イテレーション 1450 || Loss: 3.4790 || 10iter: 4.6008 sec.\n",
      "イテレーション 1460 || Loss: 4.4289 || 10iter: 4.5843 sec.\n",
      "イテレーション 1470 || Loss: 4.2471 || 10iter: 4.5809 sec.\n",
      "イテレーション 1480 || Loss: 3.6537 || 10iter: 4.5029 sec.\n",
      "イテレーション 1490 || Loss: 3.8097 || 10iter: 4.5163 sec.\n",
      "イテレーション 1500 || Loss: 4.0618 || 10iter: 4.5752 sec.\n",
      "イテレーション 1510 || Loss: 4.1038 || 10iter: 4.5124 sec.\n",
      "イテレーション 1520 || Loss: 4.0611 || 10iter: 4.6346 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "イテレーション 1530 || Loss: 4.3608 || 10iter: 4.5054 sec.\n",
      "イテレーション 1540 || Loss: 3.4786 || 10iter: 4.5117 sec.\n",
      "イテレーション 1550 || Loss: 4.2487 || 10iter: 4.4609 sec.\n",
      "-------------\n",
      "epoch 3 || Epoch_TRAIN_Loss:1973.5958 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  253.4304 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 4/200\n",
      "-------------\n",
      "（train）\n",
      "イテレーション 1560 || Loss: 3.8075 || 10iter: 4.0654 sec.\n",
      "イテレーション 1570 || Loss: 4.4827 || 10iter: 4.5052 sec.\n",
      "イテレーション 1580 || Loss: 3.4280 || 10iter: 4.5915 sec.\n",
      "イテレーション 1590 || Loss: 3.7224 || 10iter: 4.5320 sec.\n",
      "イテレーション 1600 || Loss: 3.8781 || 10iter: 4.5095 sec.\n",
      "イテレーション 1610 || Loss: 4.3110 || 10iter: 4.5112 sec.\n",
      "イテレーション 1620 || Loss: 3.5319 || 10iter: 4.5485 sec.\n",
      "イテレーション 1630 || Loss: 3.8772 || 10iter: 4.5120 sec.\n",
      "イテレーション 1640 || Loss: 3.5218 || 10iter: 4.5068 sec.\n",
      "イテレーション 1650 || Loss: 3.7584 || 10iter: 4.5127 sec.\n",
      "イテレーション 1660 || Loss: 4.3046 || 10iter: 4.5398 sec.\n",
      "イテレーション 1670 || Loss: 3.9909 || 10iter: 4.4924 sec.\n",
      "イテレーション 1680 || Loss: 3.6094 || 10iter: 4.5337 sec.\n",
      "イテレーション 1690 || Loss: 3.9011 || 10iter: 4.5065 sec.\n",
      "イテレーション 1700 || Loss: 3.4763 || 10iter: 4.5043 sec.\n",
      "イテレーション 1710 || Loss: 3.8912 || 10iter: 4.5535 sec.\n",
      "イテレーション 1720 || Loss: 4.0154 || 10iter: 4.5157 sec.\n",
      "イテレーション 1730 || Loss: 3.5676 || 10iter: 4.5296 sec.\n",
      "イテレーション 1740 || Loss: 3.4484 || 10iter: 4.5202 sec.\n",
      "イテレーション 1750 || Loss: 3.8340 || 10iter: 4.5581 sec.\n",
      "イテレーション 1760 || Loss: 3.8727 || 10iter: 4.6325 sec.\n",
      "イテレーション 1770 || Loss: 3.8477 || 10iter: 4.5819 sec.\n",
      "イテレーション 1780 || Loss: 3.3958 || 10iter: 4.5188 sec.\n",
      "イテレーション 1790 || Loss: 3.5549 || 10iter: 4.4950 sec.\n",
      "イテレーション 1800 || Loss: 3.5078 || 10iter: 4.5019 sec.\n",
      "イテレーション 1810 || Loss: 3.6507 || 10iter: 4.5259 sec.\n",
      "イテレーション 1820 || Loss: 3.4720 || 10iter: 4.5180 sec.\n",
      "イテレーション 1830 || Loss: 4.0783 || 10iter: 4.5243 sec.\n",
      "イテレーション 1840 || Loss: 3.8044 || 10iter: 4.5364 sec.\n",
      "イテレーション 1850 || Loss: 3.4951 || 10iter: 4.5776 sec.\n",
      "イテレーション 1860 || Loss: 3.8979 || 10iter: 4.4936 sec.\n",
      "イテレーション 1870 || Loss: 3.3773 || 10iter: 4.4897 sec.\n",
      "イテレーション 1880 || Loss: 3.6903 || 10iter: 4.5196 sec.\n",
      "イテレーション 1890 || Loss: 3.3675 || 10iter: 4.5338 sec.\n",
      "イテレーション 1900 || Loss: 3.4023 || 10iter: 4.5189 sec.\n",
      "イテレーション 1910 || Loss: 3.7040 || 10iter: 4.5337 sec.\n",
      "イテレーション 1920 || Loss: 3.8568 || 10iter: 4.5887 sec.\n",
      "イテレーション 1930 || Loss: 3.5156 || 10iter: 4.4910 sec.\n",
      "イテレーション 1940 || Loss: 3.8407 || 10iter: 4.5131 sec.\n",
      "イテレーション 1950 || Loss: 4.0583 || 10iter: 4.5102 sec.\n",
      "イテレーション 1960 || Loss: 3.6118 || 10iter: 4.5141 sec.\n",
      "イテレーション 1970 || Loss: 4.0188 || 10iter: 4.5662 sec.\n",
      "イテレーション 1980 || Loss: 3.7563 || 10iter: 4.5689 sec.\n",
      "イテレーション 1990 || Loss: 3.9717 || 10iter: 4.5238 sec.\n",
      "イテレーション 2000 || Loss: 4.0561 || 10iter: 4.5273 sec.\n",
      "イテレーション 2010 || Loss: 3.6030 || 10iter: 4.5345 sec.\n",
      "イテレーション 2020 || Loss: 3.3755 || 10iter: 4.5190 sec.\n",
      "イテレーション 2030 || Loss: 3.4834 || 10iter: 4.5676 sec.\n",
      "イテレーション 2040 || Loss: 3.8582 || 10iter: 4.5324 sec.\n",
      "イテレーション 2050 || Loss: 4.0757 || 10iter: 4.5183 sec.\n",
      "イテレーション 2060 || Loss: 3.1910 || 10iter: 4.5060 sec.\n",
      "イテレーション 2070 || Loss: 3.9186 || 10iter: 4.4805 sec.\n",
      "-------------\n",
      "epoch 4 || Epoch_TRAIN_Loss:1944.0382 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  246.9640 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 5/200\n",
      "-------------\n",
      "（train）\n",
      "イテレーション 2080 || Loss: 4.9572 || 10iter: 5.0675 sec.\n",
      "イテレーション 2090 || Loss: 3.9841 || 10iter: 4.5116 sec.\n",
      "イテレーション 2100 || Loss: 3.7981 || 10iter: 4.5935 sec.\n",
      "イテレーション 2110 || Loss: 3.3106 || 10iter: 4.5178 sec.\n",
      "イテレーション 2120 || Loss: 4.0460 || 10iter: 4.5227 sec.\n",
      "イテレーション 2130 || Loss: 3.8102 || 10iter: 4.5737 sec.\n",
      "イテレーション 2140 || Loss: 3.2505 || 10iter: 4.5121 sec.\n",
      "イテレーション 2150 || Loss: 3.9460 || 10iter: 4.5250 sec.\n",
      "イテレーション 2160 || Loss: 3.6114 || 10iter: 4.5363 sec.\n",
      "イテレーション 2170 || Loss: 3.9330 || 10iter: 4.5527 sec.\n",
      "イテレーション 2180 || Loss: 3.9213 || 10iter: 4.5372 sec.\n",
      "イテレーション 2190 || Loss: 3.4142 || 10iter: 4.5241 sec.\n",
      "イテレーション 2200 || Loss: 3.4491 || 10iter: 4.5830 sec.\n",
      "イテレーション 2210 || Loss: 3.9398 || 10iter: 4.4971 sec.\n",
      "イテレーション 2220 || Loss: 3.6601 || 10iter: 4.5332 sec.\n",
      "イテレーション 2230 || Loss: 3.9630 || 10iter: 4.5061 sec.\n",
      "イテレーション 2240 || Loss: 3.6477 || 10iter: 4.5041 sec.\n",
      "イテレーション 2250 || Loss: 3.5793 || 10iter: 4.5457 sec.\n",
      "イテレーション 2260 || Loss: 3.7297 || 10iter: 4.5174 sec.\n",
      "イテレーション 2270 || Loss: 2.9028 || 10iter: 4.4918 sec.\n",
      "イテレーション 2280 || Loss: 3.8309 || 10iter: 4.5362 sec.\n",
      "イテレーション 2290 || Loss: 3.9270 || 10iter: 4.5333 sec.\n",
      "イテレーション 2300 || Loss: 4.1746 || 10iter: 4.5109 sec.\n",
      "イテレーション 2310 || Loss: 3.7270 || 10iter: 4.5637 sec.\n",
      "イテレーション 2320 || Loss: 3.9342 || 10iter: 4.5632 sec.\n",
      "イテレーション 2330 || Loss: 3.8683 || 10iter: 4.5675 sec.\n",
      "イテレーション 2340 || Loss: 4.0133 || 10iter: 4.5964 sec.\n",
      "イテレーション 2350 || Loss: 3.3304 || 10iter: 4.7261 sec.\n",
      "イテレーション 2360 || Loss: 3.8532 || 10iter: 4.5475 sec.\n",
      "イテレーション 2370 || Loss: 3.4990 || 10iter: 4.5338 sec.\n",
      "イテレーション 2380 || Loss: 3.8507 || 10iter: 4.5005 sec.\n",
      "イテレーション 2390 || Loss: 3.4673 || 10iter: 4.5161 sec.\n",
      "イテレーション 2400 || Loss: 3.6734 || 10iter: 4.5592 sec.\n",
      "イテレーション 2410 || Loss: 3.8627 || 10iter: 4.5117 sec.\n",
      "イテレーション 2420 || Loss: 3.7737 || 10iter: 4.5181 sec.\n",
      "イテレーション 2430 || Loss: 3.9592 || 10iter: 4.5058 sec.\n",
      "イテレーション 2440 || Loss: 3.8939 || 10iter: 4.5477 sec.\n",
      "イテレーション 2450 || Loss: 3.3110 || 10iter: 4.5134 sec.\n",
      "イテレーション 2460 || Loss: 3.3034 || 10iter: 4.5242 sec.\n",
      "イテレーション 2470 || Loss: 3.6713 || 10iter: 4.5208 sec.\n",
      "イテレーション 2480 || Loss: 3.4969 || 10iter: 4.5293 sec.\n",
      "イテレーション 2490 || Loss: 3.9347 || 10iter: 4.5247 sec.\n",
      "イテレーション 2500 || Loss: 3.6565 || 10iter: 4.6105 sec.\n",
      "イテレーション 2510 || Loss: 3.2367 || 10iter: 4.5163 sec.\n",
      "イテレーション 2520 || Loss: 3.5876 || 10iter: 4.5009 sec.\n",
      "イテレーション 2530 || Loss: 3.3458 || 10iter: 4.5233 sec.\n",
      "イテレーション 2540 || Loss: 3.8101 || 10iter: 4.5076 sec.\n",
      "イテレーション 2550 || Loss: 3.8650 || 10iter: 4.5088 sec.\n",
      "イテレーション 2560 || Loss: 3.3582 || 10iter: 4.4984 sec.\n",
      "イテレーション 2570 || Loss: 3.7355 || 10iter: 4.5042 sec.\n",
      "イテレーション 2580 || Loss: 3.7448 || 10iter: 4.4991 sec.\n",
      "イテレーション 2590 || Loss: 3.7402 || 10iter: 4.3045 sec.\n",
      "-------------\n",
      "epoch 5 || Epoch_TRAIN_Loss:1922.6869 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  247.2376 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 6/200\n",
      "-------------\n",
      "（train）\n",
      "イテレーション 2600 || Loss: 3.6867 || 10iter: 6.1022 sec.\n",
      "イテレーション 2610 || Loss: 4.1573 || 10iter: 4.4523 sec.\n",
      "イテレーション 2620 || Loss: 3.7073 || 10iter: 4.5326 sec.\n",
      "イテレーション 2630 || Loss: 3.5004 || 10iter: 4.5073 sec.\n",
      "イテレーション 2640 || Loss: 3.2907 || 10iter: 4.5064 sec.\n",
      "イテレーション 2650 || Loss: 3.1599 || 10iter: 4.5616 sec.\n",
      "イテレーション 2660 || Loss: 3.5228 || 10iter: 4.5164 sec.\n",
      "イテレーション 2670 || Loss: 3.2657 || 10iter: 4.5692 sec.\n",
      "イテレーション 2680 || Loss: 3.4344 || 10iter: 4.4998 sec.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
