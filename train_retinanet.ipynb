{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stuff\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from itertools import product as product\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "from utils.dataset import VOCDataset, DatasetTransform, make_datapath_list, Anno_xml2list, od_collate_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make data.Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainlist:  16551\n",
      "vallist:  4952\n"
     ]
    }
   ],
   "source": [
    "# load files\n",
    "# set your VOCdevkit path!\n",
    "vocpath = \"../VOCdevkit/VOC2007\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(vocpath)\n",
    "\n",
    "vocpath = \"../VOCdevkit/VOC2012\"\n",
    "train_img_list2, train_anno_list2, _, _ = make_datapath_list(vocpath)\n",
    "\n",
    "train_img_list.extend(train_img_list2)\n",
    "train_anno_list.extend(train_anno_list2)\n",
    "\n",
    "print(\"trainlist: \", len(train_img_list))\n",
    "print(\"vallist: \", len(val_img_list))\n",
    "\n",
    "# make Dataset\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "color_mean = (104, 117, 123)  # (BGR)の色の平均値\n",
    "input_size = 300  # 画像のinputサイズを300×300にする\n",
    "\n",
    "## DatasetTransformを適応\n",
    "transform = DatasetTransform(input_size, color_mean)\n",
    "transform_anno = Anno_xml2list(voc_classes)\n",
    "\n",
    "# Dataloaderに入れるデータセットファイル。\n",
    "# ゲットで叩くと画像とGTを前処理して出力してくれる。\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase = \"train\", transform=transform, transform_anno = transform_anno)\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DatasetTransform(\n",
    "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "batch_size = 24\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn, num_workers=8)\n",
    "\n",
    "val_dataloader = data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=od_collate_fn, num_workers=8)\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 3, 300, 300])\n",
      "24\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "# 動作の確認\n",
    "batch_iterator = iter(dataloaders_dict[\"val\"])  # イタレータに変換\n",
    "images, targets = next(batch_iterator)  # 1番目の要素を取り出す\n",
    "print(images.size())  # torch.Size([4, 3, 300, 300])\n",
    "print(len(targets))\n",
    "print(targets[1].shape)  # ミニバッチのサイズのリスト、各要素は[n, 5]、nは物体数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define SSD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.retinanet import RetinaFPN as SSD\n",
    "from utils.retinanet import Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "using: cuda:0\n",
      "set weights!\n"
     ]
    }
   ],
   "source": [
    "# SSD300の設定\n",
    "ssd_cfg = {\n",
    "    'num_classes': 21,  # 背景クラスを含めた合計クラス数\n",
    "    'input_size': 300,  # 画像の入力サイズ\n",
    "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 出力するDBoxのアスペクト比の種類\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],  # 各sourceの画像サイズ\n",
    "    'steps': [8, 16, 32, 64, 100, 300],  # DBOXの大きさを決める\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],  # DBOXの大きさを決める\n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315],  # DBOXの大きさを決める\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "}\n",
    "\n",
    "net = SSD(Bottleneck, [2,2,2,2], phase=\"train\", cfg=ssd_cfg)\n",
    "\n",
    "# SSDのweightsを設定\n",
    "#print(\"using vgg weights\")\n",
    "#vgg_weights = torch.load(\"./weights/vgg16_reducedfc.pth\")\n",
    "#net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "            \n",
    "# 初期値を適応\n",
    "#net.toplayer.apply(weights_init)\n",
    "#net.smooth1.apply(weights_init)\n",
    "#net.smooth2.apply(weights_init)\n",
    "#net.latlayer1.apply(weights_init)\n",
    "#net.latlayer2.apply(weights_init)\n",
    "#net.conv6.apply(weights_init)\n",
    "#net.conv7.apply(weights_init)\n",
    "#net.conv8.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)\n",
    "\n",
    "# GPUが使えるか確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using:\", device)\n",
    "\n",
    "print(\"set weights!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RetinaFPN(\n",
      "  (layer0): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv6): Conv2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (toplayer): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (smooth1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (smooth2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (latlayer1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (latlayer2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (loc): ModuleList(\n",
      "    (0): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conf): ModuleList(\n",
      "    (0): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import MultiBoxLoss\n",
    "\n",
    "# define loss\n",
    "criterion = MultiBoxLoss(jaccard_thresh=0.5,neg_pos=3, device=device)\n",
    "\n",
    "# optim\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_lr(epoch):\n",
    "    lr = 1e-3\n",
    "    for i,lr_decay_epoch in enumerate([120,180]):\n",
    "        if epoch >= lr_decay_epoch:\n",
    "            lr *= 0.1\n",
    "    return lr\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = get_current_lr(epoch)\n",
    "    print(\"lr is:\", lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"used device:\", device)\n",
    "\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0  # epochの損失和\n",
    "    epoch_val_loss = 0.0  # epochの損失和\n",
    "    logs = []\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs+1):\n",
    "        \n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "        \n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "                print('(train)')\n",
    "            else:\n",
    "                if((epoch+1) % 10 == 0):\n",
    "                    net.eval()   # モデルを検証モードに\n",
    "                    print('-------------')\n",
    "                    print('(val)')\n",
    "                else:\n",
    "                    # 検証は10回に1回だけ行う\n",
    "                    continue\n",
    "\n",
    "            # データローダーからminibatchずつ取り出すループ\n",
    "            for images, targets in dataloaders_dict[phase]:\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                images = images.to(device)\n",
    "                targets = [ann.to(device)\n",
    "                           for ann in targets]  # リストの各要素のテンソルをGPUへ\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # 順伝搬（forward）計算\n",
    "                    outputs = net(images)\n",
    "\n",
    "                    # 損失の計算\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()  # 勾配の計算\n",
    "\n",
    "                        # 勾配が大きくなりすぎると計算が不安定になるので、clipで最大でも勾配2.0に留める\n",
    "                        nn.utils.clip_grad_value_(\n",
    "                            net.parameters(), clip_value=2.0)\n",
    "\n",
    "                        optimizer.step()  # パラメータ更新\n",
    "\n",
    "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('Iter {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
    "                                iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "\n",
    "                    # 検証時\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item()\n",
    "\n",
    "        # epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
    "            epoch+1, epoch_train_loss, epoch_val_loss))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        # ログを保存\n",
    "        log_epoch = {'epoch': epoch+1,\n",
    "                     'train_loss': epoch_train_loss, 'val_loss': epoch_val_loss}\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"log_output.csv\")\n",
    "\n",
    "        epoch_train_loss = 0.0  # epochの損失和\n",
    "        epoch_val_loss = 0.0  # epochの損失和\n",
    "\n",
    "        # ネットワークを保存する\n",
    "        if ((epoch+1) % 10 == 0):\n",
    "            torch.save(net.state_dict(), 'weights/retinanet300_' +\n",
    "                       str(epoch+1) + '.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used device: cuda:0\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 1/200\n",
      "-------------\n",
      "(train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10 || Loss: 15.1949 || 10iter: 3.6307 sec.\n",
      "Iter 20 || Loss: 10.6273 || 10iter: 1.3889 sec.\n",
      "Iter 30 || Loss: 9.0887 || 10iter: 1.4254 sec.\n",
      "Iter 40 || Loss: 8.8716 || 10iter: 1.3998 sec.\n",
      "Iter 50 || Loss: 8.0458 || 10iter: 1.4715 sec.\n",
      "Iter 60 || Loss: 8.0764 || 10iter: 1.4587 sec.\n",
      "Iter 70 || Loss: 7.6231 || 10iter: 1.3860 sec.\n",
      "Iter 80 || Loss: 7.4728 || 10iter: 1.4671 sec.\n",
      "Iter 90 || Loss: 7.5047 || 10iter: 1.4452 sec.\n",
      "Iter 100 || Loss: 7.3107 || 10iter: 1.4086 sec.\n",
      "Iter 110 || Loss: 6.9095 || 10iter: 1.4143 sec.\n",
      "Iter 120 || Loss: 7.5343 || 10iter: 1.4765 sec.\n",
      "Iter 130 || Loss: 6.7206 || 10iter: 1.4207 sec.\n",
      "Iter 140 || Loss: 7.4364 || 10iter: 1.4636 sec.\n",
      "Iter 150 || Loss: 7.2030 || 10iter: 1.4497 sec.\n",
      "Iter 160 || Loss: 7.2976 || 10iter: 1.4449 sec.\n",
      "Iter 170 || Loss: 7.1923 || 10iter: 1.4712 sec.\n",
      "Iter 180 || Loss: 7.2418 || 10iter: 1.4644 sec.\n",
      "Iter 190 || Loss: 6.6303 || 10iter: 1.4115 sec.\n",
      "Iter 200 || Loss: 6.6464 || 10iter: 1.4184 sec.\n",
      "Iter 210 || Loss: 6.6838 || 10iter: 1.4364 sec.\n",
      "Iter 220 || Loss: 6.6697 || 10iter: 1.4356 sec.\n",
      "Iter 230 || Loss: 6.9692 || 10iter: 1.4671 sec.\n",
      "Iter 240 || Loss: 6.8848 || 10iter: 1.4581 sec.\n",
      "Iter 250 || Loss: 6.5707 || 10iter: 1.4241 sec.\n",
      "Iter 260 || Loss: 6.8214 || 10iter: 1.3805 sec.\n",
      "Iter 270 || Loss: 6.6221 || 10iter: 1.4494 sec.\n",
      "Iter 280 || Loss: 6.9846 || 10iter: 1.4690 sec.\n",
      "Iter 290 || Loss: 6.5236 || 10iter: 1.4389 sec.\n",
      "Iter 300 || Loss: 5.8801 || 10iter: 1.4856 sec.\n",
      "Iter 310 || Loss: 6.7679 || 10iter: 1.4695 sec.\n",
      "Iter 320 || Loss: 7.1303 || 10iter: 1.4279 sec.\n",
      "Iter 330 || Loss: 6.5757 || 10iter: 1.4602 sec.\n",
      "Iter 340 || Loss: 6.6822 || 10iter: 1.4119 sec.\n",
      "Iter 350 || Loss: 6.4162 || 10iter: 1.4754 sec.\n",
      "Iter 360 || Loss: 6.7350 || 10iter: 1.4532 sec.\n",
      "Iter 370 || Loss: 6.4984 || 10iter: 1.4432 sec.\n",
      "Iter 380 || Loss: 6.5936 || 10iter: 1.4100 sec.\n",
      "Iter 390 || Loss: 6.3154 || 10iter: 1.4499 sec.\n",
      "Iter 400 || Loss: 5.9618 || 10iter: 1.4461 sec.\n",
      "Iter 410 || Loss: 6.2185 || 10iter: 1.4462 sec.\n",
      "Iter 420 || Loss: 6.3652 || 10iter: 1.4233 sec.\n",
      "Iter 430 || Loss: 6.3003 || 10iter: 1.4160 sec.\n",
      "Iter 440 || Loss: 5.8859 || 10iter: 1.4244 sec.\n",
      "Iter 450 || Loss: 6.4303 || 10iter: 1.4322 sec.\n",
      "Iter 460 || Loss: 6.1667 || 10iter: 1.4558 sec.\n",
      "Iter 470 || Loss: 5.7856 || 10iter: 1.4599 sec.\n",
      "Iter 480 || Loss: 6.2295 || 10iter: 1.4580 sec.\n",
      "Iter 490 || Loss: 6.4621 || 10iter: 1.4220 sec.\n",
      "Iter 500 || Loss: 6.2750 || 10iter: 1.3903 sec.\n",
      "Iter 510 || Loss: 6.1554 || 10iter: 1.4464 sec.\n",
      "Iter 520 || Loss: 6.1851 || 10iter: 1.4582 sec.\n",
      "Iter 530 || Loss: 5.9622 || 10iter: 1.4737 sec.\n",
      "Iter 540 || Loss: 5.7932 || 10iter: 1.3848 sec.\n",
      "Iter 550 || Loss: 6.0886 || 10iter: 1.4221 sec.\n",
      "Iter 560 || Loss: 5.4213 || 10iter: 1.3957 sec.\n",
      "Iter 570 || Loss: 5.3892 || 10iter: 1.4296 sec.\n",
      "Iter 580 || Loss: 5.8233 || 10iter: 1.4101 sec.\n",
      "Iter 590 || Loss: 5.6791 || 10iter: 1.4289 sec.\n",
      "Iter 600 || Loss: 6.0011 || 10iter: 1.4547 sec.\n",
      "Iter 610 || Loss: 5.9517 || 10iter: 1.4044 sec.\n",
      "Iter 620 || Loss: 5.7641 || 10iter: 1.3835 sec.\n",
      "Iter 630 || Loss: 5.5265 || 10iter: 1.4820 sec.\n",
      "Iter 640 || Loss: 5.3864 || 10iter: 1.4373 sec.\n",
      "Iter 650 || Loss: 5.8266 || 10iter: 1.4298 sec.\n",
      "Iter 660 || Loss: 5.5105 || 10iter: 1.4119 sec.\n",
      "Iter 670 || Loss: 5.6366 || 10iter: 1.5038 sec.\n",
      "Iter 680 || Loss: 5.4967 || 10iter: 1.3761 sec.\n",
      "Iter 690 || Loss: 5.4788 || 10iter: 2.1178 sec.\n",
      "-------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:4751.2483 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  104.1578 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 2/200\n",
      "-------------\n",
      "(train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 700 || Loss: 5.8074 || 10iter: 2.8835 sec.\n",
      "Iter 710 || Loss: 5.6515 || 10iter: 1.3655 sec.\n",
      "Iter 720 || Loss: 5.4100 || 10iter: 1.4087 sec.\n",
      "Iter 730 || Loss: 5.8192 || 10iter: 1.4216 sec.\n",
      "Iter 740 || Loss: 5.4620 || 10iter: 1.4234 sec.\n",
      "Iter 750 || Loss: 6.0821 || 10iter: 1.3745 sec.\n",
      "Iter 760 || Loss: 5.4831 || 10iter: 1.3818 sec.\n",
      "Iter 770 || Loss: 5.8731 || 10iter: 1.4171 sec.\n",
      "Iter 780 || Loss: 5.4119 || 10iter: 1.4034 sec.\n",
      "Iter 790 || Loss: 5.2094 || 10iter: 1.4024 sec.\n",
      "Iter 800 || Loss: 5.9166 || 10iter: 1.4924 sec.\n",
      "Iter 810 || Loss: 5.4892 || 10iter: 1.4225 sec.\n",
      "Iter 820 || Loss: 5.0315 || 10iter: 1.3873 sec.\n",
      "Iter 830 || Loss: 5.3579 || 10iter: 1.4441 sec.\n",
      "Iter 840 || Loss: 5.3510 || 10iter: 1.4417 sec.\n",
      "Iter 850 || Loss: 5.3508 || 10iter: 1.4245 sec.\n",
      "Iter 860 || Loss: 5.4362 || 10iter: 1.4411 sec.\n",
      "Iter 870 || Loss: 5.4825 || 10iter: 1.4147 sec.\n",
      "Iter 880 || Loss: 5.2356 || 10iter: 1.3731 sec.\n",
      "Iter 890 || Loss: 5.6775 || 10iter: 1.4839 sec.\n",
      "Iter 900 || Loss: 5.4433 || 10iter: 1.4340 sec.\n",
      "Iter 910 || Loss: 5.1250 || 10iter: 1.4813 sec.\n",
      "Iter 920 || Loss: 5.4003 || 10iter: 1.4264 sec.\n",
      "Iter 930 || Loss: 5.8603 || 10iter: 1.4666 sec.\n",
      "Iter 940 || Loss: 5.5635 || 10iter: 1.4300 sec.\n",
      "Iter 950 || Loss: 5.2567 || 10iter: 1.3737 sec.\n",
      "Iter 960 || Loss: 5.3459 || 10iter: 1.4410 sec.\n",
      "Iter 970 || Loss: 5.8490 || 10iter: 1.4756 sec.\n",
      "Iter 980 || Loss: 4.9866 || 10iter: 1.4611 sec.\n",
      "Iter 990 || Loss: 5.4067 || 10iter: 1.4310 sec.\n",
      "Iter 1000 || Loss: 5.0917 || 10iter: 1.4777 sec.\n",
      "Iter 1010 || Loss: 5.3507 || 10iter: 1.4436 sec.\n",
      "Iter 1020 || Loss: 5.2442 || 10iter: 1.4154 sec.\n",
      "Iter 1030 || Loss: 5.6749 || 10iter: 1.3997 sec.\n",
      "Iter 1040 || Loss: 5.7910 || 10iter: 1.4890 sec.\n",
      "Iter 1050 || Loss: 5.4388 || 10iter: 1.5268 sec.\n",
      "Iter 1060 || Loss: 4.8866 || 10iter: 1.4259 sec.\n",
      "Iter 1070 || Loss: 5.4060 || 10iter: 1.4923 sec.\n",
      "Iter 1080 || Loss: 5.2645 || 10iter: 1.4301 sec.\n",
      "Iter 1090 || Loss: 4.4621 || 10iter: 1.4522 sec.\n",
      "Iter 1100 || Loss: 5.5146 || 10iter: 1.4217 sec.\n",
      "Iter 1110 || Loss: 4.6509 || 10iter: 1.4221 sec.\n",
      "Iter 1120 || Loss: 4.9168 || 10iter: 1.4422 sec.\n",
      "Iter 1130 || Loss: 5.0976 || 10iter: 1.4030 sec.\n",
      "Iter 1140 || Loss: 5.5185 || 10iter: 1.4853 sec.\n",
      "Iter 1150 || Loss: 5.4110 || 10iter: 1.4492 sec.\n",
      "Iter 1160 || Loss: 5.3204 || 10iter: 1.4476 sec.\n",
      "Iter 1170 || Loss: 5.4921 || 10iter: 1.4011 sec.\n",
      "Iter 1180 || Loss: 5.6205 || 10iter: 1.4294 sec.\n",
      "Iter 1190 || Loss: 5.1408 || 10iter: 1.3836 sec.\n",
      "Iter 1200 || Loss: 5.7630 || 10iter: 1.4329 sec.\n",
      "Iter 1210 || Loss: 5.1723 || 10iter: 1.4228 sec.\n",
      "Iter 1220 || Loss: 5.4212 || 10iter: 1.4674 sec.\n",
      "Iter 1230 || Loss: 5.2247 || 10iter: 1.4451 sec.\n",
      "Iter 1240 || Loss: 5.5797 || 10iter: 1.4503 sec.\n",
      "Iter 1250 || Loss: 5.4183 || 10iter: 1.4653 sec.\n",
      "Iter 1260 || Loss: 5.1236 || 10iter: 1.4210 sec.\n",
      "Iter 1270 || Loss: 5.4446 || 10iter: 1.4448 sec.\n",
      "Iter 1280 || Loss: 4.8208 || 10iter: 1.4219 sec.\n",
      "Iter 1290 || Loss: 4.8999 || 10iter: 1.4332 sec.\n",
      "Iter 1300 || Loss: 5.4541 || 10iter: 1.3802 sec.\n",
      "Iter 1310 || Loss: 5.2071 || 10iter: 1.4233 sec.\n",
      "Iter 1320 || Loss: 5.1367 || 10iter: 1.4648 sec.\n",
      "Iter 1330 || Loss: 5.6376 || 10iter: 1.4433 sec.\n",
      "Iter 1340 || Loss: 5.4464 || 10iter: 1.4471 sec.\n",
      "Iter 1350 || Loss: 4.9352 || 10iter: 1.4349 sec.\n",
      "Iter 1360 || Loss: 5.0230 || 10iter: 1.4381 sec.\n",
      "Iter 1370 || Loss: 5.1224 || 10iter: 1.3250 sec.\n",
      "Iter 1380 || Loss: 5.9567 || 10iter: 1.2544 sec.\n",
      "-------------\n",
      "epoch 2 || Epoch_TRAIN_Loss:3695.3259 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.2444 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 3/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 1390 || Loss: 4.9575 || 10iter: 2.6952 sec.\n",
      "Iter 1400 || Loss: 4.9036 || 10iter: 1.3808 sec.\n",
      "Iter 1410 || Loss: 4.5282 || 10iter: 1.3972 sec.\n",
      "Iter 1420 || Loss: 5.7812 || 10iter: 1.4202 sec.\n",
      "Iter 1430 || Loss: 4.8420 || 10iter: 1.3734 sec.\n",
      "Iter 1440 || Loss: 5.4499 || 10iter: 1.4079 sec.\n",
      "Iter 1450 || Loss: 4.5398 || 10iter: 1.3948 sec.\n",
      "Iter 1460 || Loss: 5.0329 || 10iter: 1.4283 sec.\n",
      "Iter 1470 || Loss: 4.7824 || 10iter: 1.4306 sec.\n",
      "Iter 1480 || Loss: 4.7013 || 10iter: 1.4010 sec.\n",
      "Iter 1490 || Loss: 4.7385 || 10iter: 1.4462 sec.\n",
      "Iter 1500 || Loss: 5.1796 || 10iter: 1.4689 sec.\n",
      "Iter 1510 || Loss: 4.8301 || 10iter: 1.4110 sec.\n",
      "Iter 1520 || Loss: 4.9281 || 10iter: 1.3890 sec.\n",
      "Iter 1530 || Loss: 4.7136 || 10iter: 1.4148 sec.\n",
      "Iter 1540 || Loss: 4.6448 || 10iter: 1.4534 sec.\n",
      "Iter 1550 || Loss: 5.1527 || 10iter: 1.4394 sec.\n",
      "Iter 1560 || Loss: 4.5862 || 10iter: 1.4612 sec.\n",
      "Iter 1570 || Loss: 4.7095 || 10iter: 1.4574 sec.\n",
      "Iter 1580 || Loss: 4.7214 || 10iter: 1.4342 sec.\n",
      "Iter 1590 || Loss: 4.9852 || 10iter: 1.4894 sec.\n",
      "Iter 1600 || Loss: 4.8573 || 10iter: 1.4873 sec.\n",
      "Iter 1610 || Loss: 4.6641 || 10iter: 1.4814 sec.\n",
      "Iter 1620 || Loss: 4.8900 || 10iter: 1.4438 sec.\n",
      "Iter 1630 || Loss: 5.1450 || 10iter: 1.4004 sec.\n",
      "Iter 1640 || Loss: 4.7446 || 10iter: 1.4358 sec.\n",
      "Iter 1650 || Loss: 4.8446 || 10iter: 1.3922 sec.\n",
      "Iter 1660 || Loss: 4.7771 || 10iter: 1.4238 sec.\n",
      "Iter 1670 || Loss: 4.8311 || 10iter: 1.4383 sec.\n",
      "Iter 1680 || Loss: 4.8207 || 10iter: 1.4502 sec.\n",
      "Iter 1690 || Loss: 4.8394 || 10iter: 1.4995 sec.\n",
      "Iter 1700 || Loss: 5.3126 || 10iter: 1.4717 sec.\n",
      "Iter 1710 || Loss: 4.9208 || 10iter: 1.4211 sec.\n",
      "Iter 1720 || Loss: 4.9496 || 10iter: 1.4145 sec.\n",
      "Iter 1730 || Loss: 5.1267 || 10iter: 1.4785 sec.\n",
      "Iter 1740 || Loss: 4.9520 || 10iter: 1.4246 sec.\n",
      "Iter 1750 || Loss: 4.5833 || 10iter: 1.3939 sec.\n",
      "Iter 1760 || Loss: 4.8236 || 10iter: 1.4144 sec.\n",
      "Iter 1770 || Loss: 4.6394 || 10iter: 1.4703 sec.\n",
      "Iter 1780 || Loss: 4.8349 || 10iter: 1.4381 sec.\n",
      "Iter 1790 || Loss: 4.6564 || 10iter: 1.4276 sec.\n",
      "Iter 1800 || Loss: 4.8155 || 10iter: 1.4486 sec.\n",
      "Iter 1810 || Loss: 4.9795 || 10iter: 1.4363 sec.\n",
      "Iter 1820 || Loss: 4.8216 || 10iter: 1.4315 sec.\n",
      "Iter 1830 || Loss: 5.1280 || 10iter: 1.4554 sec.\n",
      "Iter 1840 || Loss: 4.7813 || 10iter: 1.4473 sec.\n",
      "Iter 1850 || Loss: 4.4417 || 10iter: 1.4277 sec.\n",
      "Iter 1860 || Loss: 5.0065 || 10iter: 1.4155 sec.\n",
      "Iter 1870 || Loss: 4.5987 || 10iter: 1.4315 sec.\n",
      "Iter 1880 || Loss: 4.6779 || 10iter: 1.4469 sec.\n",
      "Iter 1890 || Loss: 5.0390 || 10iter: 1.4229 sec.\n",
      "Iter 1900 || Loss: 4.4610 || 10iter: 1.4957 sec.\n",
      "Iter 1910 || Loss: 4.4326 || 10iter: 1.4786 sec.\n",
      "Iter 1920 || Loss: 4.7633 || 10iter: 1.4326 sec.\n",
      "Iter 1930 || Loss: 4.7112 || 10iter: 1.4674 sec.\n",
      "Iter 1940 || Loss: 4.5477 || 10iter: 1.4348 sec.\n",
      "Iter 1950 || Loss: 4.4747 || 10iter: 1.4370 sec.\n",
      "Iter 1960 || Loss: 4.5134 || 10iter: 1.4936 sec.\n",
      "Iter 1970 || Loss: 5.1436 || 10iter: 1.4199 sec.\n",
      "Iter 1980 || Loss: 4.3014 || 10iter: 1.4533 sec.\n",
      "Iter 1990 || Loss: 4.9298 || 10iter: 1.4135 sec.\n",
      "Iter 2000 || Loss: 4.4479 || 10iter: 1.4466 sec.\n",
      "Iter 2010 || Loss: 4.4227 || 10iter: 1.4235 sec.\n",
      "Iter 2020 || Loss: 4.9027 || 10iter: 1.4539 sec.\n",
      "Iter 2030 || Loss: 4.1095 || 10iter: 1.4364 sec.\n",
      "Iter 2040 || Loss: 4.5151 || 10iter: 1.4643 sec.\n",
      "Iter 2050 || Loss: 4.6983 || 10iter: 1.4390 sec.\n",
      "Iter 2060 || Loss: 5.0613 || 10iter: 1.3681 sec.\n",
      "Iter 2070 || Loss: 4.5505 || 10iter: 1.2638 sec.\n",
      "-------------\n",
      "epoch 3 || Epoch_TRAIN_Loss:3379.6294 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.3124 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 4/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 2080 || Loss: 4.4513 || 10iter: 2.7873 sec.\n",
      "Iter 2090 || Loss: 4.5087 || 10iter: 1.3490 sec.\n",
      "Iter 2100 || Loss: 4.8339 || 10iter: 1.5087 sec.\n",
      "Iter 2110 || Loss: 5.1443 || 10iter: 1.4515 sec.\n",
      "Iter 2120 || Loss: 4.2724 || 10iter: 1.4898 sec.\n",
      "Iter 2130 || Loss: 4.2144 || 10iter: 1.4229 sec.\n",
      "Iter 2140 || Loss: 4.7900 || 10iter: 1.3909 sec.\n",
      "Iter 2150 || Loss: 4.6981 || 10iter: 1.4098 sec.\n",
      "Iter 2160 || Loss: 4.7502 || 10iter: 1.4349 sec.\n",
      "Iter 2170 || Loss: 4.7588 || 10iter: 1.4316 sec.\n",
      "Iter 2180 || Loss: 4.6741 || 10iter: 1.4065 sec.\n",
      "Iter 2190 || Loss: 4.4239 || 10iter: 1.4799 sec.\n",
      "Iter 2200 || Loss: 5.3282 || 10iter: 1.3797 sec.\n",
      "Iter 2210 || Loss: 4.3022 || 10iter: 1.4356 sec.\n",
      "Iter 2220 || Loss: 5.0341 || 10iter: 1.5122 sec.\n",
      "Iter 2230 || Loss: 4.8910 || 10iter: 1.4877 sec.\n",
      "Iter 2240 || Loss: 4.7665 || 10iter: 1.4764 sec.\n",
      "Iter 2250 || Loss: 4.5264 || 10iter: 1.4674 sec.\n",
      "Iter 2260 || Loss: 4.5955 || 10iter: 1.4948 sec.\n",
      "Iter 2270 || Loss: 4.0090 || 10iter: 1.4459 sec.\n",
      "Iter 2280 || Loss: 4.1281 || 10iter: 1.4356 sec.\n",
      "Iter 2290 || Loss: 4.8072 || 10iter: 1.4236 sec.\n",
      "Iter 2300 || Loss: 4.8387 || 10iter: 1.4297 sec.\n",
      "Iter 2310 || Loss: 4.7188 || 10iter: 1.4049 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2320 || Loss: 4.8994 || 10iter: 1.5180 sec.\n",
      "Iter 2330 || Loss: 5.4873 || 10iter: 1.4168 sec.\n",
      "Iter 2340 || Loss: 4.9252 || 10iter: 1.4234 sec.\n",
      "Iter 2350 || Loss: 4.3950 || 10iter: 1.5062 sec.\n",
      "Iter 2360 || Loss: 4.6753 || 10iter: 1.4297 sec.\n",
      "Iter 2370 || Loss: 5.2964 || 10iter: 1.4560 sec.\n",
      "Iter 2380 || Loss: 4.3958 || 10iter: 1.4509 sec.\n",
      "Iter 2390 || Loss: 4.9358 || 10iter: 1.4289 sec.\n",
      "Iter 2400 || Loss: 4.8022 || 10iter: 1.4790 sec.\n",
      "Iter 2410 || Loss: 4.6298 || 10iter: 1.4215 sec.\n",
      "Iter 2420 || Loss: 4.5151 || 10iter: 1.4668 sec.\n",
      "Iter 2430 || Loss: 4.6984 || 10iter: 1.4036 sec.\n",
      "Iter 2440 || Loss: 4.8150 || 10iter: 1.4643 sec.\n",
      "Iter 2450 || Loss: 4.8885 || 10iter: 1.4594 sec.\n",
      "Iter 2460 || Loss: 4.0130 || 10iter: 1.4730 sec.\n",
      "Iter 2470 || Loss: 5.0089 || 10iter: 1.4257 sec.\n",
      "Iter 2480 || Loss: 4.6807 || 10iter: 1.4710 sec.\n",
      "Iter 2490 || Loss: 3.9390 || 10iter: 1.4222 sec.\n",
      "Iter 2500 || Loss: 4.3685 || 10iter: 1.4103 sec.\n",
      "Iter 2510 || Loss: 5.8880 || 10iter: 1.4374 sec.\n",
      "Iter 2520 || Loss: 4.4771 || 10iter: 1.4600 sec.\n",
      "Iter 2530 || Loss: 4.8369 || 10iter: 1.4884 sec.\n",
      "Iter 2540 || Loss: 4.6479 || 10iter: 1.4988 sec.\n",
      "Iter 2550 || Loss: 4.6049 || 10iter: 1.4424 sec.\n",
      "Iter 2560 || Loss: 4.4858 || 10iter: 1.4153 sec.\n",
      "Iter 2570 || Loss: 4.9684 || 10iter: 1.4116 sec.\n",
      "Iter 2580 || Loss: 4.5753 || 10iter: 1.4383 sec.\n",
      "Iter 2590 || Loss: 4.9767 || 10iter: 1.4791 sec.\n",
      "Iter 2600 || Loss: 4.2344 || 10iter: 1.4461 sec.\n",
      "Iter 2610 || Loss: 4.5213 || 10iter: 1.4429 sec.\n",
      "Iter 2620 || Loss: 4.6195 || 10iter: 1.4508 sec.\n",
      "Iter 2630 || Loss: 4.4482 || 10iter: 1.4790 sec.\n",
      "Iter 2640 || Loss: 3.8023 || 10iter: 1.4615 sec.\n",
      "Iter 2650 || Loss: 4.6460 || 10iter: 1.4002 sec.\n",
      "Iter 2660 || Loss: 4.8799 || 10iter: 1.4836 sec.\n",
      "Iter 2670 || Loss: 4.3052 || 10iter: 1.4277 sec.\n",
      "Iter 2680 || Loss: 4.8234 || 10iter: 1.4019 sec.\n",
      "Iter 2690 || Loss: 4.4471 || 10iter: 1.4076 sec.\n",
      "Iter 2700 || Loss: 4.6449 || 10iter: 1.4472 sec.\n",
      "Iter 2710 || Loss: 4.5831 || 10iter: 1.4467 sec.\n",
      "Iter 2720 || Loss: 4.5404 || 10iter: 1.4008 sec.\n",
      "Iter 2730 || Loss: 4.3538 || 10iter: 1.4377 sec.\n",
      "Iter 2740 || Loss: 4.8357 || 10iter: 1.3728 sec.\n",
      "Iter 2750 || Loss: 4.0973 || 10iter: 1.3739 sec.\n",
      "Iter 2760 || Loss: 4.3353 || 10iter: 1.2677 sec.\n",
      "-------------\n",
      "epoch 4 || Epoch_TRAIN_Loss:3208.4460 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.8083 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 5/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 2770 || Loss: 4.7560 || 10iter: 2.7802 sec.\n",
      "Iter 2780 || Loss: 4.5698 || 10iter: 1.3706 sec.\n",
      "Iter 2790 || Loss: 5.1654 || 10iter: 1.4267 sec.\n",
      "Iter 2800 || Loss: 5.0254 || 10iter: 1.3813 sec.\n",
      "Iter 2810 || Loss: 4.0271 || 10iter: 1.4372 sec.\n",
      "Iter 2820 || Loss: 4.5884 || 10iter: 1.3977 sec.\n",
      "Iter 2830 || Loss: 4.4633 || 10iter: 1.4205 sec.\n",
      "Iter 2840 || Loss: 5.1383 || 10iter: 1.4178 sec.\n",
      "Iter 2850 || Loss: 3.8683 || 10iter: 1.4340 sec.\n",
      "Iter 2860 || Loss: 4.0783 || 10iter: 1.4169 sec.\n",
      "Iter 2870 || Loss: 4.7556 || 10iter: 1.4023 sec.\n",
      "Iter 2880 || Loss: 4.0707 || 10iter: 1.3987 sec.\n",
      "Iter 2890 || Loss: 4.6155 || 10iter: 1.4257 sec.\n",
      "Iter 2900 || Loss: 4.7262 || 10iter: 1.4094 sec.\n",
      "Iter 2910 || Loss: 4.8734 || 10iter: 1.5005 sec.\n",
      "Iter 2920 || Loss: 4.3898 || 10iter: 1.4965 sec.\n",
      "Iter 2930 || Loss: 4.4797 || 10iter: 1.4500 sec.\n",
      "Iter 2940 || Loss: 4.0692 || 10iter: 1.4195 sec.\n",
      "Iter 2950 || Loss: 4.5502 || 10iter: 1.4215 sec.\n",
      "Iter 2960 || Loss: 4.3328 || 10iter: 1.4047 sec.\n",
      "Iter 2970 || Loss: 4.4703 || 10iter: 1.4713 sec.\n",
      "Iter 2980 || Loss: 4.7493 || 10iter: 1.4523 sec.\n",
      "Iter 2990 || Loss: 4.7842 || 10iter: 1.4202 sec.\n",
      "Iter 3000 || Loss: 4.7100 || 10iter: 1.3932 sec.\n",
      "Iter 3010 || Loss: 4.5368 || 10iter: 1.4349 sec.\n",
      "Iter 3020 || Loss: 4.0556 || 10iter: 1.4372 sec.\n",
      "Iter 3030 || Loss: 4.6247 || 10iter: 1.4203 sec.\n",
      "Iter 3040 || Loss: 4.3322 || 10iter: 1.3823 sec.\n",
      "Iter 3050 || Loss: 4.4691 || 10iter: 1.4398 sec.\n",
      "Iter 3060 || Loss: 4.1492 || 10iter: 1.4806 sec.\n",
      "Iter 3070 || Loss: 3.6546 || 10iter: 1.4730 sec.\n",
      "Iter 3080 || Loss: 5.1527 || 10iter: 1.4692 sec.\n",
      "Iter 3090 || Loss: 4.7583 || 10iter: 1.4347 sec.\n",
      "Iter 3100 || Loss: 4.5858 || 10iter: 1.4327 sec.\n",
      "Iter 3110 || Loss: 4.8141 || 10iter: 1.4249 sec.\n",
      "Iter 3120 || Loss: 4.5607 || 10iter: 1.4443 sec.\n",
      "Iter 3130 || Loss: 4.7125 || 10iter: 1.4423 sec.\n",
      "Iter 3140 || Loss: 4.4443 || 10iter: 1.3865 sec.\n",
      "Iter 3150 || Loss: 4.6891 || 10iter: 1.4503 sec.\n",
      "Iter 3160 || Loss: 4.6294 || 10iter: 1.4708 sec.\n",
      "Iter 3170 || Loss: 4.0589 || 10iter: 1.4061 sec.\n",
      "Iter 3180 || Loss: 4.5073 || 10iter: 1.4297 sec.\n",
      "Iter 3190 || Loss: 4.3368 || 10iter: 1.4352 sec.\n",
      "Iter 3200 || Loss: 4.1889 || 10iter: 1.4875 sec.\n",
      "Iter 3210 || Loss: 4.6606 || 10iter: 1.4422 sec.\n",
      "Iter 3220 || Loss: 4.4062 || 10iter: 1.4494 sec.\n",
      "Iter 3230 || Loss: 4.8483 || 10iter: 1.4026 sec.\n",
      "Iter 3240 || Loss: 4.3850 || 10iter: 1.3986 sec.\n",
      "Iter 3250 || Loss: 4.0137 || 10iter: 1.4413 sec.\n",
      "Iter 3260 || Loss: 4.6121 || 10iter: 1.4832 sec.\n",
      "Iter 3270 || Loss: 4.4625 || 10iter: 1.4170 sec.\n",
      "Iter 3280 || Loss: 3.7660 || 10iter: 1.4122 sec.\n",
      "Iter 3290 || Loss: 4.7746 || 10iter: 1.4333 sec.\n",
      "Iter 3300 || Loss: 4.5300 || 10iter: 1.4511 sec.\n",
      "Iter 3310 || Loss: 4.3998 || 10iter: 1.4262 sec.\n",
      "Iter 3320 || Loss: 4.7308 || 10iter: 1.4241 sec.\n",
      "Iter 3330 || Loss: 4.4991 || 10iter: 1.4230 sec.\n",
      "Iter 3340 || Loss: 5.1517 || 10iter: 1.4374 sec.\n",
      "Iter 3350 || Loss: 4.4644 || 10iter: 1.4704 sec.\n",
      "Iter 3360 || Loss: 4.5090 || 10iter: 1.4056 sec.\n",
      "Iter 3370 || Loss: 4.2496 || 10iter: 1.3957 sec.\n",
      "Iter 3380 || Loss: 4.3855 || 10iter: 1.3801 sec.\n",
      "Iter 3390 || Loss: 4.3422 || 10iter: 1.3971 sec.\n",
      "Iter 3400 || Loss: 4.0659 || 10iter: 1.4485 sec.\n",
      "Iter 3410 || Loss: 4.0935 || 10iter: 1.4305 sec.\n",
      "Iter 3420 || Loss: 4.2400 || 10iter: 1.3895 sec.\n",
      "Iter 3430 || Loss: 4.2683 || 10iter: 1.4137 sec.\n",
      "Iter 3440 || Loss: 4.3406 || 10iter: 1.3357 sec.\n",
      "Iter 3450 || Loss: 4.1266 || 10iter: 1.2743 sec.\n",
      "-------------\n",
      "epoch 5 || Epoch_TRAIN_Loss:3090.0875 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  101.8770 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 6/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 3460 || Loss: 4.3354 || 10iter: 2.8190 sec.\n",
      "Iter 3470 || Loss: 4.4269 || 10iter: 1.5186 sec.\n",
      "Iter 3480 || Loss: 4.2536 || 10iter: 1.4729 sec.\n",
      "Iter 3490 || Loss: 4.7424 || 10iter: 1.4696 sec.\n",
      "Iter 3500 || Loss: 4.5030 || 10iter: 1.3784 sec.\n",
      "Iter 3510 || Loss: 4.4604 || 10iter: 1.4390 sec.\n",
      "Iter 3520 || Loss: 4.3831 || 10iter: 1.4046 sec.\n",
      "Iter 3530 || Loss: 4.8065 || 10iter: 1.4563 sec.\n",
      "Iter 3540 || Loss: 4.2672 || 10iter: 1.3994 sec.\n",
      "Iter 3550 || Loss: 4.6384 || 10iter: 1.4280 sec.\n",
      "Iter 3560 || Loss: 4.3505 || 10iter: 1.4922 sec.\n",
      "Iter 3570 || Loss: 3.8504 || 10iter: 1.4451 sec.\n",
      "Iter 3580 || Loss: 4.1001 || 10iter: 1.4502 sec.\n",
      "Iter 3590 || Loss: 4.0355 || 10iter: 1.4266 sec.\n",
      "Iter 3600 || Loss: 4.7050 || 10iter: 1.4588 sec.\n",
      "Iter 3610 || Loss: 4.3950 || 10iter: 1.4217 sec.\n",
      "Iter 3620 || Loss: 4.7120 || 10iter: 1.4841 sec.\n",
      "Iter 3630 || Loss: 4.6489 || 10iter: 1.4476 sec.\n",
      "Iter 3640 || Loss: 4.2046 || 10iter: 1.4467 sec.\n",
      "Iter 3650 || Loss: 4.5410 || 10iter: 1.4161 sec.\n",
      "Iter 3660 || Loss: 4.8748 || 10iter: 1.4656 sec.\n",
      "Iter 3670 || Loss: 4.5324 || 10iter: 1.4236 sec.\n",
      "Iter 3680 || Loss: 4.2761 || 10iter: 1.4181 sec.\n",
      "Iter 3690 || Loss: 4.3869 || 10iter: 1.4360 sec.\n",
      "Iter 3700 || Loss: 4.6849 || 10iter: 1.4696 sec.\n",
      "Iter 3710 || Loss: 4.4370 || 10iter: 1.3988 sec.\n",
      "Iter 3720 || Loss: 3.5417 || 10iter: 1.4455 sec.\n",
      "Iter 3730 || Loss: 4.7559 || 10iter: 1.4508 sec.\n",
      "Iter 3740 || Loss: 4.1164 || 10iter: 1.4928 sec.\n",
      "Iter 3750 || Loss: 4.8183 || 10iter: 1.4563 sec.\n",
      "Iter 3760 || Loss: 4.6559 || 10iter: 1.4660 sec.\n",
      "Iter 3770 || Loss: 5.0674 || 10iter: 1.3998 sec.\n",
      "Iter 3780 || Loss: 4.7090 || 10iter: 1.4429 sec.\n",
      "Iter 3790 || Loss: 3.5526 || 10iter: 1.4659 sec.\n",
      "Iter 3800 || Loss: 3.9805 || 10iter: 1.4656 sec.\n",
      "Iter 3810 || Loss: 4.6543 || 10iter: 1.4243 sec.\n",
      "Iter 3820 || Loss: 4.4377 || 10iter: 1.4060 sec.\n",
      "Iter 3830 || Loss: 3.8031 || 10iter: 1.4101 sec.\n",
      "Iter 3840 || Loss: 4.6322 || 10iter: 1.4219 sec.\n",
      "Iter 3850 || Loss: 4.6458 || 10iter: 1.4055 sec.\n",
      "Iter 3860 || Loss: 4.6486 || 10iter: 1.4194 sec.\n",
      "Iter 3870 || Loss: 4.1727 || 10iter: 1.4489 sec.\n",
      "Iter 3880 || Loss: 4.0871 || 10iter: 1.4437 sec.\n",
      "Iter 3890 || Loss: 4.4219 || 10iter: 1.4252 sec.\n",
      "Iter 3900 || Loss: 4.1913 || 10iter: 1.4336 sec.\n",
      "Iter 3910 || Loss: 4.3114 || 10iter: 1.4817 sec.\n",
      "Iter 3920 || Loss: 4.6160 || 10iter: 1.4681 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3930 || Loss: 4.3457 || 10iter: 1.4028 sec.\n",
      "Iter 3940 || Loss: 4.3299 || 10iter: 1.4169 sec.\n",
      "Iter 3950 || Loss: 4.5807 || 10iter: 1.4578 sec.\n",
      "Iter 3960 || Loss: 4.2687 || 10iter: 1.4376 sec.\n",
      "Iter 3970 || Loss: 4.1582 || 10iter: 1.4147 sec.\n",
      "Iter 3980 || Loss: 3.9000 || 10iter: 1.4297 sec.\n",
      "Iter 3990 || Loss: 4.5963 || 10iter: 1.3898 sec.\n",
      "Iter 4000 || Loss: 4.2883 || 10iter: 1.4596 sec.\n",
      "Iter 4010 || Loss: 4.4846 || 10iter: 1.4382 sec.\n",
      "Iter 4020 || Loss: 4.4053 || 10iter: 1.4101 sec.\n",
      "Iter 4030 || Loss: 4.4456 || 10iter: 1.4339 sec.\n",
      "Iter 4040 || Loss: 4.6380 || 10iter: 1.3754 sec.\n",
      "Iter 4050 || Loss: 3.5988 || 10iter: 1.4605 sec.\n",
      "Iter 4060 || Loss: 4.3380 || 10iter: 1.4072 sec.\n",
      "Iter 4070 || Loss: 4.6243 || 10iter: 1.4606 sec.\n",
      "Iter 4080 || Loss: 4.3436 || 10iter: 1.3962 sec.\n",
      "Iter 4090 || Loss: 4.4858 || 10iter: 1.4553 sec.\n",
      "Iter 4100 || Loss: 4.3095 || 10iter: 1.3985 sec.\n",
      "Iter 4110 || Loss: 3.9933 || 10iter: 1.4147 sec.\n",
      "Iter 4120 || Loss: 4.6023 || 10iter: 1.4588 sec.\n",
      "Iter 4130 || Loss: 3.7468 || 10iter: 1.3456 sec.\n",
      "Iter 4140 || Loss: 3.7794 || 10iter: 1.2539 sec.\n",
      "-------------\n",
      "epoch 6 || Epoch_TRAIN_Loss:3000.2723 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.4349 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 7/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 4150 || Loss: 3.8368 || 10iter: 2.7340 sec.\n",
      "Iter 4160 || Loss: 4.5576 || 10iter: 1.3642 sec.\n",
      "Iter 4170 || Loss: 4.6234 || 10iter: 1.4724 sec.\n",
      "Iter 4180 || Loss: 4.3118 || 10iter: 1.3881 sec.\n",
      "Iter 4190 || Loss: 4.0394 || 10iter: 1.4008 sec.\n",
      "Iter 4200 || Loss: 4.1480 || 10iter: 1.4143 sec.\n",
      "Iter 4210 || Loss: 4.1996 || 10iter: 1.3965 sec.\n",
      "Iter 4220 || Loss: 3.8937 || 10iter: 1.4695 sec.\n",
      "Iter 4230 || Loss: 4.4120 || 10iter: 1.4229 sec.\n",
      "Iter 4240 || Loss: 4.3187 || 10iter: 1.4613 sec.\n",
      "Iter 4250 || Loss: 4.2642 || 10iter: 1.4513 sec.\n",
      "Iter 4260 || Loss: 3.9688 || 10iter: 1.3970 sec.\n",
      "Iter 4270 || Loss: 4.2643 || 10iter: 1.4019 sec.\n",
      "Iter 4280 || Loss: 4.7092 || 10iter: 1.3733 sec.\n",
      "Iter 4290 || Loss: 4.4114 || 10iter: 1.4082 sec.\n",
      "Iter 4300 || Loss: 4.0017 || 10iter: 1.4543 sec.\n",
      "Iter 4310 || Loss: 4.1752 || 10iter: 1.4345 sec.\n",
      "Iter 4320 || Loss: 4.0204 || 10iter: 1.4634 sec.\n",
      "Iter 4330 || Loss: 4.8122 || 10iter: 1.3989 sec.\n",
      "Iter 4340 || Loss: 4.5878 || 10iter: 1.4404 sec.\n",
      "Iter 4350 || Loss: 4.5441 || 10iter: 1.4578 sec.\n",
      "Iter 4360 || Loss: 3.5557 || 10iter: 1.4100 sec.\n",
      "Iter 4370 || Loss: 4.2139 || 10iter: 1.4252 sec.\n",
      "Iter 4380 || Loss: 4.3200 || 10iter: 1.5133 sec.\n",
      "Iter 4390 || Loss: 4.3864 || 10iter: 1.4237 sec.\n",
      "Iter 4400 || Loss: 5.0332 || 10iter: 1.4411 sec.\n",
      "Iter 4410 || Loss: 4.3014 || 10iter: 1.4725 sec.\n",
      "Iter 4420 || Loss: 4.7379 || 10iter: 1.4746 sec.\n",
      "Iter 4430 || Loss: 4.6381 || 10iter: 1.4292 sec.\n",
      "Iter 4440 || Loss: 4.2178 || 10iter: 1.4391 sec.\n",
      "Iter 4450 || Loss: 4.9919 || 10iter: 1.5006 sec.\n",
      "Iter 4460 || Loss: 4.6667 || 10iter: 1.4408 sec.\n",
      "Iter 4470 || Loss: 4.0231 || 10iter: 1.3743 sec.\n",
      "Iter 4480 || Loss: 4.3715 || 10iter: 1.4207 sec.\n",
      "Iter 4490 || Loss: 4.1201 || 10iter: 1.3997 sec.\n",
      "Iter 4500 || Loss: 4.3107 || 10iter: 1.3976 sec.\n",
      "Iter 4510 || Loss: 4.0845 || 10iter: 1.4023 sec.\n",
      "Iter 4520 || Loss: 4.2781 || 10iter: 1.4034 sec.\n",
      "Iter 4530 || Loss: 4.1536 || 10iter: 1.4314 sec.\n",
      "Iter 4540 || Loss: 4.9413 || 10iter: 1.4051 sec.\n",
      "Iter 4550 || Loss: 3.8826 || 10iter: 1.3900 sec.\n",
      "Iter 4560 || Loss: 4.6090 || 10iter: 1.4365 sec.\n",
      "Iter 4570 || Loss: 4.3530 || 10iter: 1.3907 sec.\n",
      "Iter 4580 || Loss: 4.6278 || 10iter: 1.4468 sec.\n",
      "Iter 4590 || Loss: 4.6715 || 10iter: 1.4251 sec.\n",
      "Iter 4600 || Loss: 4.7423 || 10iter: 1.4425 sec.\n",
      "Iter 4610 || Loss: 4.2212 || 10iter: 1.4024 sec.\n",
      "Iter 4620 || Loss: 4.6605 || 10iter: 1.4722 sec.\n",
      "Iter 4630 || Loss: 4.2339 || 10iter: 1.4362 sec.\n",
      "Iter 4640 || Loss: 5.0936 || 10iter: 1.4284 sec.\n",
      "Iter 4650 || Loss: 4.3827 || 10iter: 1.4329 sec.\n",
      "Iter 4660 || Loss: 4.2032 || 10iter: 1.4257 sec.\n",
      "Iter 4670 || Loss: 4.0023 || 10iter: 1.4547 sec.\n",
      "Iter 4680 || Loss: 4.1864 || 10iter: 1.4884 sec.\n",
      "Iter 4690 || Loss: 4.0498 || 10iter: 1.5188 sec.\n",
      "Iter 4700 || Loss: 4.5129 || 10iter: 1.4675 sec.\n",
      "Iter 4710 || Loss: 4.5374 || 10iter: 1.4395 sec.\n",
      "Iter 4720 || Loss: 3.9690 || 10iter: 1.4134 sec.\n",
      "Iter 4730 || Loss: 4.1557 || 10iter: 1.4449 sec.\n",
      "Iter 4740 || Loss: 4.7529 || 10iter: 1.4347 sec.\n",
      "Iter 4750 || Loss: 3.8457 || 10iter: 1.4204 sec.\n",
      "Iter 4760 || Loss: 4.1516 || 10iter: 1.4501 sec.\n",
      "Iter 4770 || Loss: 3.6708 || 10iter: 1.4300 sec.\n",
      "Iter 4780 || Loss: 3.7568 || 10iter: 1.4270 sec.\n",
      "Iter 4790 || Loss: 4.6315 || 10iter: 1.3864 sec.\n",
      "Iter 4800 || Loss: 4.0220 || 10iter: 1.4059 sec.\n",
      "Iter 4810 || Loss: 3.6301 || 10iter: 1.4238 sec.\n",
      "Iter 4820 || Loss: 4.2026 || 10iter: 1.3832 sec.\n",
      "Iter 4830 || Loss: 4.1561 || 10iter: 1.2611 sec.\n",
      "-------------\n",
      "epoch 7 || Epoch_TRAIN_Loss:2927.3040 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  101.9235 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 8/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 4840 || Loss: 4.2431 || 10iter: 2.7915 sec.\n",
      "Iter 4850 || Loss: 4.3100 || 10iter: 1.3684 sec.\n",
      "Iter 4860 || Loss: 3.3343 || 10iter: 1.3845 sec.\n",
      "Iter 4870 || Loss: 4.2954 || 10iter: 1.4493 sec.\n",
      "Iter 4880 || Loss: 4.3316 || 10iter: 1.3979 sec.\n",
      "Iter 4890 || Loss: 3.9917 || 10iter: 1.4472 sec.\n",
      "Iter 4900 || Loss: 4.4290 || 10iter: 1.4295 sec.\n",
      "Iter 4910 || Loss: 4.4164 || 10iter: 1.3837 sec.\n",
      "Iter 4920 || Loss: 4.1681 || 10iter: 1.4270 sec.\n",
      "Iter 4930 || Loss: 3.9820 || 10iter: 1.4274 sec.\n",
      "Iter 4940 || Loss: 4.1650 || 10iter: 1.4570 sec.\n",
      "Iter 4950 || Loss: 4.5819 || 10iter: 1.4678 sec.\n",
      "Iter 4960 || Loss: 4.3011 || 10iter: 1.3960 sec.\n",
      "Iter 4970 || Loss: 4.2211 || 10iter: 1.4155 sec.\n",
      "Iter 4980 || Loss: 4.3406 || 10iter: 1.4545 sec.\n",
      "Iter 4990 || Loss: 4.0361 || 10iter: 1.4706 sec.\n",
      "Iter 5000 || Loss: 4.2444 || 10iter: 1.4831 sec.\n",
      "Iter 5010 || Loss: 4.0645 || 10iter: 1.4401 sec.\n",
      "Iter 5020 || Loss: 3.9543 || 10iter: 1.4338 sec.\n",
      "Iter 5030 || Loss: 4.0917 || 10iter: 1.3814 sec.\n",
      "Iter 5040 || Loss: 4.2806 || 10iter: 1.4434 sec.\n",
      "Iter 5050 || Loss: 4.4509 || 10iter: 1.5060 sec.\n",
      "Iter 5060 || Loss: 4.2233 || 10iter: 1.4333 sec.\n",
      "Iter 5070 || Loss: 3.7568 || 10iter: 1.4494 sec.\n",
      "Iter 5080 || Loss: 4.5311 || 10iter: 1.4115 sec.\n",
      "Iter 5090 || Loss: 4.7634 || 10iter: 1.4200 sec.\n",
      "Iter 5100 || Loss: 4.4669 || 10iter: 1.4945 sec.\n",
      "Iter 5110 || Loss: 4.5050 || 10iter: 1.4592 sec.\n",
      "Iter 5120 || Loss: 4.1587 || 10iter: 1.4466 sec.\n",
      "Iter 5130 || Loss: 4.4754 || 10iter: 1.4334 sec.\n",
      "Iter 5140 || Loss: 3.8772 || 10iter: 1.4588 sec.\n",
      "Iter 5150 || Loss: 4.5506 || 10iter: 1.4460 sec.\n",
      "Iter 5160 || Loss: 4.3084 || 10iter: 1.4151 sec.\n",
      "Iter 5170 || Loss: 4.1348 || 10iter: 1.4396 sec.\n",
      "Iter 5180 || Loss: 4.7121 || 10iter: 1.4682 sec.\n",
      "Iter 5190 || Loss: 3.8904 || 10iter: 1.4301 sec.\n",
      "Iter 5200 || Loss: 4.1826 || 10iter: 1.4146 sec.\n",
      "Iter 5210 || Loss: 4.0561 || 10iter: 1.4577 sec.\n",
      "Iter 5220 || Loss: 3.7185 || 10iter: 1.4203 sec.\n",
      "Iter 5230 || Loss: 4.0121 || 10iter: 1.4142 sec.\n",
      "Iter 5240 || Loss: 3.9437 || 10iter: 1.4525 sec.\n",
      "Iter 5250 || Loss: 4.1894 || 10iter: 1.3931 sec.\n",
      "Iter 5260 || Loss: 3.9327 || 10iter: 1.3949 sec.\n",
      "Iter 5270 || Loss: 3.7652 || 10iter: 1.4210 sec.\n",
      "Iter 5280 || Loss: 3.8541 || 10iter: 1.4400 sec.\n",
      "Iter 5290 || Loss: 4.0557 || 10iter: 1.4397 sec.\n",
      "Iter 5300 || Loss: 4.3949 || 10iter: 1.4603 sec.\n",
      "Iter 5310 || Loss: 4.6577 || 10iter: 1.4184 sec.\n",
      "Iter 5320 || Loss: 3.6301 || 10iter: 1.4952 sec.\n",
      "Iter 5330 || Loss: 3.6149 || 10iter: 1.4262 sec.\n",
      "Iter 5340 || Loss: 4.4021 || 10iter: 1.3923 sec.\n",
      "Iter 5350 || Loss: 3.5797 || 10iter: 1.4316 sec.\n",
      "Iter 5360 || Loss: 3.9999 || 10iter: 1.4679 sec.\n",
      "Iter 5370 || Loss: 4.0663 || 10iter: 1.3988 sec.\n",
      "Iter 5380 || Loss: 4.2037 || 10iter: 1.4258 sec.\n",
      "Iter 5390 || Loss: 4.8774 || 10iter: 1.4502 sec.\n",
      "Iter 5400 || Loss: 3.4699 || 10iter: 1.4774 sec.\n",
      "Iter 5410 || Loss: 4.0044 || 10iter: 1.4317 sec.\n",
      "Iter 5420 || Loss: 3.7783 || 10iter: 1.4307 sec.\n",
      "Iter 5430 || Loss: 3.6227 || 10iter: 1.4000 sec.\n",
      "Iter 5440 || Loss: 4.2972 || 10iter: 1.4406 sec.\n",
      "Iter 5450 || Loss: 4.1794 || 10iter: 1.4249 sec.\n",
      "Iter 5460 || Loss: 3.8784 || 10iter: 1.3803 sec.\n",
      "Iter 5470 || Loss: 3.8469 || 10iter: 1.4253 sec.\n",
      "Iter 5480 || Loss: 3.8085 || 10iter: 1.4291 sec.\n",
      "Iter 5490 || Loss: 4.0890 || 10iter: 1.4126 sec.\n",
      "Iter 5500 || Loss: 3.6481 || 10iter: 1.4523 sec.\n",
      "Iter 5510 || Loss: 4.7727 || 10iter: 1.3570 sec.\n",
      "Iter 5520 || Loss: 4.3192 || 10iter: 1.2419 sec.\n",
      "-------------\n",
      "epoch 8 || Epoch_TRAIN_Loss:2851.1055 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.1284 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 9/200\n",
      "-------------\n",
      "(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5530 || Loss: 4.1857 || 10iter: 2.6783 sec.\n",
      "Iter 5540 || Loss: 4.1984 || 10iter: 1.3193 sec.\n",
      "Iter 5550 || Loss: 3.7496 || 10iter: 1.4471 sec.\n",
      "Iter 5560 || Loss: 3.6405 || 10iter: 1.4076 sec.\n",
      "Iter 5570 || Loss: 3.9753 || 10iter: 1.4535 sec.\n",
      "Iter 5580 || Loss: 3.6695 || 10iter: 1.4506 sec.\n",
      "Iter 5590 || Loss: 4.0877 || 10iter: 1.3734 sec.\n",
      "Iter 5600 || Loss: 4.1738 || 10iter: 1.4080 sec.\n",
      "Iter 5610 || Loss: 4.3432 || 10iter: 1.4254 sec.\n",
      "Iter 5620 || Loss: 3.5003 || 10iter: 1.3670 sec.\n",
      "Iter 5630 || Loss: 3.6132 || 10iter: 1.4152 sec.\n",
      "Iter 5640 || Loss: 3.8148 || 10iter: 1.4501 sec.\n",
      "Iter 5650 || Loss: 4.0367 || 10iter: 1.4227 sec.\n",
      "Iter 5660 || Loss: 3.9660 || 10iter: 1.3893 sec.\n",
      "Iter 5670 || Loss: 4.5214 || 10iter: 1.4831 sec.\n",
      "Iter 5680 || Loss: 4.5838 || 10iter: 1.4464 sec.\n",
      "Iter 5690 || Loss: 4.2297 || 10iter: 1.4295 sec.\n",
      "Iter 5700 || Loss: 3.6111 || 10iter: 1.4325 sec.\n",
      "Iter 5710 || Loss: 3.7454 || 10iter: 1.4134 sec.\n",
      "Iter 5720 || Loss: 3.5318 || 10iter: 1.4382 sec.\n",
      "Iter 5730 || Loss: 3.5879 || 10iter: 1.4091 sec.\n",
      "Iter 5740 || Loss: 4.1579 || 10iter: 1.4929 sec.\n",
      "Iter 5750 || Loss: 4.7334 || 10iter: 1.4775 sec.\n",
      "Iter 5760 || Loss: 4.3411 || 10iter: 1.4413 sec.\n",
      "Iter 5770 || Loss: 4.1750 || 10iter: 1.4265 sec.\n",
      "Iter 5780 || Loss: 4.0804 || 10iter: 1.4299 sec.\n",
      "Iter 5790 || Loss: 4.5487 || 10iter: 1.4194 sec.\n",
      "Iter 5800 || Loss: 3.8877 || 10iter: 1.4215 sec.\n",
      "Iter 5810 || Loss: 3.6277 || 10iter: 1.4135 sec.\n",
      "Iter 5820 || Loss: 3.7211 || 10iter: 1.4295 sec.\n",
      "Iter 5830 || Loss: 3.9853 || 10iter: 1.4514 sec.\n",
      "Iter 5840 || Loss: 4.1438 || 10iter: 1.4545 sec.\n",
      "Iter 5850 || Loss: 3.9416 || 10iter: 1.4210 sec.\n",
      "Iter 5860 || Loss: 4.7592 || 10iter: 1.3869 sec.\n",
      "Iter 5870 || Loss: 4.0491 || 10iter: 1.4831 sec.\n",
      "Iter 5880 || Loss: 3.7150 || 10iter: 1.4771 sec.\n",
      "Iter 5890 || Loss: 4.2264 || 10iter: 1.4425 sec.\n",
      "Iter 5900 || Loss: 4.7396 || 10iter: 1.4873 sec.\n",
      "Iter 5910 || Loss: 3.7508 || 10iter: 1.4605 sec.\n",
      "Iter 5920 || Loss: 4.2945 || 10iter: 1.4107 sec.\n",
      "Iter 5930 || Loss: 3.9128 || 10iter: 1.4946 sec.\n",
      "Iter 5940 || Loss: 3.6739 || 10iter: 1.5143 sec.\n",
      "Iter 5950 || Loss: 3.9760 || 10iter: 1.4598 sec.\n",
      "Iter 5960 || Loss: 4.4793 || 10iter: 1.4183 sec.\n",
      "Iter 5970 || Loss: 4.0686 || 10iter: 1.4605 sec.\n",
      "Iter 5980 || Loss: 3.7403 || 10iter: 1.4514 sec.\n",
      "Iter 5990 || Loss: 4.1755 || 10iter: 1.3941 sec.\n",
      "Iter 6000 || Loss: 3.6517 || 10iter: 1.4177 sec.\n",
      "Iter 6010 || Loss: 4.5885 || 10iter: 1.4131 sec.\n",
      "Iter 6020 || Loss: 4.2217 || 10iter: 1.3637 sec.\n",
      "Iter 6030 || Loss: 4.3108 || 10iter: 1.4153 sec.\n",
      "Iter 6040 || Loss: 3.6375 || 10iter: 1.4550 sec.\n",
      "Iter 6050 || Loss: 4.4202 || 10iter: 1.4254 sec.\n",
      "Iter 6060 || Loss: 4.2765 || 10iter: 1.4182 sec.\n",
      "Iter 6070 || Loss: 3.9148 || 10iter: 1.4041 sec.\n",
      "Iter 6080 || Loss: 3.9356 || 10iter: 1.4346 sec.\n",
      "Iter 6090 || Loss: 3.9101 || 10iter: 1.4499 sec.\n",
      "Iter 6100 || Loss: 4.2558 || 10iter: 1.4698 sec.\n",
      "Iter 6110 || Loss: 3.5653 || 10iter: 1.4218 sec.\n",
      "Iter 6120 || Loss: 4.1893 || 10iter: 1.3706 sec.\n",
      "Iter 6130 || Loss: 3.9634 || 10iter: 1.3939 sec.\n",
      "Iter 6140 || Loss: 4.1422 || 10iter: 1.4165 sec.\n",
      "Iter 6150 || Loss: 4.3327 || 10iter: 1.3917 sec.\n",
      "Iter 6160 || Loss: 4.0172 || 10iter: 1.5055 sec.\n",
      "Iter 6170 || Loss: 4.7436 || 10iter: 1.4816 sec.\n",
      "Iter 6180 || Loss: 4.5134 || 10iter: 1.4479 sec.\n",
      "Iter 6190 || Loss: 4.3804 || 10iter: 1.4045 sec.\n",
      "Iter 6200 || Loss: 3.6848 || 10iter: 1.3471 sec.\n",
      "Iter 6210 || Loss: 4.0164 || 10iter: 1.2561 sec.\n",
      "-------------\n",
      "epoch 9 || Epoch_TRAIN_Loss:2811.3147 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  101.9204 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 10/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 6220 || Loss: 4.1448 || 10iter: 2.7411 sec.\n",
      "Iter 6230 || Loss: 4.0359 || 10iter: 1.3547 sec.\n",
      "Iter 6240 || Loss: 3.8775 || 10iter: 1.4188 sec.\n",
      "Iter 6250 || Loss: 4.0881 || 10iter: 1.4401 sec.\n",
      "Iter 6260 || Loss: 4.5408 || 10iter: 1.4027 sec.\n",
      "Iter 6270 || Loss: 3.9605 || 10iter: 1.4324 sec.\n",
      "Iter 6280 || Loss: 3.9293 || 10iter: 1.4410 sec.\n",
      "Iter 6290 || Loss: 4.3010 || 10iter: 1.3880 sec.\n",
      "Iter 6300 || Loss: 3.7109 || 10iter: 1.4316 sec.\n",
      "Iter 6310 || Loss: 4.3053 || 10iter: 1.4097 sec.\n",
      "Iter 6320 || Loss: 4.0837 || 10iter: 1.5078 sec.\n",
      "Iter 6330 || Loss: 4.0388 || 10iter: 1.4480 sec.\n",
      "Iter 6340 || Loss: 4.1054 || 10iter: 1.4241 sec.\n",
      "Iter 6350 || Loss: 4.0586 || 10iter: 1.3896 sec.\n",
      "Iter 6360 || Loss: 3.7989 || 10iter: 1.4414 sec.\n",
      "Iter 6370 || Loss: 5.2839 || 10iter: 1.4742 sec.\n",
      "Iter 6380 || Loss: 3.9595 || 10iter: 1.4682 sec.\n",
      "Iter 6390 || Loss: 3.7871 || 10iter: 1.4090 sec.\n",
      "Iter 6400 || Loss: 4.6947 || 10iter: 1.4124 sec.\n",
      "Iter 6410 || Loss: 3.5389 || 10iter: 1.4639 sec.\n",
      "Iter 6420 || Loss: 4.0860 || 10iter: 1.4672 sec.\n",
      "Iter 6430 || Loss: 3.8523 || 10iter: 1.4996 sec.\n",
      "Iter 6440 || Loss: 4.0026 || 10iter: 1.4655 sec.\n",
      "Iter 6450 || Loss: 3.6558 || 10iter: 1.4019 sec.\n",
      "Iter 6460 || Loss: 4.3813 || 10iter: 1.4445 sec.\n",
      "Iter 6470 || Loss: 3.9265 || 10iter: 1.4402 sec.\n",
      "Iter 6480 || Loss: 3.2822 || 10iter: 1.4705 sec.\n",
      "Iter 6490 || Loss: 4.1875 || 10iter: 1.4572 sec.\n",
      "Iter 6500 || Loss: 3.5943 || 10iter: 1.4149 sec.\n",
      "Iter 6510 || Loss: 4.6300 || 10iter: 1.4546 sec.\n",
      "Iter 6520 || Loss: 3.8090 || 10iter: 1.4804 sec.\n",
      "Iter 6530 || Loss: 4.1140 || 10iter: 1.4215 sec.\n",
      "Iter 6540 || Loss: 3.5677 || 10iter: 1.4071 sec.\n",
      "Iter 6550 || Loss: 3.8010 || 10iter: 1.4440 sec.\n",
      "Iter 6560 || Loss: 3.9612 || 10iter: 1.4529 sec.\n",
      "Iter 6570 || Loss: 4.4308 || 10iter: 1.4907 sec.\n",
      "Iter 6580 || Loss: 4.6116 || 10iter: 1.4919 sec.\n",
      "Iter 6590 || Loss: 4.0677 || 10iter: 1.3922 sec.\n",
      "Iter 6600 || Loss: 4.1981 || 10iter: 1.4306 sec.\n",
      "Iter 6610 || Loss: 4.1342 || 10iter: 1.4046 sec.\n",
      "Iter 6620 || Loss: 4.3506 || 10iter: 1.4308 sec.\n",
      "Iter 6630 || Loss: 4.2733 || 10iter: 1.4601 sec.\n",
      "Iter 6640 || Loss: 4.6440 || 10iter: 1.4008 sec.\n",
      "Iter 6650 || Loss: 4.3789 || 10iter: 1.4197 sec.\n",
      "Iter 6660 || Loss: 3.6382 || 10iter: 1.4464 sec.\n",
      "Iter 6670 || Loss: 3.7858 || 10iter: 1.4596 sec.\n",
      "Iter 6680 || Loss: 4.1609 || 10iter: 1.3869 sec.\n",
      "Iter 6690 || Loss: 4.5864 || 10iter: 1.4266 sec.\n",
      "Iter 6700 || Loss: 3.9262 || 10iter: 1.4353 sec.\n",
      "Iter 6710 || Loss: 3.4644 || 10iter: 1.4079 sec.\n",
      "Iter 6720 || Loss: 4.4806 || 10iter: 1.4174 sec.\n",
      "Iter 6730 || Loss: 3.3827 || 10iter: 1.3994 sec.\n",
      "Iter 6740 || Loss: 3.7824 || 10iter: 1.4315 sec.\n",
      "Iter 6750 || Loss: 4.0539 || 10iter: 1.4364 sec.\n",
      "Iter 6760 || Loss: 4.7572 || 10iter: 1.5083 sec.\n",
      "Iter 6770 || Loss: 3.7978 || 10iter: 1.4136 sec.\n",
      "Iter 6780 || Loss: 4.2105 || 10iter: 1.4235 sec.\n",
      "Iter 6790 || Loss: 3.6559 || 10iter: 1.4213 sec.\n",
      "Iter 6800 || Loss: 3.6793 || 10iter: 1.4190 sec.\n",
      "Iter 6810 || Loss: 3.4681 || 10iter: 1.4314 sec.\n",
      "Iter 6820 || Loss: 3.9649 || 10iter: 1.4510 sec.\n",
      "Iter 6830 || Loss: 4.3941 || 10iter: 1.4770 sec.\n",
      "Iter 6840 || Loss: 3.8803 || 10iter: 1.4909 sec.\n",
      "Iter 6850 || Loss: 3.9194 || 10iter: 1.4085 sec.\n",
      "Iter 6860 || Loss: 4.6808 || 10iter: 1.3733 sec.\n",
      "Iter 6870 || Loss: 3.9351 || 10iter: 1.4528 sec.\n",
      "Iter 6880 || Loss: 4.0644 || 10iter: 1.4363 sec.\n",
      "Iter 6890 || Loss: 4.4968 || 10iter: 1.3689 sec.\n",
      "Iter 6900 || Loss: 3.7782 || 10iter: 1.2534 sec.\n",
      "-------------\n",
      "(val)\n",
      "-------------\n",
      "epoch 10 || Epoch_TRAIN_Loss:2780.9595 ||Epoch_VAL_Loss:796.4889\n",
      "timer:  120.0997 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 11/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 6910 || Loss: 4.1175 || 10iter: 2.7128 sec.\n",
      "Iter 6920 || Loss: 3.5287 || 10iter: 1.3954 sec.\n",
      "Iter 6930 || Loss: 4.2916 || 10iter: 1.4300 sec.\n",
      "Iter 6940 || Loss: 3.7238 || 10iter: 1.4071 sec.\n",
      "Iter 6950 || Loss: 4.2415 || 10iter: 1.3908 sec.\n",
      "Iter 6960 || Loss: 3.7882 || 10iter: 1.3974 sec.\n",
      "Iter 6970 || Loss: 3.1538 || 10iter: 1.4320 sec.\n",
      "Iter 6980 || Loss: 3.7232 || 10iter: 1.4006 sec.\n",
      "Iter 6990 || Loss: 3.6143 || 10iter: 1.4834 sec.\n",
      "Iter 7000 || Loss: 4.2220 || 10iter: 1.5163 sec.\n",
      "Iter 7010 || Loss: 4.3354 || 10iter: 1.4675 sec.\n",
      "Iter 7020 || Loss: 3.8238 || 10iter: 1.4507 sec.\n",
      "Iter 7030 || Loss: 3.7278 || 10iter: 1.4130 sec.\n",
      "Iter 7040 || Loss: 3.8182 || 10iter: 1.4266 sec.\n",
      "Iter 7050 || Loss: 3.8434 || 10iter: 1.4079 sec.\n",
      "Iter 7060 || Loss: 3.9209 || 10iter: 1.4644 sec.\n",
      "Iter 7070 || Loss: 3.7754 || 10iter: 1.4540 sec.\n",
      "Iter 7080 || Loss: 4.0364 || 10iter: 1.4567 sec.\n",
      "Iter 7090 || Loss: 4.5976 || 10iter: 1.4244 sec.\n",
      "Iter 7100 || Loss: 3.9695 || 10iter: 1.4449 sec.\n",
      "Iter 7110 || Loss: 3.6050 || 10iter: 1.4283 sec.\n",
      "Iter 7120 || Loss: 4.2670 || 10iter: 1.4421 sec.\n",
      "Iter 7130 || Loss: 3.8163 || 10iter: 1.4703 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7140 || Loss: 4.6483 || 10iter: 1.5041 sec.\n",
      "Iter 7150 || Loss: 3.7236 || 10iter: 1.4328 sec.\n",
      "Iter 7160 || Loss: 3.8499 || 10iter: 1.3907 sec.\n",
      "Iter 7170 || Loss: 3.9485 || 10iter: 1.4429 sec.\n",
      "Iter 7180 || Loss: 4.0420 || 10iter: 1.4592 sec.\n",
      "Iter 7190 || Loss: 4.2499 || 10iter: 1.4048 sec.\n",
      "Iter 7200 || Loss: 4.5529 || 10iter: 1.3983 sec.\n",
      "Iter 7210 || Loss: 3.8654 || 10iter: 1.4178 sec.\n",
      "Iter 7220 || Loss: 3.6709 || 10iter: 1.4989 sec.\n",
      "Iter 7230 || Loss: 3.8606 || 10iter: 1.3819 sec.\n",
      "Iter 7240 || Loss: 4.5533 || 10iter: 1.4815 sec.\n",
      "Iter 7250 || Loss: 3.8362 || 10iter: 1.4892 sec.\n",
      "Iter 7260 || Loss: 4.2666 || 10iter: 1.4364 sec.\n",
      "Iter 7270 || Loss: 4.0060 || 10iter: 1.3931 sec.\n",
      "Iter 7280 || Loss: 3.9244 || 10iter: 1.4612 sec.\n",
      "Iter 7290 || Loss: 4.0875 || 10iter: 1.4243 sec.\n",
      "Iter 7300 || Loss: 4.1049 || 10iter: 1.4152 sec.\n",
      "Iter 7310 || Loss: 4.0240 || 10iter: 1.4510 sec.\n",
      "Iter 7320 || Loss: 3.8090 || 10iter: 1.4252 sec.\n",
      "Iter 7330 || Loss: 4.0534 || 10iter: 1.4547 sec.\n",
      "Iter 7340 || Loss: 3.9762 || 10iter: 1.4275 sec.\n",
      "Iter 7350 || Loss: 3.5465 || 10iter: 1.4170 sec.\n",
      "Iter 7360 || Loss: 3.6779 || 10iter: 1.4835 sec.\n",
      "Iter 7370 || Loss: 3.9022 || 10iter: 1.4060 sec.\n",
      "Iter 7380 || Loss: 4.1280 || 10iter: 1.4206 sec.\n",
      "Iter 7390 || Loss: 4.1224 || 10iter: 1.3729 sec.\n",
      "Iter 7400 || Loss: 4.0468 || 10iter: 1.4651 sec.\n",
      "Iter 7410 || Loss: 4.1969 || 10iter: 1.4084 sec.\n",
      "Iter 7420 || Loss: 3.6770 || 10iter: 1.4248 sec.\n",
      "Iter 7430 || Loss: 4.2133 || 10iter: 1.5040 sec.\n",
      "Iter 7440 || Loss: 3.8734 || 10iter: 1.4678 sec.\n",
      "Iter 7450 || Loss: 3.3176 || 10iter: 1.4568 sec.\n",
      "Iter 7460 || Loss: 3.9261 || 10iter: 1.4268 sec.\n",
      "Iter 7470 || Loss: 3.7607 || 10iter: 1.4653 sec.\n",
      "Iter 7480 || Loss: 3.9769 || 10iter: 1.4081 sec.\n",
      "Iter 7490 || Loss: 3.4405 || 10iter: 1.4404 sec.\n",
      "Iter 7500 || Loss: 4.3507 || 10iter: 1.4380 sec.\n",
      "Iter 7510 || Loss: 4.3704 || 10iter: 1.4944 sec.\n",
      "Iter 7520 || Loss: 3.6634 || 10iter: 1.4411 sec.\n",
      "Iter 7530 || Loss: 4.6457 || 10iter: 1.4881 sec.\n",
      "Iter 7540 || Loss: 4.0035 || 10iter: 1.4473 sec.\n",
      "Iter 7550 || Loss: 4.7936 || 10iter: 1.4577 sec.\n",
      "Iter 7560 || Loss: 3.9835 || 10iter: 1.4134 sec.\n",
      "Iter 7570 || Loss: 4.0637 || 10iter: 1.4245 sec.\n",
      "Iter 7580 || Loss: 4.0815 || 10iter: 1.3459 sec.\n",
      "Iter 7590 || Loss: 4.1061 || 10iter: 1.2806 sec.\n",
      "-------------\n",
      "epoch 11 || Epoch_TRAIN_Loss:2738.1785 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.4789 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 12/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 7600 || Loss: 3.3900 || 10iter: 2.6723 sec.\n",
      "Iter 7610 || Loss: 4.0365 || 10iter: 1.4063 sec.\n",
      "Iter 7620 || Loss: 3.5373 || 10iter: 1.3988 sec.\n",
      "Iter 7630 || Loss: 3.6040 || 10iter: 1.4300 sec.\n",
      "Iter 7640 || Loss: 3.7043 || 10iter: 1.3923 sec.\n",
      "Iter 7650 || Loss: 4.0691 || 10iter: 1.3892 sec.\n",
      "Iter 7660 || Loss: 3.9406 || 10iter: 1.4259 sec.\n",
      "Iter 7670 || Loss: 3.6569 || 10iter: 1.4426 sec.\n",
      "Iter 7680 || Loss: 3.5644 || 10iter: 1.3993 sec.\n",
      "Iter 7690 || Loss: 3.8646 || 10iter: 1.4209 sec.\n",
      "Iter 7700 || Loss: 4.3033 || 10iter: 1.4643 sec.\n",
      "Iter 7710 || Loss: 4.5386 || 10iter: 1.4517 sec.\n",
      "Iter 7720 || Loss: 4.1024 || 10iter: 1.4462 sec.\n",
      "Iter 7730 || Loss: 3.6252 || 10iter: 1.3797 sec.\n",
      "Iter 7740 || Loss: 4.1008 || 10iter: 1.4419 sec.\n",
      "Iter 7750 || Loss: 4.2496 || 10iter: 1.4050 sec.\n",
      "Iter 7760 || Loss: 4.3281 || 10iter: 1.4106 sec.\n",
      "Iter 7770 || Loss: 3.7569 || 10iter: 1.4352 sec.\n",
      "Iter 7780 || Loss: 3.9221 || 10iter: 1.3830 sec.\n",
      "Iter 7790 || Loss: 3.5442 || 10iter: 1.4809 sec.\n",
      "Iter 7800 || Loss: 3.5842 || 10iter: 1.4550 sec.\n",
      "Iter 7810 || Loss: 3.7926 || 10iter: 1.4320 sec.\n",
      "Iter 7820 || Loss: 4.1995 || 10iter: 1.4669 sec.\n",
      "Iter 7830 || Loss: 4.0463 || 10iter: 1.4829 sec.\n",
      "Iter 7840 || Loss: 4.6571 || 10iter: 1.4828 sec.\n",
      "Iter 7850 || Loss: 4.2170 || 10iter: 1.4808 sec.\n",
      "Iter 7860 || Loss: 3.7130 || 10iter: 1.4374 sec.\n",
      "Iter 7870 || Loss: 3.7239 || 10iter: 1.4448 sec.\n",
      "Iter 7880 || Loss: 3.7590 || 10iter: 1.4064 sec.\n",
      "Iter 7890 || Loss: 4.1976 || 10iter: 1.4353 sec.\n",
      "Iter 7900 || Loss: 4.5161 || 10iter: 1.4551 sec.\n",
      "Iter 7910 || Loss: 3.9305 || 10iter: 1.3822 sec.\n",
      "Iter 7920 || Loss: 3.4895 || 10iter: 1.4627 sec.\n",
      "Iter 7930 || Loss: 3.8582 || 10iter: 1.4109 sec.\n",
      "Iter 7940 || Loss: 3.0565 || 10iter: 1.4664 sec.\n",
      "Iter 7950 || Loss: 3.9385 || 10iter: 1.4389 sec.\n",
      "Iter 7960 || Loss: 3.9213 || 10iter: 1.3857 sec.\n",
      "Iter 7970 || Loss: 3.8063 || 10iter: 1.3851 sec.\n",
      "Iter 7980 || Loss: 4.4328 || 10iter: 1.4537 sec.\n",
      "Iter 7990 || Loss: 4.1960 || 10iter: 1.4742 sec.\n",
      "Iter 8000 || Loss: 3.7708 || 10iter: 1.4181 sec.\n",
      "Iter 8010 || Loss: 4.2942 || 10iter: 1.4561 sec.\n",
      "Iter 8020 || Loss: 3.6119 || 10iter: 1.4404 sec.\n",
      "Iter 8030 || Loss: 3.6346 || 10iter: 1.4120 sec.\n",
      "Iter 8040 || Loss: 4.2876 || 10iter: 1.4396 sec.\n",
      "Iter 8050 || Loss: 3.9273 || 10iter: 1.4713 sec.\n",
      "Iter 8060 || Loss: 4.8559 || 10iter: 1.4352 sec.\n",
      "Iter 8070 || Loss: 3.8330 || 10iter: 1.4111 sec.\n",
      "Iter 8080 || Loss: 4.1018 || 10iter: 1.4399 sec.\n",
      "Iter 8090 || Loss: 4.1210 || 10iter: 1.4309 sec.\n",
      "Iter 8100 || Loss: 4.1910 || 10iter: 1.4641 sec.\n",
      "Iter 8110 || Loss: 3.6881 || 10iter: 1.4460 sec.\n",
      "Iter 8120 || Loss: 3.5663 || 10iter: 1.4359 sec.\n",
      "Iter 8130 || Loss: 3.6873 || 10iter: 1.4513 sec.\n",
      "Iter 8140 || Loss: 3.0893 || 10iter: 1.4078 sec.\n",
      "Iter 8150 || Loss: 4.1367 || 10iter: 1.4454 sec.\n",
      "Iter 8160 || Loss: 3.5649 || 10iter: 1.4317 sec.\n",
      "Iter 8170 || Loss: 4.5082 || 10iter: 1.4399 sec.\n",
      "Iter 8180 || Loss: 3.7219 || 10iter: 1.4226 sec.\n",
      "Iter 8190 || Loss: 4.6211 || 10iter: 1.4076 sec.\n",
      "Iter 8200 || Loss: 4.3475 || 10iter: 1.4423 sec.\n",
      "Iter 8210 || Loss: 3.7118 || 10iter: 1.4472 sec.\n",
      "Iter 8220 || Loss: 4.0277 || 10iter: 1.5467 sec.\n",
      "Iter 8230 || Loss: 3.6919 || 10iter: 1.4888 sec.\n",
      "Iter 8240 || Loss: 4.6524 || 10iter: 1.4141 sec.\n",
      "Iter 8250 || Loss: 4.0232 || 10iter: 1.4191 sec.\n",
      "Iter 8260 || Loss: 3.9670 || 10iter: 1.4429 sec.\n",
      "Iter 8270 || Loss: 4.6165 || 10iter: 1.3756 sec.\n",
      "Iter 8280 || Loss: 3.9579 || 10iter: 1.2592 sec.\n",
      "-------------\n",
      "epoch 12 || Epoch_TRAIN_Loss:2702.4204 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.1848 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 13/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 8290 || Loss: 4.0374 || 10iter: 2.7515 sec.\n",
      "Iter 8300 || Loss: 4.7139 || 10iter: 1.3176 sec.\n",
      "Iter 8310 || Loss: 4.3828 || 10iter: 1.4026 sec.\n",
      "Iter 8320 || Loss: 3.9942 || 10iter: 1.3990 sec.\n",
      "Iter 8330 || Loss: 3.5247 || 10iter: 1.4258 sec.\n",
      "Iter 8340 || Loss: 3.7466 || 10iter: 1.4313 sec.\n",
      "Iter 8350 || Loss: 4.6479 || 10iter: 1.4070 sec.\n",
      "Iter 8360 || Loss: 3.8994 || 10iter: 1.4357 sec.\n",
      "Iter 8370 || Loss: 3.7290 || 10iter: 1.4185 sec.\n",
      "Iter 8380 || Loss: 4.0532 || 10iter: 1.4910 sec.\n",
      "Iter 8390 || Loss: 3.4850 || 10iter: 1.4671 sec.\n",
      "Iter 8400 || Loss: 3.8083 || 10iter: 1.4255 sec.\n",
      "Iter 8410 || Loss: 3.4012 || 10iter: 1.4041 sec.\n",
      "Iter 8420 || Loss: 3.5855 || 10iter: 1.4197 sec.\n",
      "Iter 8430 || Loss: 3.8017 || 10iter: 1.4193 sec.\n",
      "Iter 8440 || Loss: 3.9082 || 10iter: 1.4299 sec.\n",
      "Iter 8450 || Loss: 3.1477 || 10iter: 1.4954 sec.\n",
      "Iter 8460 || Loss: 3.6523 || 10iter: 1.4654 sec.\n",
      "Iter 8470 || Loss: 4.1528 || 10iter: 1.4327 sec.\n",
      "Iter 8480 || Loss: 3.9936 || 10iter: 1.4556 sec.\n",
      "Iter 8490 || Loss: 4.2570 || 10iter: 1.4219 sec.\n",
      "Iter 8500 || Loss: 3.6761 || 10iter: 1.4928 sec.\n",
      "Iter 8510 || Loss: 3.8364 || 10iter: 1.4533 sec.\n",
      "Iter 8520 || Loss: 4.2000 || 10iter: 1.4920 sec.\n",
      "Iter 8530 || Loss: 3.8829 || 10iter: 1.4316 sec.\n",
      "Iter 8540 || Loss: 3.6246 || 10iter: 1.4345 sec.\n",
      "Iter 8550 || Loss: 3.5275 || 10iter: 1.4135 sec.\n",
      "Iter 8560 || Loss: 4.3405 || 10iter: 1.4042 sec.\n",
      "Iter 8570 || Loss: 3.7047 || 10iter: 1.4703 sec.\n",
      "Iter 8580 || Loss: 4.1149 || 10iter: 1.4290 sec.\n",
      "Iter 8590 || Loss: 4.0103 || 10iter: 1.5322 sec.\n",
      "Iter 8600 || Loss: 4.6331 || 10iter: 1.4745 sec.\n",
      "Iter 8610 || Loss: 4.2262 || 10iter: 1.3943 sec.\n",
      "Iter 8620 || Loss: 3.5480 || 10iter: 1.4455 sec.\n",
      "Iter 8630 || Loss: 3.9991 || 10iter: 1.4115 sec.\n",
      "Iter 8640 || Loss: 3.6470 || 10iter: 1.4472 sec.\n",
      "Iter 8650 || Loss: 4.0261 || 10iter: 1.4448 sec.\n",
      "Iter 8660 || Loss: 4.2443 || 10iter: 1.4061 sec.\n",
      "Iter 8670 || Loss: 3.8129 || 10iter: 1.4893 sec.\n",
      "Iter 8680 || Loss: 3.7584 || 10iter: 1.4156 sec.\n",
      "Iter 8690 || Loss: 3.9186 || 10iter: 1.3975 sec.\n",
      "Iter 8700 || Loss: 4.0252 || 10iter: 1.4542 sec.\n",
      "Iter 8710 || Loss: 3.7242 || 10iter: 1.4208 sec.\n",
      "Iter 8720 || Loss: 3.9367 || 10iter: 1.4413 sec.\n",
      "Iter 8730 || Loss: 3.6458 || 10iter: 1.4470 sec.\n",
      "Iter 8740 || Loss: 3.9626 || 10iter: 1.4046 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8750 || Loss: 3.5880 || 10iter: 1.3984 sec.\n",
      "Iter 8760 || Loss: 4.3141 || 10iter: 1.4397 sec.\n",
      "Iter 8770 || Loss: 4.0955 || 10iter: 1.4113 sec.\n",
      "Iter 8780 || Loss: 3.6998 || 10iter: 1.3620 sec.\n",
      "Iter 8790 || Loss: 4.1088 || 10iter: 1.4730 sec.\n",
      "Iter 8800 || Loss: 4.1670 || 10iter: 1.4591 sec.\n",
      "Iter 8810 || Loss: 5.0476 || 10iter: 1.4160 sec.\n",
      "Iter 8820 || Loss: 3.7472 || 10iter: 1.4053 sec.\n",
      "Iter 8830 || Loss: 4.0829 || 10iter: 1.4948 sec.\n",
      "Iter 8840 || Loss: 3.6424 || 10iter: 1.4307 sec.\n",
      "Iter 8850 || Loss: 3.6773 || 10iter: 1.4146 sec.\n",
      "Iter 8860 || Loss: 3.9882 || 10iter: 1.4064 sec.\n",
      "Iter 8870 || Loss: 3.5894 || 10iter: 1.4212 sec.\n",
      "Iter 8880 || Loss: 4.0267 || 10iter: 1.4641 sec.\n",
      "Iter 8890 || Loss: 3.6033 || 10iter: 1.4482 sec.\n",
      "Iter 8900 || Loss: 3.5607 || 10iter: 1.4185 sec.\n",
      "Iter 8910 || Loss: 4.0905 || 10iter: 1.3945 sec.\n",
      "Iter 8920 || Loss: 4.0302 || 10iter: 1.4182 sec.\n",
      "Iter 8930 || Loss: 4.4502 || 10iter: 1.4434 sec.\n",
      "Iter 8940 || Loss: 3.4112 || 10iter: 1.4416 sec.\n",
      "Iter 8950 || Loss: 4.6381 || 10iter: 1.4454 sec.\n",
      "Iter 8960 || Loss: 4.1488 || 10iter: 1.3556 sec.\n",
      "Iter 8970 || Loss: 3.5964 || 10iter: 1.2556 sec.\n",
      "-------------\n",
      "epoch 13 || Epoch_TRAIN_Loss:2673.4656 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.1396 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 14/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 8980 || Loss: 3.1115 || 10iter: 2.7322 sec.\n",
      "Iter 8990 || Loss: 3.6369 || 10iter: 1.3572 sec.\n",
      "Iter 9000 || Loss: 3.8354 || 10iter: 1.4078 sec.\n",
      "Iter 9010 || Loss: 4.1474 || 10iter: 1.4257 sec.\n",
      "Iter 9020 || Loss: 3.8305 || 10iter: 1.3828 sec.\n",
      "Iter 9030 || Loss: 3.7090 || 10iter: 1.3990 sec.\n",
      "Iter 9040 || Loss: 4.1381 || 10iter: 1.3556 sec.\n",
      "Iter 9050 || Loss: 3.5451 || 10iter: 1.4173 sec.\n",
      "Iter 9060 || Loss: 3.2370 || 10iter: 1.4070 sec.\n",
      "Iter 9070 || Loss: 3.6620 || 10iter: 1.4421 sec.\n",
      "Iter 9080 || Loss: 3.4697 || 10iter: 1.4946 sec.\n",
      "Iter 9090 || Loss: 3.6664 || 10iter: 1.4679 sec.\n",
      "Iter 9100 || Loss: 3.6804 || 10iter: 1.3954 sec.\n",
      "Iter 9110 || Loss: 4.3973 || 10iter: 1.4287 sec.\n",
      "Iter 9120 || Loss: 4.0614 || 10iter: 1.4397 sec.\n",
      "Iter 9130 || Loss: 3.6980 || 10iter: 1.4592 sec.\n",
      "Iter 9140 || Loss: 4.1926 || 10iter: 1.4543 sec.\n",
      "Iter 9150 || Loss: 3.8063 || 10iter: 1.4869 sec.\n",
      "Iter 9160 || Loss: 3.9543 || 10iter: 1.4342 sec.\n",
      "Iter 9170 || Loss: 3.3420 || 10iter: 1.4362 sec.\n",
      "Iter 9180 || Loss: 3.8722 || 10iter: 1.4700 sec.\n",
      "Iter 9190 || Loss: 4.2819 || 10iter: 1.4191 sec.\n",
      "Iter 9200 || Loss: 3.8341 || 10iter: 1.4067 sec.\n",
      "Iter 9210 || Loss: 3.7859 || 10iter: 1.4529 sec.\n",
      "Iter 9220 || Loss: 4.2016 || 10iter: 1.4728 sec.\n",
      "Iter 9230 || Loss: 4.6608 || 10iter: 1.4532 sec.\n",
      "Iter 9240 || Loss: 3.6816 || 10iter: 1.4330 sec.\n",
      "Iter 9250 || Loss: 3.8573 || 10iter: 1.4008 sec.\n",
      "Iter 9260 || Loss: 3.3968 || 10iter: 1.4485 sec.\n",
      "Iter 9270 || Loss: 3.6313 || 10iter: 1.4864 sec.\n",
      "Iter 9280 || Loss: 4.8117 || 10iter: 1.5184 sec.\n",
      "Iter 9290 || Loss: 3.8171 || 10iter: 1.4594 sec.\n",
      "Iter 9300 || Loss: 3.7259 || 10iter: 1.4706 sec.\n",
      "Iter 9310 || Loss: 3.4858 || 10iter: 1.4441 sec.\n",
      "Iter 9320 || Loss: 4.2418 || 10iter: 1.3969 sec.\n",
      "Iter 9330 || Loss: 4.1337 || 10iter: 1.3972 sec.\n",
      "Iter 9340 || Loss: 4.0765 || 10iter: 1.4264 sec.\n",
      "Iter 9350 || Loss: 3.8710 || 10iter: 1.4306 sec.\n",
      "Iter 9360 || Loss: 3.7071 || 10iter: 1.4336 sec.\n",
      "Iter 9370 || Loss: 3.5273 || 10iter: 1.3938 sec.\n",
      "Iter 9380 || Loss: 3.5950 || 10iter: 1.4412 sec.\n",
      "Iter 9390 || Loss: 3.8469 || 10iter: 1.4418 sec.\n",
      "Iter 9400 || Loss: 4.5225 || 10iter: 1.4153 sec.\n",
      "Iter 9410 || Loss: 4.0084 || 10iter: 1.3961 sec.\n",
      "Iter 9420 || Loss: 4.0605 || 10iter: 1.5194 sec.\n",
      "Iter 9430 || Loss: 3.3400 || 10iter: 1.5478 sec.\n",
      "Iter 9440 || Loss: 3.7758 || 10iter: 1.4675 sec.\n",
      "Iter 9450 || Loss: 3.8912 || 10iter: 1.4540 sec.\n",
      "Iter 9460 || Loss: 3.3899 || 10iter: 1.4131 sec.\n",
      "Iter 9470 || Loss: 4.1266 || 10iter: 1.4335 sec.\n",
      "Iter 9480 || Loss: 3.7296 || 10iter: 1.5104 sec.\n",
      "Iter 9490 || Loss: 3.9067 || 10iter: 1.4407 sec.\n",
      "Iter 9500 || Loss: 3.1508 || 10iter: 1.4089 sec.\n",
      "Iter 9510 || Loss: 4.1724 || 10iter: 1.4496 sec.\n",
      "Iter 9520 || Loss: 4.3408 || 10iter: 1.3674 sec.\n",
      "Iter 9530 || Loss: 4.4855 || 10iter: 1.3970 sec.\n",
      "Iter 9540 || Loss: 4.2593 || 10iter: 1.4429 sec.\n",
      "Iter 9550 || Loss: 4.2625 || 10iter: 1.4633 sec.\n",
      "Iter 9560 || Loss: 3.7687 || 10iter: 1.4594 sec.\n",
      "Iter 9570 || Loss: 3.7287 || 10iter: 1.4177 sec.\n",
      "Iter 9580 || Loss: 3.6092 || 10iter: 1.3890 sec.\n",
      "Iter 9590 || Loss: 3.5801 || 10iter: 1.4443 sec.\n",
      "Iter 9600 || Loss: 3.6265 || 10iter: 1.4014 sec.\n",
      "Iter 9610 || Loss: 3.8428 || 10iter: 1.4706 sec.\n",
      "Iter 9620 || Loss: 4.3863 || 10iter: 1.4265 sec.\n",
      "Iter 9630 || Loss: 3.8431 || 10iter: 1.4118 sec.\n",
      "Iter 9640 || Loss: 3.6301 || 10iter: 1.4361 sec.\n",
      "Iter 9650 || Loss: 4.1470 || 10iter: 1.3600 sec.\n",
      "Iter 9660 || Loss: 3.9197 || 10iter: 1.2534 sec.\n",
      "-------------\n",
      "epoch 14 || Epoch_TRAIN_Loss:2651.5913 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.2865 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 15/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 9670 || Loss: 3.5891 || 10iter: 2.6938 sec.\n",
      "Iter 9680 || Loss: 3.4155 || 10iter: 1.3561 sec.\n",
      "Iter 9690 || Loss: 3.3389 || 10iter: 1.4240 sec.\n",
      "Iter 9700 || Loss: 4.2231 || 10iter: 1.4442 sec.\n",
      "Iter 9710 || Loss: 3.8791 || 10iter: 1.4395 sec.\n",
      "Iter 9720 || Loss: 3.5781 || 10iter: 1.3852 sec.\n",
      "Iter 9730 || Loss: 3.7353 || 10iter: 1.4161 sec.\n",
      "Iter 9740 || Loss: 3.7947 || 10iter: 1.4449 sec.\n",
      "Iter 9750 || Loss: 3.8615 || 10iter: 1.4394 sec.\n",
      "Iter 9760 || Loss: 4.0220 || 10iter: 1.4152 sec.\n",
      "Iter 9770 || Loss: 4.1531 || 10iter: 1.3982 sec.\n",
      "Iter 9780 || Loss: 3.6102 || 10iter: 1.4539 sec.\n",
      "Iter 9790 || Loss: 3.4966 || 10iter: 1.3963 sec.\n",
      "Iter 9800 || Loss: 4.2867 || 10iter: 1.3840 sec.\n",
      "Iter 9810 || Loss: 4.0571 || 10iter: 1.4170 sec.\n",
      "Iter 9820 || Loss: 3.8912 || 10iter: 1.4760 sec.\n",
      "Iter 9830 || Loss: 3.5633 || 10iter: 1.4523 sec.\n",
      "Iter 9840 || Loss: 3.7366 || 10iter: 1.4369 sec.\n",
      "Iter 9850 || Loss: 3.9439 || 10iter: 1.3880 sec.\n",
      "Iter 9860 || Loss: 3.4609 || 10iter: 1.4209 sec.\n",
      "Iter 9870 || Loss: 3.8245 || 10iter: 1.5257 sec.\n",
      "Iter 9880 || Loss: 3.7444 || 10iter: 1.4490 sec.\n",
      "Iter 9890 || Loss: 3.4585 || 10iter: 1.4311 sec.\n",
      "Iter 9900 || Loss: 3.4771 || 10iter: 1.4615 sec.\n",
      "Iter 9910 || Loss: 4.6135 || 10iter: 1.4502 sec.\n",
      "Iter 9920 || Loss: 3.4305 || 10iter: 1.3976 sec.\n",
      "Iter 9930 || Loss: 4.4085 || 10iter: 1.4713 sec.\n",
      "Iter 9940 || Loss: 3.6048 || 10iter: 1.4184 sec.\n",
      "Iter 9950 || Loss: 3.7358 || 10iter: 1.4510 sec.\n",
      "Iter 9960 || Loss: 3.9120 || 10iter: 1.4046 sec.\n",
      "Iter 9970 || Loss: 4.1922 || 10iter: 1.4702 sec.\n",
      "Iter 9980 || Loss: 3.5062 || 10iter: 1.4283 sec.\n",
      "Iter 9990 || Loss: 3.3628 || 10iter: 1.4313 sec.\n",
      "Iter 10000 || Loss: 3.0311 || 10iter: 1.4424 sec.\n",
      "Iter 10010 || Loss: 3.4355 || 10iter: 1.4465 sec.\n",
      "Iter 10020 || Loss: 3.7457 || 10iter: 1.4311 sec.\n",
      "Iter 10030 || Loss: 3.9082 || 10iter: 1.4226 sec.\n",
      "Iter 10040 || Loss: 3.5286 || 10iter: 1.4260 sec.\n",
      "Iter 10050 || Loss: 4.1123 || 10iter: 1.3931 sec.\n",
      "Iter 10060 || Loss: 3.6488 || 10iter: 1.4591 sec.\n",
      "Iter 10070 || Loss: 4.1450 || 10iter: 1.4045 sec.\n",
      "Iter 10080 || Loss: 2.9698 || 10iter: 1.4271 sec.\n",
      "Iter 10090 || Loss: 3.3800 || 10iter: 1.4486 sec.\n",
      "Iter 10100 || Loss: 3.9531 || 10iter: 1.4485 sec.\n",
      "Iter 10110 || Loss: 3.7571 || 10iter: 1.4680 sec.\n",
      "Iter 10120 || Loss: 3.5794 || 10iter: 1.4399 sec.\n",
      "Iter 10130 || Loss: 4.1060 || 10iter: 1.4189 sec.\n",
      "Iter 10140 || Loss: 4.1760 || 10iter: 1.4337 sec.\n",
      "Iter 10150 || Loss: 3.3256 || 10iter: 1.4561 sec.\n",
      "Iter 10160 || Loss: 3.7792 || 10iter: 1.4069 sec.\n",
      "Iter 10170 || Loss: 3.6053 || 10iter: 1.3793 sec.\n",
      "Iter 10180 || Loss: 3.2377 || 10iter: 1.4382 sec.\n",
      "Iter 10190 || Loss: 3.4624 || 10iter: 1.4447 sec.\n",
      "Iter 10200 || Loss: 3.9227 || 10iter: 1.4753 sec.\n",
      "Iter 10210 || Loss: 4.0343 || 10iter: 1.4706 sec.\n",
      "Iter 10220 || Loss: 4.0763 || 10iter: 1.4196 sec.\n",
      "Iter 10230 || Loss: 3.5854 || 10iter: 1.3891 sec.\n",
      "Iter 10240 || Loss: 3.8877 || 10iter: 1.4597 sec.\n",
      "Iter 10250 || Loss: 3.4715 || 10iter: 1.3895 sec.\n",
      "Iter 10260 || Loss: 3.8427 || 10iter: 1.4284 sec.\n",
      "Iter 10270 || Loss: 3.4471 || 10iter: 1.3940 sec.\n",
      "Iter 10280 || Loss: 4.6279 || 10iter: 1.4114 sec.\n",
      "Iter 10290 || Loss: 4.3264 || 10iter: 1.5027 sec.\n",
      "Iter 10300 || Loss: 3.8634 || 10iter: 1.4431 sec.\n",
      "Iter 10310 || Loss: 3.5063 || 10iter: 1.4137 sec.\n",
      "Iter 10320 || Loss: 3.1409 || 10iter: 1.4830 sec.\n",
      "Iter 10330 || Loss: 4.1709 || 10iter: 1.4664 sec.\n",
      "Iter 10340 || Loss: 3.6381 || 10iter: 1.3465 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10350 || Loss: 3.5312 || 10iter: 1.2590 sec.\n",
      "-------------\n",
      "epoch 15 || Epoch_TRAIN_Loss:2624.0052 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  101.9795 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 16/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 10360 || Loss: 3.4463 || 10iter: 2.7430 sec.\n",
      "Iter 10370 || Loss: 4.2109 || 10iter: 1.4140 sec.\n",
      "Iter 10380 || Loss: 3.7024 || 10iter: 1.4895 sec.\n",
      "Iter 10390 || Loss: 3.5558 || 10iter: 1.3590 sec.\n",
      "Iter 10400 || Loss: 3.8585 || 10iter: 1.4462 sec.\n",
      "Iter 10410 || Loss: 4.0474 || 10iter: 1.4776 sec.\n",
      "Iter 10420 || Loss: 3.8031 || 10iter: 1.3825 sec.\n",
      "Iter 10430 || Loss: 4.2866 || 10iter: 1.4374 sec.\n",
      "Iter 10440 || Loss: 3.6566 || 10iter: 1.4137 sec.\n",
      "Iter 10450 || Loss: 4.0127 || 10iter: 1.4598 sec.\n",
      "Iter 10460 || Loss: 3.7038 || 10iter: 1.4144 sec.\n",
      "Iter 10470 || Loss: 3.9162 || 10iter: 1.4569 sec.\n",
      "Iter 10480 || Loss: 4.0726 || 10iter: 1.4472 sec.\n",
      "Iter 10490 || Loss: 3.5154 || 10iter: 1.4126 sec.\n",
      "Iter 10500 || Loss: 3.7611 || 10iter: 1.4085 sec.\n",
      "Iter 10510 || Loss: 3.3622 || 10iter: 1.4325 sec.\n",
      "Iter 10520 || Loss: 3.1263 || 10iter: 1.4296 sec.\n",
      "Iter 10530 || Loss: 3.7457 || 10iter: 1.4039 sec.\n",
      "Iter 10540 || Loss: 3.5115 || 10iter: 1.4280 sec.\n",
      "Iter 10550 || Loss: 3.7206 || 10iter: 1.4467 sec.\n",
      "Iter 10560 || Loss: 3.5421 || 10iter: 1.4550 sec.\n",
      "Iter 10570 || Loss: 4.3007 || 10iter: 1.4509 sec.\n",
      "Iter 10580 || Loss: 4.4555 || 10iter: 1.4104 sec.\n",
      "Iter 10590 || Loss: 3.3748 || 10iter: 1.4153 sec.\n",
      "Iter 10600 || Loss: 3.6189 || 10iter: 1.4018 sec.\n",
      "Iter 10610 || Loss: 4.1489 || 10iter: 1.4313 sec.\n",
      "Iter 10620 || Loss: 3.7330 || 10iter: 1.4271 sec.\n",
      "Iter 10630 || Loss: 4.4596 || 10iter: 1.4752 sec.\n",
      "Iter 10640 || Loss: 4.0578 || 10iter: 1.4674 sec.\n",
      "Iter 10650 || Loss: 4.2429 || 10iter: 1.5435 sec.\n",
      "Iter 10660 || Loss: 3.8030 || 10iter: 1.5037 sec.\n",
      "Iter 10670 || Loss: 3.7508 || 10iter: 1.4146 sec.\n",
      "Iter 10680 || Loss: 3.6604 || 10iter: 1.4887 sec.\n",
      "Iter 10690 || Loss: 3.7501 || 10iter: 1.4104 sec.\n",
      "Iter 10700 || Loss: 3.8034 || 10iter: 1.4619 sec.\n",
      "Iter 10710 || Loss: 3.9206 || 10iter: 1.4748 sec.\n",
      "Iter 10720 || Loss: 3.3623 || 10iter: 1.3958 sec.\n",
      "Iter 10730 || Loss: 3.3018 || 10iter: 1.3901 sec.\n",
      "Iter 10740 || Loss: 3.9633 || 10iter: 1.4288 sec.\n",
      "Iter 10750 || Loss: 4.0658 || 10iter: 1.4749 sec.\n",
      "Iter 10760 || Loss: 3.1319 || 10iter: 1.4287 sec.\n",
      "Iter 10770 || Loss: 4.1786 || 10iter: 1.4658 sec.\n",
      "Iter 10780 || Loss: 3.4728 || 10iter: 1.4361 sec.\n",
      "Iter 10790 || Loss: 4.5289 || 10iter: 1.4240 sec.\n",
      "Iter 10800 || Loss: 3.3663 || 10iter: 1.4497 sec.\n",
      "Iter 10810 || Loss: 3.7050 || 10iter: 1.4693 sec.\n",
      "Iter 10820 || Loss: 4.1491 || 10iter: 1.4478 sec.\n",
      "Iter 10830 || Loss: 3.9997 || 10iter: 1.4105 sec.\n",
      "Iter 10840 || Loss: 3.5454 || 10iter: 1.4446 sec.\n",
      "Iter 10850 || Loss: 3.8791 || 10iter: 1.5101 sec.\n",
      "Iter 10860 || Loss: 3.7078 || 10iter: 1.4215 sec.\n",
      "Iter 10870 || Loss: 3.3657 || 10iter: 1.4096 sec.\n",
      "Iter 10880 || Loss: 4.5391 || 10iter: 1.4570 sec.\n",
      "Iter 10890 || Loss: 3.7769 || 10iter: 1.4295 sec.\n",
      "Iter 10900 || Loss: 3.2387 || 10iter: 1.4225 sec.\n",
      "Iter 10910 || Loss: 3.7327 || 10iter: 1.4408 sec.\n",
      "Iter 10920 || Loss: 3.8219 || 10iter: 1.4081 sec.\n",
      "Iter 10930 || Loss: 4.1623 || 10iter: 1.4546 sec.\n",
      "Iter 10940 || Loss: 3.6809 || 10iter: 1.4289 sec.\n",
      "Iter 10950 || Loss: 3.4855 || 10iter: 1.4295 sec.\n",
      "Iter 10960 || Loss: 3.2501 || 10iter: 1.4165 sec.\n",
      "Iter 10970 || Loss: 4.0321 || 10iter: 1.4276 sec.\n",
      "Iter 10980 || Loss: 3.7222 || 10iter: 1.3864 sec.\n",
      "Iter 10990 || Loss: 3.4716 || 10iter: 1.4399 sec.\n",
      "Iter 11000 || Loss: 3.9232 || 10iter: 1.4043 sec.\n",
      "Iter 11010 || Loss: 4.2304 || 10iter: 1.4424 sec.\n",
      "Iter 11020 || Loss: 4.1678 || 10iter: 1.3868 sec.\n",
      "Iter 11030 || Loss: 4.1635 || 10iter: 1.3435 sec.\n",
      "Iter 11040 || Loss: 3.3930 || 10iter: 1.2558 sec.\n",
      "-------------\n",
      "epoch 16 || Epoch_TRAIN_Loss:2596.9231 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.2743 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 17/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 11050 || Loss: 4.0658 || 10iter: 2.8347 sec.\n",
      "Iter 11060 || Loss: 4.6532 || 10iter: 1.3719 sec.\n",
      "Iter 11070 || Loss: 3.7550 || 10iter: 1.3724 sec.\n",
      "Iter 11080 || Loss: 3.1724 || 10iter: 1.4726 sec.\n",
      "Iter 11090 || Loss: 3.2392 || 10iter: 1.4268 sec.\n",
      "Iter 11100 || Loss: 4.5157 || 10iter: 1.4180 sec.\n",
      "Iter 11110 || Loss: 3.6574 || 10iter: 1.4192 sec.\n",
      "Iter 11120 || Loss: 3.6534 || 10iter: 1.3867 sec.\n",
      "Iter 11130 || Loss: 3.9512 || 10iter: 1.4306 sec.\n",
      "Iter 11140 || Loss: 3.7761 || 10iter: 1.4481 sec.\n",
      "Iter 11150 || Loss: 4.5771 || 10iter: 1.4314 sec.\n",
      "Iter 11160 || Loss: 3.8766 || 10iter: 1.4358 sec.\n",
      "Iter 11170 || Loss: 3.4159 || 10iter: 1.4338 sec.\n",
      "Iter 11180 || Loss: 3.6521 || 10iter: 1.4343 sec.\n",
      "Iter 11190 || Loss: 3.9079 || 10iter: 1.4605 sec.\n",
      "Iter 11200 || Loss: 3.0958 || 10iter: 1.4865 sec.\n",
      "Iter 11210 || Loss: 3.9562 || 10iter: 1.4626 sec.\n",
      "Iter 11220 || Loss: 3.5682 || 10iter: 1.5019 sec.\n",
      "Iter 11230 || Loss: 3.2404 || 10iter: 1.4406 sec.\n",
      "Iter 11240 || Loss: 3.5352 || 10iter: 1.4842 sec.\n",
      "Iter 11250 || Loss: 3.9781 || 10iter: 1.4084 sec.\n",
      "Iter 11260 || Loss: 4.3025 || 10iter: 1.4972 sec.\n",
      "Iter 11270 || Loss: 3.6141 || 10iter: 1.3975 sec.\n",
      "Iter 11280 || Loss: 4.1099 || 10iter: 1.4376 sec.\n",
      "Iter 11290 || Loss: 3.4073 || 10iter: 1.4200 sec.\n",
      "Iter 11300 || Loss: 3.7228 || 10iter: 1.3703 sec.\n",
      "Iter 11310 || Loss: 3.3617 || 10iter: 1.4147 sec.\n",
      "Iter 11320 || Loss: 3.7105 || 10iter: 1.4642 sec.\n",
      "Iter 11330 || Loss: 3.8672 || 10iter: 1.4662 sec.\n",
      "Iter 11340 || Loss: 3.7645 || 10iter: 1.4537 sec.\n",
      "Iter 11350 || Loss: 3.2291 || 10iter: 1.4779 sec.\n",
      "Iter 11360 || Loss: 3.8425 || 10iter: 1.4850 sec.\n",
      "Iter 11370 || Loss: 4.0890 || 10iter: 1.4397 sec.\n",
      "Iter 11380 || Loss: 3.8104 || 10iter: 1.3972 sec.\n",
      "Iter 11390 || Loss: 3.7223 || 10iter: 1.4143 sec.\n",
      "Iter 11400 || Loss: 3.8577 || 10iter: 1.4262 sec.\n",
      "Iter 11410 || Loss: 3.7190 || 10iter: 1.3746 sec.\n",
      "Iter 11420 || Loss: 3.4507 || 10iter: 1.3811 sec.\n",
      "Iter 11430 || Loss: 3.9176 || 10iter: 1.3888 sec.\n",
      "Iter 11440 || Loss: 3.7670 || 10iter: 1.4244 sec.\n",
      "Iter 11450 || Loss: 3.4994 || 10iter: 1.4449 sec.\n",
      "Iter 11460 || Loss: 3.4250 || 10iter: 1.4486 sec.\n",
      "Iter 11470 || Loss: 3.9930 || 10iter: 1.3950 sec.\n",
      "Iter 11480 || Loss: 3.4238 || 10iter: 1.4405 sec.\n",
      "Iter 11490 || Loss: 4.4231 || 10iter: 1.4644 sec.\n",
      "Iter 11500 || Loss: 3.7521 || 10iter: 1.4364 sec.\n",
      "Iter 11510 || Loss: 3.8296 || 10iter: 1.4300 sec.\n",
      "Iter 11520 || Loss: 3.4121 || 10iter: 1.4676 sec.\n",
      "Iter 11530 || Loss: 3.2926 || 10iter: 1.4219 sec.\n",
      "Iter 11540 || Loss: 4.1416 || 10iter: 1.4079 sec.\n",
      "Iter 11550 || Loss: 3.7184 || 10iter: 1.4630 sec.\n",
      "Iter 11560 || Loss: 3.5803 || 10iter: 1.4334 sec.\n",
      "Iter 11570 || Loss: 3.3662 || 10iter: 1.4647 sec.\n",
      "Iter 11580 || Loss: 3.8363 || 10iter: 1.4342 sec.\n",
      "Iter 11590 || Loss: 3.6424 || 10iter: 1.4898 sec.\n",
      "Iter 11600 || Loss: 3.7265 || 10iter: 1.4709 sec.\n",
      "Iter 11610 || Loss: 3.1891 || 10iter: 1.4429 sec.\n",
      "Iter 11620 || Loss: 3.3138 || 10iter: 1.4276 sec.\n",
      "Iter 11630 || Loss: 3.7146 || 10iter: 1.3795 sec.\n",
      "Iter 11640 || Loss: 3.6433 || 10iter: 1.4146 sec.\n",
      "Iter 11650 || Loss: 3.5012 || 10iter: 1.4162 sec.\n",
      "Iter 11660 || Loss: 3.8436 || 10iter: 1.4773 sec.\n",
      "Iter 11670 || Loss: 3.8949 || 10iter: 1.4530 sec.\n",
      "Iter 11680 || Loss: 3.7361 || 10iter: 1.4688 sec.\n",
      "Iter 11690 || Loss: 3.8612 || 10iter: 1.4769 sec.\n",
      "Iter 11700 || Loss: 3.6228 || 10iter: 1.4698 sec.\n",
      "Iter 11710 || Loss: 3.7188 || 10iter: 1.4136 sec.\n",
      "Iter 11720 || Loss: 3.2995 || 10iter: 1.3999 sec.\n",
      "Iter 11730 || Loss: 3.6044 || 10iter: 1.2604 sec.\n",
      "-------------\n",
      "epoch 17 || Epoch_TRAIN_Loss:2574.0957 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.4518 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 18/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 11740 || Loss: 3.6860 || 10iter: 2.7043 sec.\n",
      "Iter 11750 || Loss: 3.7514 || 10iter: 1.3740 sec.\n",
      "Iter 11760 || Loss: 2.8290 || 10iter: 1.3940 sec.\n",
      "Iter 11770 || Loss: 3.3525 || 10iter: 1.4424 sec.\n",
      "Iter 11780 || Loss: 3.5213 || 10iter: 1.4447 sec.\n",
      "Iter 11790 || Loss: 3.9002 || 10iter: 1.4350 sec.\n",
      "Iter 11800 || Loss: 3.5008 || 10iter: 1.4373 sec.\n",
      "Iter 11810 || Loss: 3.3347 || 10iter: 1.4086 sec.\n",
      "Iter 11820 || Loss: 3.9325 || 10iter: 1.4189 sec.\n",
      "Iter 11830 || Loss: 4.0462 || 10iter: 1.4443 sec.\n",
      "Iter 11840 || Loss: 3.2897 || 10iter: 1.4445 sec.\n",
      "Iter 11850 || Loss: 3.5004 || 10iter: 1.5056 sec.\n",
      "Iter 11860 || Loss: 3.1329 || 10iter: 1.4991 sec.\n",
      "Iter 11870 || Loss: 3.6973 || 10iter: 1.4139 sec.\n",
      "Iter 11880 || Loss: 3.3356 || 10iter: 1.4616 sec.\n",
      "Iter 11890 || Loss: 3.5836 || 10iter: 1.4598 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 11900 || Loss: 3.4627 || 10iter: 1.4086 sec.\n",
      "Iter 11910 || Loss: 3.1708 || 10iter: 1.3903 sec.\n",
      "Iter 11920 || Loss: 3.5011 || 10iter: 1.3954 sec.\n",
      "Iter 11930 || Loss: 4.2554 || 10iter: 1.4501 sec.\n",
      "Iter 11940 || Loss: 3.5948 || 10iter: 1.4509 sec.\n",
      "Iter 11950 || Loss: 3.7489 || 10iter: 1.5099 sec.\n",
      "Iter 11960 || Loss: 3.9827 || 10iter: 1.4291 sec.\n",
      "Iter 11970 || Loss: 3.7399 || 10iter: 1.4461 sec.\n",
      "Iter 11980 || Loss: 3.4009 || 10iter: 1.4794 sec.\n",
      "Iter 11990 || Loss: 3.9977 || 10iter: 1.4070 sec.\n",
      "Iter 12000 || Loss: 4.0635 || 10iter: 1.4289 sec.\n",
      "Iter 12010 || Loss: 3.8358 || 10iter: 1.4296 sec.\n",
      "Iter 12020 || Loss: 3.5076 || 10iter: 1.4274 sec.\n",
      "Iter 12030 || Loss: 3.7929 || 10iter: 1.4432 sec.\n",
      "Iter 12040 || Loss: 3.9350 || 10iter: 1.4935 sec.\n",
      "Iter 12050 || Loss: 3.2453 || 10iter: 1.4686 sec.\n",
      "Iter 12060 || Loss: 3.9101 || 10iter: 1.4043 sec.\n",
      "Iter 12070 || Loss: 3.4580 || 10iter: 1.4366 sec.\n",
      "Iter 12080 || Loss: 3.6532 || 10iter: 1.4468 sec.\n",
      "Iter 12090 || Loss: 3.6707 || 10iter: 1.3975 sec.\n",
      "Iter 12100 || Loss: 3.5779 || 10iter: 1.3872 sec.\n",
      "Iter 12110 || Loss: 3.4496 || 10iter: 1.4283 sec.\n",
      "Iter 12120 || Loss: 3.3583 || 10iter: 1.4530 sec.\n",
      "Iter 12130 || Loss: 4.4008 || 10iter: 1.4137 sec.\n",
      "Iter 12140 || Loss: 4.3620 || 10iter: 1.4459 sec.\n",
      "Iter 12150 || Loss: 3.4113 || 10iter: 1.5021 sec.\n",
      "Iter 12160 || Loss: 3.8796 || 10iter: 1.4197 sec.\n",
      "Iter 12170 || Loss: 3.2210 || 10iter: 1.4963 sec.\n",
      "Iter 12180 || Loss: 4.5253 || 10iter: 1.4746 sec.\n",
      "Iter 12190 || Loss: 3.9681 || 10iter: 1.4829 sec.\n",
      "Iter 12200 || Loss: 3.1450 || 10iter: 1.4294 sec.\n",
      "Iter 12210 || Loss: 4.0914 || 10iter: 1.4499 sec.\n",
      "Iter 12220 || Loss: 3.7207 || 10iter: 1.4090 sec.\n",
      "Iter 12230 || Loss: 3.3238 || 10iter: 1.4359 sec.\n",
      "Iter 12240 || Loss: 4.1934 || 10iter: 1.3955 sec.\n",
      "Iter 12250 || Loss: 3.7392 || 10iter: 1.5060 sec.\n",
      "Iter 12260 || Loss: 4.2052 || 10iter: 1.4637 sec.\n",
      "Iter 12270 || Loss: 3.8792 || 10iter: 1.4229 sec.\n",
      "Iter 12280 || Loss: 4.2457 || 10iter: 1.4457 sec.\n",
      "Iter 12290 || Loss: 3.5749 || 10iter: 1.4284 sec.\n",
      "Iter 12300 || Loss: 3.6116 || 10iter: 1.4294 sec.\n",
      "Iter 12310 || Loss: 3.5744 || 10iter: 1.4442 sec.\n",
      "Iter 12320 || Loss: 3.5775 || 10iter: 1.3976 sec.\n",
      "Iter 12330 || Loss: 3.8235 || 10iter: 1.3977 sec.\n",
      "Iter 12340 || Loss: 3.2834 || 10iter: 1.4339 sec.\n",
      "Iter 12350 || Loss: 3.9335 || 10iter: 1.4705 sec.\n",
      "Iter 12360 || Loss: 2.6445 || 10iter: 1.4713 sec.\n",
      "Iter 12370 || Loss: 3.4200 || 10iter: 1.4117 sec.\n",
      "Iter 12380 || Loss: 3.5530 || 10iter: 1.4372 sec.\n",
      "Iter 12390 || Loss: 3.8003 || 10iter: 1.3935 sec.\n",
      "Iter 12400 || Loss: 2.9654 || 10iter: 1.4148 sec.\n",
      "Iter 12410 || Loss: 2.9665 || 10iter: 1.3505 sec.\n",
      "Iter 12420 || Loss: 3.2788 || 10iter: 1.2691 sec.\n",
      "-------------\n",
      "epoch 18 || Epoch_TRAIN_Loss:2559.3143 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.3882 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 19/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 12430 || Loss: 3.6275 || 10iter: 2.8045 sec.\n",
      "Iter 12440 || Loss: 3.5154 || 10iter: 1.3659 sec.\n",
      "Iter 12450 || Loss: 4.2296 || 10iter: 1.4132 sec.\n",
      "Iter 12460 || Loss: 3.8664 || 10iter: 1.3883 sec.\n",
      "Iter 12470 || Loss: 3.3907 || 10iter: 1.3873 sec.\n",
      "Iter 12480 || Loss: 4.0792 || 10iter: 1.4235 sec.\n",
      "Iter 12490 || Loss: 3.5749 || 10iter: 1.4221 sec.\n",
      "Iter 12500 || Loss: 3.2261 || 10iter: 1.4195 sec.\n",
      "Iter 12510 || Loss: 3.5521 || 10iter: 1.4401 sec.\n",
      "Iter 12520 || Loss: 3.1883 || 10iter: 1.4295 sec.\n",
      "Iter 12530 || Loss: 3.0760 || 10iter: 1.3995 sec.\n",
      "Iter 12540 || Loss: 3.4167 || 10iter: 1.4371 sec.\n",
      "Iter 12550 || Loss: 4.1076 || 10iter: 1.4023 sec.\n",
      "Iter 12560 || Loss: 3.7363 || 10iter: 1.4097 sec.\n",
      "Iter 12570 || Loss: 3.7469 || 10iter: 1.4558 sec.\n",
      "Iter 12580 || Loss: 3.3801 || 10iter: 1.4848 sec.\n",
      "Iter 12590 || Loss: 3.5492 || 10iter: 1.4151 sec.\n",
      "Iter 12600 || Loss: 3.3129 || 10iter: 1.4317 sec.\n",
      "Iter 12610 || Loss: 3.8037 || 10iter: 1.4007 sec.\n",
      "Iter 12620 || Loss: 3.3164 || 10iter: 1.4772 sec.\n",
      "Iter 12630 || Loss: 3.7786 || 10iter: 1.3883 sec.\n",
      "Iter 12640 || Loss: 3.6341 || 10iter: 1.4357 sec.\n",
      "Iter 12650 || Loss: 3.7279 || 10iter: 1.3750 sec.\n",
      "Iter 12660 || Loss: 3.6586 || 10iter: 1.4053 sec.\n",
      "Iter 12670 || Loss: 4.6421 || 10iter: 1.4639 sec.\n",
      "Iter 12680 || Loss: 4.1724 || 10iter: 1.4314 sec.\n",
      "Iter 12690 || Loss: 3.2469 || 10iter: 1.4427 sec.\n",
      "Iter 12700 || Loss: 4.0334 || 10iter: 1.4295 sec.\n",
      "Iter 12710 || Loss: 4.0800 || 10iter: 1.4093 sec.\n",
      "Iter 12720 || Loss: 3.2328 || 10iter: 1.4799 sec.\n",
      "Iter 12730 || Loss: 4.0771 || 10iter: 1.5063 sec.\n",
      "Iter 12740 || Loss: 3.9474 || 10iter: 1.4256 sec.\n",
      "Iter 12750 || Loss: 3.9367 || 10iter: 1.3916 sec.\n",
      "Iter 12760 || Loss: 4.2667 || 10iter: 1.4113 sec.\n",
      "Iter 12770 || Loss: 3.2132 || 10iter: 1.4269 sec.\n",
      "Iter 12780 || Loss: 3.7646 || 10iter: 1.4509 sec.\n",
      "Iter 12790 || Loss: 3.7099 || 10iter: 1.4027 sec.\n",
      "Iter 12800 || Loss: 3.8280 || 10iter: 1.3887 sec.\n",
      "Iter 12810 || Loss: 3.6715 || 10iter: 1.4047 sec.\n",
      "Iter 12820 || Loss: 3.5799 || 10iter: 1.4275 sec.\n",
      "Iter 12830 || Loss: 3.5070 || 10iter: 1.4026 sec.\n",
      "Iter 12840 || Loss: 3.8088 || 10iter: 1.4611 sec.\n",
      "Iter 12850 || Loss: 3.3777 || 10iter: 1.4138 sec.\n",
      "Iter 12860 || Loss: 3.4793 || 10iter: 1.4233 sec.\n",
      "Iter 12870 || Loss: 3.5849 || 10iter: 1.3853 sec.\n",
      "Iter 12880 || Loss: 3.9157 || 10iter: 1.4855 sec.\n",
      "Iter 12890 || Loss: 3.8250 || 10iter: 1.4158 sec.\n",
      "Iter 12900 || Loss: 3.5957 || 10iter: 1.4731 sec.\n",
      "Iter 12910 || Loss: 3.8572 || 10iter: 1.4054 sec.\n",
      "Iter 12920 || Loss: 3.5343 || 10iter: 1.4150 sec.\n",
      "Iter 12930 || Loss: 3.9906 || 10iter: 1.4425 sec.\n",
      "Iter 12940 || Loss: 3.2221 || 10iter: 1.4517 sec.\n",
      "Iter 12950 || Loss: 4.4080 || 10iter: 1.4087 sec.\n",
      "Iter 12960 || Loss: 3.5315 || 10iter: 1.4657 sec.\n",
      "Iter 12970 || Loss: 3.1895 || 10iter: 1.4281 sec.\n",
      "Iter 12980 || Loss: 3.5143 || 10iter: 1.4728 sec.\n",
      "Iter 12990 || Loss: 3.7021 || 10iter: 1.4077 sec.\n",
      "Iter 13000 || Loss: 2.7912 || 10iter: 1.4296 sec.\n",
      "Iter 13010 || Loss: 3.2338 || 10iter: 1.4352 sec.\n",
      "Iter 13020 || Loss: 3.9108 || 10iter: 1.4194 sec.\n",
      "Iter 13030 || Loss: 4.0437 || 10iter: 1.4293 sec.\n",
      "Iter 13040 || Loss: 3.5831 || 10iter: 1.4470 sec.\n",
      "Iter 13050 || Loss: 3.5431 || 10iter: 1.4582 sec.\n",
      "Iter 13060 || Loss: 3.4962 || 10iter: 1.4206 sec.\n",
      "Iter 13070 || Loss: 3.1786 || 10iter: 1.4601 sec.\n",
      "Iter 13080 || Loss: 3.9766 || 10iter: 1.5265 sec.\n",
      "Iter 13090 || Loss: 3.8716 || 10iter: 1.4512 sec.\n",
      "Iter 13100 || Loss: 3.5499 || 10iter: 1.3483 sec.\n",
      "Iter 13110 || Loss: 3.8112 || 10iter: 1.2658 sec.\n",
      "-------------\n",
      "epoch 19 || Epoch_TRAIN_Loss:2535.3498 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  101.8993 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 20/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 13120 || Loss: 3.4673 || 10iter: 2.8009 sec.\n",
      "Iter 13130 || Loss: 3.6785 || 10iter: 1.3736 sec.\n",
      "Iter 13140 || Loss: 3.5143 || 10iter: 1.4334 sec.\n",
      "Iter 13150 || Loss: 4.1750 || 10iter: 1.3724 sec.\n",
      "Iter 13160 || Loss: 4.0482 || 10iter: 1.4369 sec.\n",
      "Iter 13170 || Loss: 4.0864 || 10iter: 1.4734 sec.\n",
      "Iter 13180 || Loss: 3.6365 || 10iter: 1.4068 sec.\n",
      "Iter 13190 || Loss: 3.5836 || 10iter: 1.4076 sec.\n",
      "Iter 13200 || Loss: 3.7436 || 10iter: 1.3909 sec.\n",
      "Iter 13210 || Loss: 3.9984 || 10iter: 1.4830 sec.\n",
      "Iter 13220 || Loss: 3.7060 || 10iter: 1.4554 sec.\n",
      "Iter 13230 || Loss: 3.8641 || 10iter: 1.4265 sec.\n",
      "Iter 13240 || Loss: 3.5509 || 10iter: 1.4064 sec.\n",
      "Iter 13250 || Loss: 3.1086 || 10iter: 1.4475 sec.\n",
      "Iter 13260 || Loss: 3.4894 || 10iter: 1.4557 sec.\n",
      "Iter 13270 || Loss: 3.0540 || 10iter: 1.4336 sec.\n",
      "Iter 13280 || Loss: 3.6271 || 10iter: 1.4561 sec.\n",
      "Iter 13290 || Loss: 3.5551 || 10iter: 1.4176 sec.\n",
      "Iter 13300 || Loss: 3.3341 || 10iter: 1.3843 sec.\n",
      "Iter 13310 || Loss: 3.9033 || 10iter: 1.4150 sec.\n",
      "Iter 13320 || Loss: 3.6108 || 10iter: 1.4503 sec.\n",
      "Iter 13330 || Loss: 4.1429 || 10iter: 1.4335 sec.\n",
      "Iter 13340 || Loss: 4.0830 || 10iter: 1.4168 sec.\n",
      "Iter 13350 || Loss: 3.6541 || 10iter: 1.4590 sec.\n",
      "Iter 13360 || Loss: 3.5399 || 10iter: 1.4233 sec.\n",
      "Iter 13370 || Loss: 4.3945 || 10iter: 1.4462 sec.\n",
      "Iter 13380 || Loss: 3.5561 || 10iter: 1.4195 sec.\n",
      "Iter 13390 || Loss: 3.1685 || 10iter: 1.4719 sec.\n",
      "Iter 13400 || Loss: 4.0130 || 10iter: 1.4099 sec.\n",
      "Iter 13410 || Loss: 4.0014 || 10iter: 1.4727 sec.\n",
      "Iter 13420 || Loss: 3.4655 || 10iter: 1.4742 sec.\n",
      "Iter 13430 || Loss: 4.0065 || 10iter: 1.4407 sec.\n",
      "Iter 13440 || Loss: 3.5967 || 10iter: 1.4180 sec.\n",
      "Iter 13450 || Loss: 3.5762 || 10iter: 1.3979 sec.\n",
      "Iter 13460 || Loss: 4.2068 || 10iter: 1.4334 sec.\n",
      "Iter 13470 || Loss: 3.7805 || 10iter: 1.4318 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 13480 || Loss: 3.6380 || 10iter: 1.4267 sec.\n",
      "Iter 13490 || Loss: 3.8184 || 10iter: 1.4100 sec.\n",
      "Iter 13500 || Loss: 2.9719 || 10iter: 1.4525 sec.\n",
      "Iter 13510 || Loss: 3.5191 || 10iter: 1.4252 sec.\n",
      "Iter 13520 || Loss: 3.6616 || 10iter: 1.4139 sec.\n",
      "Iter 13530 || Loss: 3.4481 || 10iter: 1.4499 sec.\n",
      "Iter 13540 || Loss: 3.3606 || 10iter: 1.4577 sec.\n",
      "Iter 13550 || Loss: 3.4478 || 10iter: 1.4206 sec.\n",
      "Iter 13560 || Loss: 3.6069 || 10iter: 1.4334 sec.\n",
      "Iter 13570 || Loss: 3.7036 || 10iter: 1.4186 sec.\n",
      "Iter 13580 || Loss: 3.1618 || 10iter: 1.4344 sec.\n",
      "Iter 13590 || Loss: 3.9750 || 10iter: 1.3860 sec.\n",
      "Iter 13600 || Loss: 3.2660 || 10iter: 1.5068 sec.\n",
      "Iter 13610 || Loss: 3.4853 || 10iter: 1.4697 sec.\n",
      "Iter 13620 || Loss: 3.6283 || 10iter: 1.3883 sec.\n",
      "Iter 13630 || Loss: 3.8234 || 10iter: 1.4530 sec.\n",
      "Iter 13640 || Loss: 3.9860 || 10iter: 1.4382 sec.\n",
      "Iter 13650 || Loss: 3.6520 || 10iter: 1.4318 sec.\n",
      "Iter 13660 || Loss: 3.4380 || 10iter: 1.4021 sec.\n",
      "Iter 13670 || Loss: 3.1552 || 10iter: 1.4090 sec.\n",
      "Iter 13680 || Loss: 3.9365 || 10iter: 1.4750 sec.\n",
      "Iter 13690 || Loss: 3.2719 || 10iter: 1.4199 sec.\n",
      "Iter 13700 || Loss: 3.7116 || 10iter: 1.4400 sec.\n",
      "Iter 13710 || Loss: 3.5943 || 10iter: 1.4427 sec.\n",
      "Iter 13720 || Loss: 3.8798 || 10iter: 1.4084 sec.\n",
      "Iter 13730 || Loss: 3.4743 || 10iter: 1.4633 sec.\n",
      "Iter 13740 || Loss: 3.9729 || 10iter: 1.4254 sec.\n",
      "Iter 13750 || Loss: 4.1810 || 10iter: 1.4021 sec.\n",
      "Iter 13760 || Loss: 3.7584 || 10iter: 1.4203 sec.\n",
      "Iter 13770 || Loss: 3.8043 || 10iter: 1.3887 sec.\n",
      "Iter 13780 || Loss: 3.7919 || 10iter: 1.4216 sec.\n",
      "Iter 13790 || Loss: 3.7679 || 10iter: 1.3444 sec.\n",
      "Iter 13800 || Loss: 4.2140 || 10iter: 1.2575 sec.\n",
      "-------------\n",
      "(val)\n",
      "-------------\n",
      "epoch 20 || Epoch_TRAIN_Loss:2520.2634 ||Epoch_VAL_Loss:732.1057\n",
      "timer:  119.3767 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 21/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 13810 || Loss: 3.3901 || 10iter: 2.7581 sec.\n",
      "Iter 13820 || Loss: 3.9891 || 10iter: 1.3120 sec.\n",
      "Iter 13830 || Loss: 3.2714 || 10iter: 1.4518 sec.\n",
      "Iter 13840 || Loss: 3.5262 || 10iter: 1.3767 sec.\n",
      "Iter 13850 || Loss: 3.8152 || 10iter: 1.4074 sec.\n",
      "Iter 13860 || Loss: 3.5570 || 10iter: 1.4543 sec.\n",
      "Iter 13870 || Loss: 3.2051 || 10iter: 1.4206 sec.\n",
      "Iter 13880 || Loss: 3.3005 || 10iter: 1.4360 sec.\n",
      "Iter 13890 || Loss: 4.0480 || 10iter: 1.4918 sec.\n",
      "Iter 13900 || Loss: 3.8722 || 10iter: 1.4032 sec.\n",
      "Iter 13910 || Loss: 3.4061 || 10iter: 1.4602 sec.\n",
      "Iter 13920 || Loss: 3.8734 || 10iter: 1.4448 sec.\n",
      "Iter 13930 || Loss: 4.0604 || 10iter: 1.3699 sec.\n",
      "Iter 13940 || Loss: 3.6941 || 10iter: 1.3995 sec.\n",
      "Iter 13950 || Loss: 3.5281 || 10iter: 1.4218 sec.\n",
      "Iter 13960 || Loss: 3.9143 || 10iter: 1.4494 sec.\n",
      "Iter 13970 || Loss: 3.8902 || 10iter: 1.4329 sec.\n",
      "Iter 13980 || Loss: 3.8963 || 10iter: 1.4653 sec.\n",
      "Iter 13990 || Loss: 3.5887 || 10iter: 1.4199 sec.\n",
      "Iter 14000 || Loss: 3.3365 || 10iter: 1.4683 sec.\n",
      "Iter 14010 || Loss: 3.4706 || 10iter: 1.4496 sec.\n",
      "Iter 14020 || Loss: 3.5689 || 10iter: 1.4413 sec.\n",
      "Iter 14030 || Loss: 4.1710 || 10iter: 1.4466 sec.\n",
      "Iter 14040 || Loss: 3.8731 || 10iter: 1.4933 sec.\n",
      "Iter 14050 || Loss: 3.2887 || 10iter: 1.4237 sec.\n",
      "Iter 14060 || Loss: 3.7270 || 10iter: 1.4412 sec.\n",
      "Iter 14070 || Loss: 3.6151 || 10iter: 1.4533 sec.\n",
      "Iter 14080 || Loss: 3.6112 || 10iter: 1.4459 sec.\n",
      "Iter 14090 || Loss: 3.4833 || 10iter: 1.4347 sec.\n",
      "Iter 14100 || Loss: 3.6483 || 10iter: 1.4394 sec.\n",
      "Iter 14110 || Loss: 3.2968 || 10iter: 1.4647 sec.\n",
      "Iter 14120 || Loss: 3.7272 || 10iter: 1.4412 sec.\n",
      "Iter 14130 || Loss: 3.4036 || 10iter: 1.5028 sec.\n",
      "Iter 14140 || Loss: 3.9777 || 10iter: 1.4094 sec.\n",
      "Iter 14150 || Loss: 3.8121 || 10iter: 1.4177 sec.\n",
      "Iter 14160 || Loss: 3.8874 || 10iter: 1.4833 sec.\n",
      "Iter 14170 || Loss: 3.8854 || 10iter: 1.5227 sec.\n",
      "Iter 14180 || Loss: 3.3942 || 10iter: 1.4749 sec.\n",
      "Iter 14190 || Loss: 3.6358 || 10iter: 1.4204 sec.\n",
      "Iter 14200 || Loss: 3.8457 || 10iter: 1.3875 sec.\n",
      "Iter 14210 || Loss: 3.5535 || 10iter: 1.3959 sec.\n",
      "Iter 14220 || Loss: 3.4426 || 10iter: 1.4033 sec.\n",
      "Iter 14230 || Loss: 3.2592 || 10iter: 1.4451 sec.\n",
      "Iter 14240 || Loss: 3.2956 || 10iter: 1.4347 sec.\n",
      "Iter 14250 || Loss: 3.8527 || 10iter: 1.4853 sec.\n",
      "Iter 14260 || Loss: 3.5376 || 10iter: 1.4592 sec.\n",
      "Iter 14270 || Loss: 3.5254 || 10iter: 1.4332 sec.\n",
      "Iter 14280 || Loss: 3.5071 || 10iter: 1.4279 sec.\n",
      "Iter 14290 || Loss: 3.6590 || 10iter: 1.4622 sec.\n",
      "Iter 14300 || Loss: 3.3041 || 10iter: 1.3797 sec.\n",
      "Iter 14310 || Loss: 2.9835 || 10iter: 1.3888 sec.\n",
      "Iter 14320 || Loss: 4.4392 || 10iter: 1.4378 sec.\n",
      "Iter 14330 || Loss: 3.5660 || 10iter: 1.4545 sec.\n",
      "Iter 14340 || Loss: 3.5066 || 10iter: 1.4754 sec.\n",
      "Iter 14350 || Loss: 4.1437 || 10iter: 1.4956 sec.\n",
      "Iter 14360 || Loss: 3.7239 || 10iter: 1.4336 sec.\n",
      "Iter 14370 || Loss: 4.3054 || 10iter: 1.4773 sec.\n",
      "Iter 14380 || Loss: 3.0803 || 10iter: 1.4773 sec.\n",
      "Iter 14390 || Loss: 4.1272 || 10iter: 1.4028 sec.\n",
      "Iter 14400 || Loss: 3.9612 || 10iter: 1.4263 sec.\n",
      "Iter 14410 || Loss: 4.4280 || 10iter: 1.4270 sec.\n",
      "Iter 14420 || Loss: 3.2549 || 10iter: 1.3865 sec.\n",
      "Iter 14430 || Loss: 4.1015 || 10iter: 1.5078 sec.\n",
      "Iter 14440 || Loss: 3.8940 || 10iter: 1.3912 sec.\n",
      "Iter 14450 || Loss: 3.4306 || 10iter: 1.3885 sec.\n",
      "Iter 14460 || Loss: 3.7194 || 10iter: 1.4038 sec.\n",
      "Iter 14470 || Loss: 3.8047 || 10iter: 1.3806 sec.\n",
      "Iter 14480 || Loss: 3.8571 || 10iter: 1.3610 sec.\n",
      "Iter 14490 || Loss: 4.1276 || 10iter: 1.2737 sec.\n",
      "-------------\n",
      "epoch 21 || Epoch_TRAIN_Loss:2506.4816 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.3187 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 22/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 14500 || Loss: 3.1414 || 10iter: 2.6925 sec.\n",
      "Iter 14510 || Loss: 3.5575 || 10iter: 1.3845 sec.\n",
      "Iter 14520 || Loss: 3.7575 || 10iter: 1.4485 sec.\n",
      "Iter 14530 || Loss: 3.2234 || 10iter: 1.4560 sec.\n",
      "Iter 14540 || Loss: 3.6341 || 10iter: 1.4348 sec.\n",
      "Iter 14550 || Loss: 4.0958 || 10iter: 1.4638 sec.\n",
      "Iter 14560 || Loss: 3.2444 || 10iter: 1.4249 sec.\n",
      "Iter 14570 || Loss: 3.2002 || 10iter: 1.4386 sec.\n",
      "Iter 14580 || Loss: 3.4904 || 10iter: 1.4294 sec.\n",
      "Iter 14590 || Loss: 3.6697 || 10iter: 1.4492 sec.\n",
      "Iter 14600 || Loss: 3.6239 || 10iter: 1.4339 sec.\n",
      "Iter 14610 || Loss: 3.9316 || 10iter: 1.4226 sec.\n",
      "Iter 14620 || Loss: 3.8180 || 10iter: 1.4209 sec.\n",
      "Iter 14630 || Loss: 3.5345 || 10iter: 1.3638 sec.\n",
      "Iter 14640 || Loss: 3.7558 || 10iter: 1.4431 sec.\n",
      "Iter 14650 || Loss: 3.3893 || 10iter: 1.4317 sec.\n",
      "Iter 14660 || Loss: 3.2907 || 10iter: 1.4795 sec.\n",
      "Iter 14670 || Loss: 3.6012 || 10iter: 1.4142 sec.\n",
      "Iter 14680 || Loss: 3.7330 || 10iter: 1.4257 sec.\n",
      "Iter 14690 || Loss: 3.8149 || 10iter: 1.4417 sec.\n",
      "Iter 14700 || Loss: 3.7064 || 10iter: 1.4949 sec.\n",
      "Iter 14710 || Loss: 3.7804 || 10iter: 1.4620 sec.\n",
      "Iter 14720 || Loss: 3.3489 || 10iter: 1.4057 sec.\n",
      "Iter 14730 || Loss: 3.2776 || 10iter: 1.4014 sec.\n",
      "Iter 14740 || Loss: 3.5223 || 10iter: 1.4432 sec.\n",
      "Iter 14750 || Loss: 4.2951 || 10iter: 1.4567 sec.\n",
      "Iter 14760 || Loss: 3.6175 || 10iter: 1.4217 sec.\n",
      "Iter 14770 || Loss: 3.6635 || 10iter: 1.4067 sec.\n",
      "Iter 14780 || Loss: 3.5429 || 10iter: 1.4644 sec.\n",
      "Iter 14790 || Loss: 3.4419 || 10iter: 1.4387 sec.\n",
      "Iter 14800 || Loss: 3.6866 || 10iter: 1.4619 sec.\n",
      "Iter 14810 || Loss: 4.2206 || 10iter: 1.4483 sec.\n",
      "Iter 14820 || Loss: 3.8599 || 10iter: 1.4302 sec.\n",
      "Iter 14830 || Loss: 3.0991 || 10iter: 1.3809 sec.\n",
      "Iter 14840 || Loss: 3.2864 || 10iter: 1.4560 sec.\n",
      "Iter 14850 || Loss: 3.3392 || 10iter: 1.4307 sec.\n",
      "Iter 14860 || Loss: 3.4246 || 10iter: 1.3957 sec.\n",
      "Iter 14870 || Loss: 3.8731 || 10iter: 1.4072 sec.\n",
      "Iter 14880 || Loss: 3.5863 || 10iter: 1.4161 sec.\n",
      "Iter 14890 || Loss: 2.8525 || 10iter: 1.4303 sec.\n",
      "Iter 14900 || Loss: 3.6757 || 10iter: 1.4363 sec.\n",
      "Iter 14910 || Loss: 3.9648 || 10iter: 1.4567 sec.\n",
      "Iter 14920 || Loss: 3.6816 || 10iter: 1.4569 sec.\n",
      "Iter 14930 || Loss: 4.0619 || 10iter: 1.4567 sec.\n",
      "Iter 14940 || Loss: 3.7852 || 10iter: 1.4395 sec.\n",
      "Iter 14950 || Loss: 4.0223 || 10iter: 1.4927 sec.\n",
      "Iter 14960 || Loss: 2.8952 || 10iter: 1.4417 sec.\n",
      "Iter 14970 || Loss: 2.9041 || 10iter: 1.4466 sec.\n",
      "Iter 14980 || Loss: 3.5757 || 10iter: 1.4398 sec.\n",
      "Iter 14990 || Loss: 3.6066 || 10iter: 1.4037 sec.\n",
      "Iter 15000 || Loss: 3.9122 || 10iter: 1.4243 sec.\n",
      "Iter 15010 || Loss: 3.4844 || 10iter: 1.4498 sec.\n",
      "Iter 15020 || Loss: 4.0419 || 10iter: 1.4971 sec.\n",
      "Iter 15030 || Loss: 3.6402 || 10iter: 1.4111 sec.\n",
      "Iter 15040 || Loss: 4.1821 || 10iter: 1.4713 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 15050 || Loss: 3.7774 || 10iter: 1.4611 sec.\n",
      "Iter 15060 || Loss: 3.5208 || 10iter: 1.4274 sec.\n",
      "Iter 15070 || Loss: 3.3452 || 10iter: 1.4335 sec.\n",
      "Iter 15080 || Loss: 3.7464 || 10iter: 1.3888 sec.\n",
      "Iter 15090 || Loss: 3.9257 || 10iter: 1.5274 sec.\n",
      "Iter 15100 || Loss: 3.9649 || 10iter: 1.4123 sec.\n",
      "Iter 15110 || Loss: 3.3378 || 10iter: 1.4354 sec.\n",
      "Iter 15120 || Loss: 3.5724 || 10iter: 1.3964 sec.\n",
      "Iter 15130 || Loss: 4.2620 || 10iter: 1.4763 sec.\n",
      "Iter 15140 || Loss: 3.3942 || 10iter: 1.4275 sec.\n",
      "Iter 15150 || Loss: 3.1242 || 10iter: 1.4152 sec.\n",
      "Iter 15160 || Loss: 3.6009 || 10iter: 1.4485 sec.\n",
      "Iter 15170 || Loss: 3.5214 || 10iter: 1.3271 sec.\n",
      "Iter 15180 || Loss: 3.7927 || 10iter: 1.2568 sec.\n",
      "-------------\n",
      "epoch 22 || Epoch_TRAIN_Loss:2500.9984 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.2357 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 23/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 15190 || Loss: 3.8257 || 10iter: 2.7592 sec.\n",
      "Iter 15200 || Loss: 3.6803 || 10iter: 1.3765 sec.\n",
      "Iter 15210 || Loss: 3.5840 || 10iter: 1.4252 sec.\n",
      "Iter 15220 || Loss: 3.2287 || 10iter: 1.4263 sec.\n",
      "Iter 15230 || Loss: 3.5150 || 10iter: 1.3578 sec.\n",
      "Iter 15240 || Loss: 3.6967 || 10iter: 1.4269 sec.\n",
      "Iter 15250 || Loss: 3.5648 || 10iter: 1.4152 sec.\n",
      "Iter 15260 || Loss: 3.7475 || 10iter: 1.4265 sec.\n",
      "Iter 15270 || Loss: 3.6231 || 10iter: 1.4243 sec.\n",
      "Iter 15280 || Loss: 3.6010 || 10iter: 1.3914 sec.\n",
      "Iter 15290 || Loss: 3.7443 || 10iter: 1.4611 sec.\n",
      "Iter 15300 || Loss: 3.9035 || 10iter: 1.3990 sec.\n",
      "Iter 15310 || Loss: 3.5480 || 10iter: 1.4114 sec.\n",
      "Iter 15320 || Loss: 4.3808 || 10iter: 1.4138 sec.\n",
      "Iter 15330 || Loss: 3.2803 || 10iter: 1.4325 sec.\n",
      "Iter 15340 || Loss: 4.1825 || 10iter: 1.4519 sec.\n",
      "Iter 15350 || Loss: 3.9074 || 10iter: 1.4250 sec.\n",
      "Iter 15360 || Loss: 2.9423 || 10iter: 1.4033 sec.\n",
      "Iter 15370 || Loss: 3.4578 || 10iter: 1.3833 sec.\n",
      "Iter 15380 || Loss: 4.1799 || 10iter: 1.5024 sec.\n",
      "Iter 15390 || Loss: 3.4331 || 10iter: 1.5146 sec.\n",
      "Iter 15400 || Loss: 4.2387 || 10iter: 1.4354 sec.\n",
      "Iter 15410 || Loss: 3.4788 || 10iter: 1.4551 sec.\n",
      "Iter 15420 || Loss: 3.9783 || 10iter: 1.4086 sec.\n",
      "Iter 15430 || Loss: 3.4575 || 10iter: 1.4832 sec.\n",
      "Iter 15440 || Loss: 3.6864 || 10iter: 1.4305 sec.\n",
      "Iter 15450 || Loss: 3.5079 || 10iter: 1.4410 sec.\n",
      "Iter 15460 || Loss: 3.8783 || 10iter: 1.4622 sec.\n",
      "Iter 15470 || Loss: 3.9164 || 10iter: 1.4202 sec.\n",
      "Iter 15480 || Loss: 3.5141 || 10iter: 1.4801 sec.\n",
      "Iter 15490 || Loss: 3.7761 || 10iter: 1.4332 sec.\n",
      "Iter 15500 || Loss: 3.5984 || 10iter: 1.4525 sec.\n",
      "Iter 15510 || Loss: 4.4698 || 10iter: 1.4209 sec.\n",
      "Iter 15520 || Loss: 3.8003 || 10iter: 1.4416 sec.\n",
      "Iter 15530 || Loss: 3.3926 || 10iter: 1.4048 sec.\n",
      "Iter 15540 || Loss: 4.5468 || 10iter: 1.4129 sec.\n",
      "Iter 15550 || Loss: 4.0654 || 10iter: 1.3609 sec.\n",
      "Iter 15560 || Loss: 3.5488 || 10iter: 1.3957 sec.\n",
      "Iter 15570 || Loss: 3.8480 || 10iter: 1.3959 sec.\n",
      "Iter 15580 || Loss: 3.5543 || 10iter: 1.4648 sec.\n",
      "Iter 15590 || Loss: 3.6471 || 10iter: 1.4015 sec.\n",
      "Iter 15600 || Loss: 3.5710 || 10iter: 1.4640 sec.\n",
      "Iter 15610 || Loss: 3.4531 || 10iter: 1.4476 sec.\n",
      "Iter 15620 || Loss: 3.7851 || 10iter: 1.4340 sec.\n",
      "Iter 15630 || Loss: 3.8934 || 10iter: 1.4870 sec.\n",
      "Iter 15640 || Loss: 3.5255 || 10iter: 1.4938 sec.\n",
      "Iter 15650 || Loss: 4.1012 || 10iter: 1.4156 sec.\n",
      "Iter 15660 || Loss: 3.6771 || 10iter: 1.4389 sec.\n",
      "Iter 15670 || Loss: 3.6804 || 10iter: 1.4425 sec.\n",
      "Iter 15680 || Loss: 3.3379 || 10iter: 1.4090 sec.\n",
      "Iter 15690 || Loss: 3.8651 || 10iter: 1.3721 sec.\n",
      "Iter 15700 || Loss: 3.5661 || 10iter: 1.4470 sec.\n",
      "Iter 15710 || Loss: 3.4313 || 10iter: 1.4070 sec.\n",
      "Iter 15720 || Loss: 3.6247 || 10iter: 1.4587 sec.\n",
      "Iter 15730 || Loss: 3.9010 || 10iter: 1.4684 sec.\n",
      "Iter 15740 || Loss: 3.5578 || 10iter: 1.4501 sec.\n",
      "Iter 15750 || Loss: 3.6056 || 10iter: 1.5106 sec.\n",
      "Iter 15760 || Loss: 3.9201 || 10iter: 1.3785 sec.\n",
      "Iter 15770 || Loss: 3.9252 || 10iter: 1.4520 sec.\n",
      "Iter 15780 || Loss: 3.3404 || 10iter: 1.3873 sec.\n",
      "Iter 15790 || Loss: 3.7380 || 10iter: 1.4153 sec.\n",
      "Iter 15800 || Loss: 3.4713 || 10iter: 1.4561 sec.\n",
      "Iter 15810 || Loss: 3.3824 || 10iter: 1.4294 sec.\n",
      "Iter 15820 || Loss: 3.1354 || 10iter: 1.4610 sec.\n",
      "Iter 15830 || Loss: 3.3583 || 10iter: 1.4214 sec.\n",
      "Iter 15840 || Loss: 3.1668 || 10iter: 1.4708 sec.\n",
      "Iter 15850 || Loss: 3.5112 || 10iter: 1.4518 sec.\n",
      "Iter 15860 || Loss: 3.5760 || 10iter: 1.3450 sec.\n",
      "Iter 15870 || Loss: 3.7730 || 10iter: 1.2786 sec.\n",
      "-------------\n",
      "epoch 23 || Epoch_TRAIN_Loss:2491.9806 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.0529 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 24/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 15880 || Loss: 3.3862 || 10iter: 2.6298 sec.\n",
      "Iter 15890 || Loss: 3.6726 || 10iter: 1.4777 sec.\n",
      "Iter 15900 || Loss: 3.2939 || 10iter: 1.4365 sec.\n",
      "Iter 15910 || Loss: 3.8535 || 10iter: 1.4077 sec.\n",
      "Iter 15920 || Loss: 3.8467 || 10iter: 1.4273 sec.\n",
      "Iter 15930 || Loss: 3.2630 || 10iter: 1.4203 sec.\n",
      "Iter 15940 || Loss: 3.3353 || 10iter: 1.4165 sec.\n",
      "Iter 15950 || Loss: 3.3708 || 10iter: 1.4276 sec.\n",
      "Iter 15960 || Loss: 3.6225 || 10iter: 1.4556 sec.\n",
      "Iter 15970 || Loss: 3.3454 || 10iter: 1.4101 sec.\n",
      "Iter 15980 || Loss: 3.3919 || 10iter: 1.4470 sec.\n",
      "Iter 15990 || Loss: 3.7760 || 10iter: 1.4721 sec.\n",
      "Iter 16000 || Loss: 4.0609 || 10iter: 1.4462 sec.\n",
      "Iter 16010 || Loss: 3.7764 || 10iter: 1.3681 sec.\n",
      "Iter 16020 || Loss: 3.5745 || 10iter: 1.4475 sec.\n",
      "Iter 16030 || Loss: 3.2149 || 10iter: 1.4184 sec.\n",
      "Iter 16040 || Loss: 3.4771 || 10iter: 1.4834 sec.\n",
      "Iter 16050 || Loss: 3.8280 || 10iter: 1.3923 sec.\n",
      "Iter 16060 || Loss: 3.7092 || 10iter: 1.4361 sec.\n",
      "Iter 16070 || Loss: 3.0273 || 10iter: 1.4438 sec.\n",
      "Iter 16080 || Loss: 3.4695 || 10iter: 1.4378 sec.\n",
      "Iter 16090 || Loss: 3.3927 || 10iter: 1.4859 sec.\n",
      "Iter 16100 || Loss: 3.3023 || 10iter: 1.4450 sec.\n",
      "Iter 16110 || Loss: 3.8292 || 10iter: 1.4460 sec.\n",
      "Iter 16120 || Loss: 3.8389 || 10iter: 1.4970 sec.\n",
      "Iter 16130 || Loss: 4.0219 || 10iter: 1.4231 sec.\n",
      "Iter 16140 || Loss: 3.6394 || 10iter: 1.4551 sec.\n",
      "Iter 16150 || Loss: 3.1491 || 10iter: 1.4536 sec.\n",
      "Iter 16160 || Loss: 3.2834 || 10iter: 1.4167 sec.\n",
      "Iter 16170 || Loss: 3.7058 || 10iter: 1.4631 sec.\n",
      "Iter 16180 || Loss: 4.0899 || 10iter: 1.4517 sec.\n",
      "Iter 16190 || Loss: 3.9553 || 10iter: 1.4138 sec.\n",
      "Iter 16200 || Loss: 3.3602 || 10iter: 1.3900 sec.\n",
      "Iter 16210 || Loss: 3.7435 || 10iter: 1.4048 sec.\n",
      "Iter 16220 || Loss: 3.3750 || 10iter: 1.4427 sec.\n",
      "Iter 16230 || Loss: 3.4939 || 10iter: 1.4200 sec.\n",
      "Iter 16240 || Loss: 3.2973 || 10iter: 1.4005 sec.\n",
      "Iter 16250 || Loss: 3.1951 || 10iter: 1.4221 sec.\n",
      "Iter 16260 || Loss: 2.8396 || 10iter: 1.4484 sec.\n",
      "Iter 16270 || Loss: 3.0277 || 10iter: 1.4120 sec.\n",
      "Iter 16280 || Loss: 3.4992 || 10iter: 1.4479 sec.\n",
      "Iter 16290 || Loss: 3.4168 || 10iter: 1.3874 sec.\n",
      "Iter 16300 || Loss: 4.0683 || 10iter: 1.4045 sec.\n",
      "Iter 16310 || Loss: 3.2584 || 10iter: 1.4113 sec.\n",
      "Iter 16320 || Loss: 3.8708 || 10iter: 1.4218 sec.\n",
      "Iter 16330 || Loss: 3.8508 || 10iter: 1.4660 sec.\n",
      "Iter 16340 || Loss: 3.2072 || 10iter: 1.4312 sec.\n",
      "Iter 16350 || Loss: 3.8162 || 10iter: 1.4452 sec.\n",
      "Iter 16360 || Loss: 3.6594 || 10iter: 1.3964 sec.\n",
      "Iter 16370 || Loss: 3.4009 || 10iter: 1.4168 sec.\n",
      "Iter 16380 || Loss: 3.9517 || 10iter: 1.4241 sec.\n",
      "Iter 16390 || Loss: 3.4892 || 10iter: 1.4220 sec.\n",
      "Iter 16400 || Loss: 3.8535 || 10iter: 1.4171 sec.\n",
      "Iter 16410 || Loss: 2.4716 || 10iter: 1.3972 sec.\n",
      "Iter 16420 || Loss: 3.5435 || 10iter: 1.4680 sec.\n",
      "Iter 16430 || Loss: 3.2587 || 10iter: 1.4404 sec.\n",
      "Iter 16440 || Loss: 3.8488 || 10iter: 1.4280 sec.\n",
      "Iter 16450 || Loss: 3.2045 || 10iter: 1.4692 sec.\n",
      "Iter 16460 || Loss: 3.6004 || 10iter: 1.3859 sec.\n",
      "Iter 16470 || Loss: 3.4983 || 10iter: 1.4758 sec.\n",
      "Iter 16480 || Loss: 3.7554 || 10iter: 1.3742 sec.\n",
      "Iter 16490 || Loss: 2.9154 || 10iter: 1.4163 sec.\n",
      "Iter 16500 || Loss: 3.5930 || 10iter: 1.3981 sec.\n",
      "Iter 16510 || Loss: 3.6942 || 10iter: 1.4438 sec.\n",
      "Iter 16520 || Loss: 3.7863 || 10iter: 1.4268 sec.\n",
      "Iter 16530 || Loss: 3.2320 || 10iter: 1.4116 sec.\n",
      "Iter 16540 || Loss: 3.9873 || 10iter: 1.4482 sec.\n",
      "Iter 16550 || Loss: 4.0837 || 10iter: 1.3348 sec.\n",
      "Iter 16560 || Loss: 3.2074 || 10iter: 1.2534 sec.\n",
      "-------------\n",
      "epoch 24 || Epoch_TRAIN_Loss:2459.0023 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  101.8203 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 25/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 16570 || Loss: 3.6702 || 10iter: 2.7858 sec.\n",
      "Iter 16580 || Loss: 3.6265 || 10iter: 1.3911 sec.\n",
      "Iter 16590 || Loss: 3.8551 || 10iter: 1.4251 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 16600 || Loss: 3.3716 || 10iter: 1.5386 sec.\n",
      "Iter 16610 || Loss: 3.1631 || 10iter: 1.4641 sec.\n",
      "Iter 16620 || Loss: 4.2524 || 10iter: 1.4133 sec.\n",
      "Iter 16630 || Loss: 3.4334 || 10iter: 1.4034 sec.\n",
      "Iter 16640 || Loss: 3.2362 || 10iter: 1.3889 sec.\n",
      "Iter 16650 || Loss: 3.9987 || 10iter: 1.3700 sec.\n",
      "Iter 16660 || Loss: 3.4859 || 10iter: 1.4322 sec.\n",
      "Iter 16670 || Loss: 3.1562 || 10iter: 1.3962 sec.\n",
      "Iter 16680 || Loss: 3.8412 || 10iter: 1.4015 sec.\n",
      "Iter 16690 || Loss: 3.0863 || 10iter: 1.4188 sec.\n",
      "Iter 16700 || Loss: 3.1556 || 10iter: 1.4699 sec.\n",
      "Iter 16710 || Loss: 3.5915 || 10iter: 1.4358 sec.\n",
      "Iter 16720 || Loss: 3.6305 || 10iter: 1.4620 sec.\n",
      "Iter 16730 || Loss: 3.7823 || 10iter: 1.4055 sec.\n",
      "Iter 16740 || Loss: 3.4683 || 10iter: 1.4418 sec.\n",
      "Iter 16750 || Loss: 3.8251 || 10iter: 1.3688 sec.\n",
      "Iter 16760 || Loss: 3.2802 || 10iter: 1.3985 sec.\n",
      "Iter 16770 || Loss: 3.9553 || 10iter: 1.4585 sec.\n",
      "Iter 16780 || Loss: 3.4067 || 10iter: 1.4310 sec.\n",
      "Iter 16790 || Loss: 3.1205 || 10iter: 1.4749 sec.\n",
      "Iter 16800 || Loss: 3.2132 || 10iter: 1.4474 sec.\n",
      "Iter 16810 || Loss: 3.1537 || 10iter: 1.4322 sec.\n",
      "Iter 16820 || Loss: 3.2086 || 10iter: 1.5014 sec.\n",
      "Iter 16830 || Loss: 3.7008 || 10iter: 1.4068 sec.\n",
      "Iter 16840 || Loss: 3.6178 || 10iter: 1.4265 sec.\n",
      "Iter 16850 || Loss: 3.1640 || 10iter: 1.4469 sec.\n",
      "Iter 16860 || Loss: 3.6950 || 10iter: 1.4564 sec.\n",
      "Iter 16870 || Loss: 3.3774 || 10iter: 1.4682 sec.\n",
      "Iter 16880 || Loss: 4.0234 || 10iter: 1.4287 sec.\n",
      "Iter 16890 || Loss: 3.5938 || 10iter: 1.4080 sec.\n",
      "Iter 16900 || Loss: 3.4960 || 10iter: 1.3811 sec.\n",
      "Iter 16910 || Loss: 4.1159 || 10iter: 1.3890 sec.\n",
      "Iter 16920 || Loss: 3.3675 || 10iter: 1.4902 sec.\n",
      "Iter 16930 || Loss: 3.7196 || 10iter: 1.4121 sec.\n",
      "Iter 16940 || Loss: 3.6749 || 10iter: 1.3803 sec.\n",
      "Iter 16950 || Loss: 3.6163 || 10iter: 1.3740 sec.\n",
      "Iter 16960 || Loss: 3.1629 || 10iter: 1.4760 sec.\n",
      "Iter 16970 || Loss: 3.5720 || 10iter: 1.4942 sec.\n",
      "Iter 16980 || Loss: 3.4438 || 10iter: 1.4764 sec.\n",
      "Iter 16990 || Loss: 4.2316 || 10iter: 1.4651 sec.\n",
      "Iter 17000 || Loss: 3.8192 || 10iter: 1.4589 sec.\n",
      "Iter 17010 || Loss: 3.6290 || 10iter: 1.5041 sec.\n",
      "Iter 17020 || Loss: 3.0556 || 10iter: 1.4377 sec.\n",
      "Iter 17030 || Loss: 3.8626 || 10iter: 1.4405 sec.\n",
      "Iter 17040 || Loss: 3.8714 || 10iter: 1.3990 sec.\n",
      "Iter 17050 || Loss: 3.7656 || 10iter: 1.4195 sec.\n",
      "Iter 17060 || Loss: 3.6615 || 10iter: 1.3680 sec.\n",
      "Iter 17070 || Loss: 3.1678 || 10iter: 1.4830 sec.\n",
      "Iter 17080 || Loss: 3.1258 || 10iter: 1.4462 sec.\n",
      "Iter 17090 || Loss: 3.8717 || 10iter: 1.4553 sec.\n",
      "Iter 17100 || Loss: 3.1882 || 10iter: 1.4001 sec.\n",
      "Iter 17110 || Loss: 3.8100 || 10iter: 1.4348 sec.\n",
      "Iter 17120 || Loss: 3.0853 || 10iter: 1.3755 sec.\n",
      "Iter 17130 || Loss: 3.6083 || 10iter: 1.4709 sec.\n",
      "Iter 17140 || Loss: 3.7002 || 10iter: 1.4453 sec.\n",
      "Iter 17150 || Loss: 3.4733 || 10iter: 1.4016 sec.\n",
      "Iter 17160 || Loss: 3.0299 || 10iter: 1.4592 sec.\n",
      "Iter 17170 || Loss: 3.3682 || 10iter: 1.4534 sec.\n",
      "Iter 17180 || Loss: 4.3982 || 10iter: 1.4500 sec.\n",
      "Iter 17190 || Loss: 3.7602 || 10iter: 1.4398 sec.\n",
      "Iter 17200 || Loss: 3.2550 || 10iter: 1.4726 sec.\n",
      "Iter 17210 || Loss: 4.1883 || 10iter: 1.4915 sec.\n",
      "Iter 17220 || Loss: 3.4422 || 10iter: 1.4145 sec.\n",
      "Iter 17230 || Loss: 3.1048 || 10iter: 1.4352 sec.\n",
      "Iter 17240 || Loss: 3.4373 || 10iter: 1.3359 sec.\n",
      "Iter 17250 || Loss: 3.9290 || 10iter: 1.2527 sec.\n",
      "-------------\n",
      "epoch 25 || Epoch_TRAIN_Loss:2440.2048 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.2235 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 26/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 17260 || Loss: 3.8375 || 10iter: 2.7781 sec.\n",
      "Iter 17270 || Loss: 4.1885 || 10iter: 1.3855 sec.\n",
      "Iter 17280 || Loss: 3.3889 || 10iter: 1.4486 sec.\n",
      "Iter 17290 || Loss: 3.7534 || 10iter: 1.4589 sec.\n",
      "Iter 17300 || Loss: 3.4733 || 10iter: 1.4229 sec.\n",
      "Iter 17310 || Loss: 3.7708 || 10iter: 1.4179 sec.\n",
      "Iter 17320 || Loss: 2.9539 || 10iter: 1.4216 sec.\n",
      "Iter 17330 || Loss: 3.9428 || 10iter: 1.3832 sec.\n",
      "Iter 17340 || Loss: 3.2258 || 10iter: 1.3719 sec.\n",
      "Iter 17350 || Loss: 3.7768 || 10iter: 1.4218 sec.\n",
      "Iter 17360 || Loss: 3.0332 || 10iter: 1.4952 sec.\n",
      "Iter 17370 || Loss: 3.8044 || 10iter: 1.4799 sec.\n",
      "Iter 17380 || Loss: 3.6834 || 10iter: 1.3791 sec.\n",
      "Iter 17390 || Loss: 3.0880 || 10iter: 1.3924 sec.\n",
      "Iter 17400 || Loss: 3.7250 || 10iter: 1.4055 sec.\n",
      "Iter 17410 || Loss: 4.1616 || 10iter: 1.4628 sec.\n",
      "Iter 17420 || Loss: 3.3832 || 10iter: 1.4545 sec.\n",
      "Iter 17430 || Loss: 3.3099 || 10iter: 1.3998 sec.\n",
      "Iter 17440 || Loss: 3.9962 || 10iter: 1.4106 sec.\n",
      "Iter 17450 || Loss: 3.4834 || 10iter: 1.4527 sec.\n",
      "Iter 17460 || Loss: 3.4892 || 10iter: 1.4098 sec.\n",
      "Iter 17470 || Loss: 4.1793 || 10iter: 1.4547 sec.\n",
      "Iter 17480 || Loss: 3.2516 || 10iter: 1.4223 sec.\n",
      "Iter 17490 || Loss: 3.1998 || 10iter: 1.4469 sec.\n",
      "Iter 17500 || Loss: 4.0183 || 10iter: 1.3959 sec.\n",
      "Iter 17510 || Loss: 3.6011 || 10iter: 1.4150 sec.\n",
      "Iter 17520 || Loss: 3.2778 || 10iter: 1.4445 sec.\n",
      "Iter 17530 || Loss: 3.6325 || 10iter: 1.3801 sec.\n",
      "Iter 17540 || Loss: 3.5989 || 10iter: 1.4647 sec.\n",
      "Iter 17550 || Loss: 3.4113 || 10iter: 1.4723 sec.\n",
      "Iter 17560 || Loss: 3.5596 || 10iter: 1.4411 sec.\n",
      "Iter 17570 || Loss: 3.6334 || 10iter: 1.4977 sec.\n",
      "Iter 17580 || Loss: 3.2345 || 10iter: 1.4393 sec.\n",
      "Iter 17590 || Loss: 3.3303 || 10iter: 1.4500 sec.\n",
      "Iter 17600 || Loss: 3.4458 || 10iter: 1.4439 sec.\n",
      "Iter 17610 || Loss: 3.6027 || 10iter: 1.3716 sec.\n",
      "Iter 17620 || Loss: 3.1348 || 10iter: 1.4220 sec.\n",
      "Iter 17630 || Loss: 3.5434 || 10iter: 1.3726 sec.\n",
      "Iter 17640 || Loss: 4.3326 || 10iter: 1.4292 sec.\n",
      "Iter 17650 || Loss: 3.5562 || 10iter: 1.4137 sec.\n",
      "Iter 17660 || Loss: 3.2690 || 10iter: 1.4441 sec.\n",
      "Iter 17670 || Loss: 2.9834 || 10iter: 1.4423 sec.\n",
      "Iter 17680 || Loss: 3.5687 || 10iter: 1.4313 sec.\n",
      "Iter 17690 || Loss: 3.0907 || 10iter: 1.4027 sec.\n",
      "Iter 17700 || Loss: 3.1246 || 10iter: 1.4448 sec.\n",
      "Iter 17710 || Loss: 3.3053 || 10iter: 1.4203 sec.\n",
      "Iter 17720 || Loss: 3.5403 || 10iter: 1.4551 sec.\n",
      "Iter 17730 || Loss: 3.7157 || 10iter: 1.4158 sec.\n",
      "Iter 17740 || Loss: 3.2524 || 10iter: 1.4595 sec.\n",
      "Iter 17750 || Loss: 3.6598 || 10iter: 1.3990 sec.\n",
      "Iter 17760 || Loss: 3.2290 || 10iter: 1.4128 sec.\n",
      "Iter 17770 || Loss: 3.5923 || 10iter: 1.3907 sec.\n",
      "Iter 17780 || Loss: 3.4483 || 10iter: 1.4145 sec.\n",
      "Iter 17790 || Loss: 3.5220 || 10iter: 1.4172 sec.\n",
      "Iter 17800 || Loss: 3.1307 || 10iter: 1.4637 sec.\n",
      "Iter 17810 || Loss: 3.5288 || 10iter: 1.4303 sec.\n",
      "Iter 17820 || Loss: 3.6982 || 10iter: 1.4759 sec.\n",
      "Iter 17830 || Loss: 3.4787 || 10iter: 1.5487 sec.\n",
      "Iter 17840 || Loss: 3.8616 || 10iter: 1.4225 sec.\n",
      "Iter 17850 || Loss: 3.9758 || 10iter: 1.3994 sec.\n",
      "Iter 17860 || Loss: 3.2781 || 10iter: 1.4595 sec.\n",
      "Iter 17870 || Loss: 3.1576 || 10iter: 1.4423 sec.\n",
      "Iter 17880 || Loss: 3.2543 || 10iter: 1.4835 sec.\n",
      "Iter 17890 || Loss: 3.2356 || 10iter: 1.4132 sec.\n",
      "Iter 17900 || Loss: 3.4541 || 10iter: 1.5035 sec.\n",
      "Iter 17910 || Loss: 3.2564 || 10iter: 1.4056 sec.\n",
      "Iter 17920 || Loss: 3.3276 || 10iter: 1.4347 sec.\n",
      "Iter 17930 || Loss: 3.6322 || 10iter: 1.3445 sec.\n",
      "Iter 17940 || Loss: 4.2704 || 10iter: 1.2600 sec.\n",
      "-------------\n",
      "epoch 26 || Epoch_TRAIN_Loss:2441.7536 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.0460 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 27/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 17950 || Loss: 3.9421 || 10iter: 2.6821 sec.\n",
      "Iter 17960 || Loss: 3.2831 || 10iter: 1.3695 sec.\n",
      "Iter 17970 || Loss: 3.6601 || 10iter: 1.4323 sec.\n",
      "Iter 17980 || Loss: 3.6830 || 10iter: 1.3741 sec.\n",
      "Iter 17990 || Loss: 3.6252 || 10iter: 1.4281 sec.\n",
      "Iter 18000 || Loss: 3.4771 || 10iter: 1.4261 sec.\n",
      "Iter 18010 || Loss: 4.3469 || 10iter: 1.4134 sec.\n",
      "Iter 18020 || Loss: 2.9686 || 10iter: 1.4241 sec.\n",
      "Iter 18030 || Loss: 3.1506 || 10iter: 1.4982 sec.\n",
      "Iter 18040 || Loss: 3.3258 || 10iter: 1.4250 sec.\n",
      "Iter 18050 || Loss: 3.2126 || 10iter: 1.4447 sec.\n",
      "Iter 18060 || Loss: 5.0718 || 10iter: 1.4352 sec.\n",
      "Iter 18070 || Loss: 3.4187 || 10iter: 1.4121 sec.\n",
      "Iter 18080 || Loss: 3.3081 || 10iter: 1.3902 sec.\n",
      "Iter 18090 || Loss: 3.7448 || 10iter: 1.4498 sec.\n",
      "Iter 18100 || Loss: 3.1753 || 10iter: 1.4229 sec.\n",
      "Iter 18110 || Loss: 3.4200 || 10iter: 1.4231 sec.\n",
      "Iter 18120 || Loss: 3.3234 || 10iter: 1.4429 sec.\n",
      "Iter 18130 || Loss: 3.7565 || 10iter: 1.3900 sec.\n",
      "Iter 18140 || Loss: 4.2666 || 10iter: 1.4706 sec.\n",
      "Iter 18150 || Loss: 3.8577 || 10iter: 1.4383 sec.\n",
      "Iter 18160 || Loss: 2.8217 || 10iter: 1.4678 sec.\n",
      "Iter 18170 || Loss: 3.9655 || 10iter: 1.3971 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 18180 || Loss: 4.0990 || 10iter: 1.4560 sec.\n",
      "Iter 18190 || Loss: 3.3583 || 10iter: 1.4049 sec.\n",
      "Iter 18200 || Loss: 3.6154 || 10iter: 1.4473 sec.\n",
      "Iter 18210 || Loss: 2.7192 || 10iter: 1.4466 sec.\n",
      "Iter 18220 || Loss: 3.8758 || 10iter: 1.4336 sec.\n",
      "Iter 18230 || Loss: 3.7849 || 10iter: 1.4259 sec.\n",
      "Iter 18240 || Loss: 3.4431 || 10iter: 1.4354 sec.\n",
      "Iter 18250 || Loss: 3.7518 || 10iter: 1.5044 sec.\n",
      "Iter 18260 || Loss: 3.3834 || 10iter: 1.4580 sec.\n",
      "Iter 18270 || Loss: 3.6703 || 10iter: 1.4298 sec.\n",
      "Iter 18280 || Loss: 3.5344 || 10iter: 1.4140 sec.\n",
      "Iter 18290 || Loss: 3.3847 || 10iter: 1.4407 sec.\n",
      "Iter 18300 || Loss: 2.8861 || 10iter: 1.4643 sec.\n",
      "Iter 18310 || Loss: 3.2278 || 10iter: 1.4421 sec.\n",
      "Iter 18320 || Loss: 3.7913 || 10iter: 1.3921 sec.\n",
      "Iter 18330 || Loss: 3.3890 || 10iter: 1.4255 sec.\n",
      "Iter 18340 || Loss: 3.8030 || 10iter: 1.4798 sec.\n",
      "Iter 18350 || Loss: 3.3507 || 10iter: 1.4451 sec.\n",
      "Iter 18360 || Loss: 3.8270 || 10iter: 1.4420 sec.\n",
      "Iter 18370 || Loss: 3.9451 || 10iter: 1.4661 sec.\n",
      "Iter 18380 || Loss: 4.0971 || 10iter: 1.4574 sec.\n",
      "Iter 18390 || Loss: 4.2649 || 10iter: 1.3994 sec.\n",
      "Iter 18400 || Loss: 2.9262 || 10iter: 1.5358 sec.\n",
      "Iter 18410 || Loss: 3.4449 || 10iter: 1.4888 sec.\n",
      "Iter 18420 || Loss: 3.4961 || 10iter: 1.4299 sec.\n",
      "Iter 18430 || Loss: 2.9888 || 10iter: 1.4359 sec.\n",
      "Iter 18440 || Loss: 3.6787 || 10iter: 1.4381 sec.\n",
      "Iter 18450 || Loss: 3.9005 || 10iter: 1.4772 sec.\n",
      "Iter 18460 || Loss: 3.6402 || 10iter: 1.4610 sec.\n",
      "Iter 18470 || Loss: 3.4992 || 10iter: 1.4546 sec.\n",
      "Iter 18480 || Loss: 3.6063 || 10iter: 1.4746 sec.\n",
      "Iter 18490 || Loss: 3.2417 || 10iter: 1.4350 sec.\n",
      "Iter 18500 || Loss: 3.3801 || 10iter: 1.4415 sec.\n",
      "Iter 18510 || Loss: 3.3959 || 10iter: 1.4322 sec.\n",
      "Iter 18520 || Loss: 3.7121 || 10iter: 1.4245 sec.\n",
      "Iter 18530 || Loss: 3.2408 || 10iter: 1.4606 sec.\n",
      "Iter 18540 || Loss: 4.2552 || 10iter: 1.3856 sec.\n",
      "Iter 18550 || Loss: 3.2832 || 10iter: 1.4005 sec.\n",
      "Iter 18560 || Loss: 3.8079 || 10iter: 1.4438 sec.\n",
      "Iter 18570 || Loss: 3.4261 || 10iter: 1.4364 sec.\n",
      "Iter 18580 || Loss: 3.9645 || 10iter: 1.4159 sec.\n",
      "Iter 18590 || Loss: 3.9936 || 10iter: 1.5006 sec.\n",
      "Iter 18600 || Loss: 2.8682 || 10iter: 1.4322 sec.\n",
      "Iter 18610 || Loss: 2.7771 || 10iter: 1.4992 sec.\n",
      "Iter 18620 || Loss: 3.3571 || 10iter: 1.3626 sec.\n",
      "Iter 18630 || Loss: 2.9331 || 10iter: 1.2595 sec.\n",
      "-------------\n",
      "epoch 27 || Epoch_TRAIN_Loss:2414.3657 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.4690 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 28/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 18640 || Loss: 3.2831 || 10iter: 2.7781 sec.\n",
      "Iter 18650 || Loss: 3.1419 || 10iter: 1.3231 sec.\n",
      "Iter 18660 || Loss: 3.1074 || 10iter: 1.3923 sec.\n",
      "Iter 18670 || Loss: 3.3703 || 10iter: 1.4323 sec.\n",
      "Iter 18680 || Loss: 2.8542 || 10iter: 1.4573 sec.\n",
      "Iter 18690 || Loss: 3.1496 || 10iter: 1.4552 sec.\n",
      "Iter 18700 || Loss: 3.6559 || 10iter: 1.3993 sec.\n",
      "Iter 18710 || Loss: 3.5493 || 10iter: 1.3989 sec.\n",
      "Iter 18720 || Loss: 3.4158 || 10iter: 1.4478 sec.\n",
      "Iter 18730 || Loss: 3.3391 || 10iter: 1.3946 sec.\n",
      "Iter 18740 || Loss: 3.2843 || 10iter: 1.4584 sec.\n",
      "Iter 18750 || Loss: 4.2970 || 10iter: 1.4161 sec.\n",
      "Iter 18760 || Loss: 3.5228 || 10iter: 1.4731 sec.\n",
      "Iter 18770 || Loss: 3.7737 || 10iter: 1.4592 sec.\n",
      "Iter 18780 || Loss: 3.1149 || 10iter: 1.4491 sec.\n",
      "Iter 18790 || Loss: 3.8258 || 10iter: 1.4695 sec.\n",
      "Iter 18800 || Loss: 3.1423 || 10iter: 1.4645 sec.\n",
      "Iter 18810 || Loss: 3.4622 || 10iter: 1.4523 sec.\n",
      "Iter 18820 || Loss: 3.4056 || 10iter: 1.4055 sec.\n",
      "Iter 18830 || Loss: 3.6989 || 10iter: 1.4321 sec.\n",
      "Iter 18840 || Loss: 3.8504 || 10iter: 1.4327 sec.\n",
      "Iter 18850 || Loss: 4.4074 || 10iter: 1.4506 sec.\n",
      "Iter 18860 || Loss: 3.0773 || 10iter: 1.4541 sec.\n",
      "Iter 18870 || Loss: 3.3832 || 10iter: 1.4737 sec.\n",
      "Iter 18880 || Loss: 2.9080 || 10iter: 1.4205 sec.\n",
      "Iter 18890 || Loss: 3.8583 || 10iter: 1.4135 sec.\n",
      "Iter 18900 || Loss: 3.9066 || 10iter: 1.4456 sec.\n",
      "Iter 18910 || Loss: 4.0296 || 10iter: 1.4283 sec.\n",
      "Iter 18920 || Loss: 3.5249 || 10iter: 1.4320 sec.\n",
      "Iter 18930 || Loss: 3.1416 || 10iter: 1.4386 sec.\n",
      "Iter 18940 || Loss: 3.3818 || 10iter: 1.4560 sec.\n",
      "Iter 18950 || Loss: 3.5766 || 10iter: 1.4036 sec.\n",
      "Iter 18960 || Loss: 4.1704 || 10iter: 1.4119 sec.\n",
      "Iter 18970 || Loss: 3.0082 || 10iter: 1.4205 sec.\n",
      "Iter 18980 || Loss: 3.3362 || 10iter: 1.4427 sec.\n",
      "Iter 18990 || Loss: 3.1580 || 10iter: 1.4401 sec.\n",
      "Iter 19000 || Loss: 3.5617 || 10iter: 1.4074 sec.\n",
      "Iter 19010 || Loss: 3.4524 || 10iter: 1.4502 sec.\n",
      "Iter 19020 || Loss: 3.5281 || 10iter: 1.3926 sec.\n",
      "Iter 19030 || Loss: 3.2733 || 10iter: 1.4861 sec.\n",
      "Iter 19040 || Loss: 3.5663 || 10iter: 1.5144 sec.\n",
      "Iter 19050 || Loss: 2.9509 || 10iter: 1.4426 sec.\n",
      "Iter 19060 || Loss: 3.5291 || 10iter: 1.4677 sec.\n",
      "Iter 19070 || Loss: 3.8854 || 10iter: 1.4529 sec.\n",
      "Iter 19080 || Loss: 3.6976 || 10iter: 1.4364 sec.\n",
      "Iter 19090 || Loss: 3.4223 || 10iter: 1.4578 sec.\n",
      "Iter 19100 || Loss: 3.4392 || 10iter: 1.4299 sec.\n",
      "Iter 19110 || Loss: 3.5833 || 10iter: 1.3840 sec.\n",
      "Iter 19120 || Loss: 3.4927 || 10iter: 1.4365 sec.\n",
      "Iter 19130 || Loss: 3.7666 || 10iter: 1.3889 sec.\n",
      "Iter 19140 || Loss: 3.5516 || 10iter: 1.4713 sec.\n",
      "Iter 19150 || Loss: 3.0319 || 10iter: 1.4137 sec.\n",
      "Iter 19160 || Loss: 3.5141 || 10iter: 1.4352 sec.\n",
      "Iter 19170 || Loss: 3.4159 || 10iter: 1.4036 sec.\n",
      "Iter 19180 || Loss: 3.2787 || 10iter: 1.4273 sec.\n",
      "Iter 19190 || Loss: 3.5073 || 10iter: 1.4628 sec.\n",
      "Iter 19200 || Loss: 2.9288 || 10iter: 1.4709 sec.\n",
      "Iter 19210 || Loss: 3.5645 || 10iter: 1.4560 sec.\n",
      "Iter 19220 || Loss: 3.4570 || 10iter: 1.4342 sec.\n",
      "Iter 19230 || Loss: 3.4293 || 10iter: 1.3800 sec.\n",
      "Iter 19240 || Loss: 4.1576 || 10iter: 1.4219 sec.\n",
      "Iter 19250 || Loss: 3.0620 || 10iter: 1.4164 sec.\n",
      "Iter 19260 || Loss: 2.9218 || 10iter: 1.4001 sec.\n",
      "Iter 19270 || Loss: 3.3540 || 10iter: 1.4293 sec.\n",
      "Iter 19280 || Loss: 2.8818 || 10iter: 1.4085 sec.\n",
      "Iter 19290 || Loss: 3.6732 || 10iter: 1.4344 sec.\n",
      "Iter 19300 || Loss: 3.9054 || 10iter: 1.4258 sec.\n",
      "Iter 19310 || Loss: 3.8255 || 10iter: 1.3331 sec.\n",
      "Iter 19320 || Loss: 4.1387 || 10iter: 1.2768 sec.\n",
      "-------------\n",
      "epoch 28 || Epoch_TRAIN_Loss:2407.3253 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.1440 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 29/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 19330 || Loss: 3.1007 || 10iter: 2.8190 sec.\n",
      "Iter 19340 || Loss: 3.0851 || 10iter: 1.3871 sec.\n",
      "Iter 19350 || Loss: 4.2081 || 10iter: 1.4051 sec.\n",
      "Iter 19360 || Loss: 3.5090 || 10iter: 1.4384 sec.\n",
      "Iter 19370 || Loss: 3.4203 || 10iter: 1.4167 sec.\n",
      "Iter 19380 || Loss: 3.1427 || 10iter: 1.4053 sec.\n",
      "Iter 19390 || Loss: 3.7006 || 10iter: 1.4172 sec.\n",
      "Iter 19400 || Loss: 3.5470 || 10iter: 1.4343 sec.\n",
      "Iter 19410 || Loss: 3.1705 || 10iter: 1.4329 sec.\n",
      "Iter 19420 || Loss: 3.5459 || 10iter: 1.4074 sec.\n",
      "Iter 19430 || Loss: 3.5211 || 10iter: 1.4552 sec.\n",
      "Iter 19440 || Loss: 3.2087 || 10iter: 1.5120 sec.\n",
      "Iter 19450 || Loss: 4.0934 || 10iter: 1.4322 sec.\n",
      "Iter 19460 || Loss: 3.6793 || 10iter: 1.4480 sec.\n",
      "Iter 19470 || Loss: 3.4105 || 10iter: 1.3990 sec.\n",
      "Iter 19480 || Loss: 2.9468 || 10iter: 1.4263 sec.\n",
      "Iter 19490 || Loss: 3.5275 || 10iter: 1.4747 sec.\n",
      "Iter 19500 || Loss: 3.4143 || 10iter: 1.4398 sec.\n",
      "Iter 19510 || Loss: 3.5739 || 10iter: 1.4455 sec.\n",
      "Iter 19520 || Loss: 3.0653 || 10iter: 1.4269 sec.\n",
      "Iter 19530 || Loss: 3.7462 || 10iter: 1.4979 sec.\n",
      "Iter 19540 || Loss: 3.5305 || 10iter: 1.4407 sec.\n",
      "Iter 19550 || Loss: 3.2134 || 10iter: 1.4394 sec.\n",
      "Iter 19560 || Loss: 3.5856 || 10iter: 1.4304 sec.\n",
      "Iter 19570 || Loss: 3.5252 || 10iter: 1.4499 sec.\n",
      "Iter 19580 || Loss: 3.6062 || 10iter: 1.4749 sec.\n",
      "Iter 19590 || Loss: 3.5002 || 10iter: 1.4374 sec.\n",
      "Iter 19600 || Loss: 3.7096 || 10iter: 1.4459 sec.\n",
      "Iter 19610 || Loss: 4.0050 || 10iter: 1.4831 sec.\n",
      "Iter 19620 || Loss: 3.6200 || 10iter: 1.4941 sec.\n",
      "Iter 19630 || Loss: 3.8484 || 10iter: 1.4356 sec.\n",
      "Iter 19640 || Loss: 3.9790 || 10iter: 1.4236 sec.\n",
      "Iter 19650 || Loss: 3.5105 || 10iter: 1.4199 sec.\n",
      "Iter 19660 || Loss: 3.1074 || 10iter: 1.4654 sec.\n",
      "Iter 19670 || Loss: 3.5309 || 10iter: 1.5030 sec.\n",
      "Iter 19680 || Loss: 2.8353 || 10iter: 1.4157 sec.\n",
      "Iter 19690 || Loss: 3.5245 || 10iter: 1.4076 sec.\n",
      "Iter 19700 || Loss: 3.7737 || 10iter: 1.4082 sec.\n",
      "Iter 19710 || Loss: 3.6743 || 10iter: 1.4981 sec.\n",
      "Iter 19720 || Loss: 3.3295 || 10iter: 1.4613 sec.\n",
      "Iter 19730 || Loss: 3.5857 || 10iter: 1.3919 sec.\n",
      "Iter 19740 || Loss: 3.3467 || 10iter: 1.4556 sec.\n",
      "Iter 19750 || Loss: 3.8066 || 10iter: 1.4268 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 19760 || Loss: 2.2794 || 10iter: 1.4139 sec.\n",
      "Iter 19770 || Loss: 4.2602 || 10iter: 1.4437 sec.\n",
      "Iter 19780 || Loss: 3.3424 || 10iter: 1.4763 sec.\n",
      "Iter 19790 || Loss: 3.1074 || 10iter: 1.5038 sec.\n",
      "Iter 19800 || Loss: 4.3617 || 10iter: 1.4808 sec.\n",
      "Iter 19810 || Loss: 3.0624 || 10iter: 1.3894 sec.\n",
      "Iter 19820 || Loss: 2.9589 || 10iter: 1.4177 sec.\n",
      "Iter 19830 || Loss: 3.1582 || 10iter: 1.4136 sec.\n",
      "Iter 19840 || Loss: 4.0858 || 10iter: 1.4008 sec.\n",
      "Iter 19850 || Loss: 3.2042 || 10iter: 1.4367 sec.\n",
      "Iter 19860 || Loss: 3.2770 || 10iter: 1.4169 sec.\n",
      "Iter 19870 || Loss: 3.5381 || 10iter: 1.4345 sec.\n",
      "Iter 19880 || Loss: 3.7213 || 10iter: 1.4483 sec.\n",
      "Iter 19890 || Loss: 3.5045 || 10iter: 1.4627 sec.\n",
      "Iter 19900 || Loss: 3.3306 || 10iter: 1.3756 sec.\n",
      "Iter 19910 || Loss: 3.8794 || 10iter: 1.4793 sec.\n",
      "Iter 19920 || Loss: 3.5874 || 10iter: 1.4236 sec.\n",
      "Iter 19930 || Loss: 3.4147 || 10iter: 1.4141 sec.\n",
      "Iter 19940 || Loss: 3.4987 || 10iter: 1.3961 sec.\n",
      "Iter 19950 || Loss: 3.2184 || 10iter: 1.5002 sec.\n",
      "Iter 19960 || Loss: 3.8439 || 10iter: 1.4598 sec.\n",
      "Iter 19970 || Loss: 3.6185 || 10iter: 1.4374 sec.\n",
      "Iter 19980 || Loss: 3.9600 || 10iter: 1.4329 sec.\n",
      "Iter 19990 || Loss: 3.4223 || 10iter: 1.4182 sec.\n",
      "Iter 20000 || Loss: 3.3946 || 10iter: 1.3587 sec.\n",
      "Iter 20010 || Loss: 3.4328 || 10iter: 1.2766 sec.\n",
      "-------------\n",
      "epoch 29 || Epoch_TRAIN_Loss:2402.6046 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.5562 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 30/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 20020 || Loss: 3.3893 || 10iter: 2.7369 sec.\n",
      "Iter 20030 || Loss: 3.1979 || 10iter: 1.3465 sec.\n",
      "Iter 20040 || Loss: 3.9141 || 10iter: 1.4154 sec.\n",
      "Iter 20050 || Loss: 3.6530 || 10iter: 1.4763 sec.\n",
      "Iter 20060 || Loss: 3.8834 || 10iter: 1.4301 sec.\n",
      "Iter 20070 || Loss: 3.6380 || 10iter: 1.3938 sec.\n",
      "Iter 20080 || Loss: 3.9275 || 10iter: 1.4563 sec.\n",
      "Iter 20090 || Loss: 2.7508 || 10iter: 1.3762 sec.\n",
      "Iter 20100 || Loss: 3.5591 || 10iter: 1.4445 sec.\n",
      "Iter 20110 || Loss: 3.6887 || 10iter: 1.4271 sec.\n",
      "Iter 20120 || Loss: 3.1931 || 10iter: 1.4378 sec.\n",
      "Iter 20130 || Loss: 3.7618 || 10iter: 1.4251 sec.\n",
      "Iter 20140 || Loss: 3.2191 || 10iter: 1.4293 sec.\n",
      "Iter 20150 || Loss: 3.4560 || 10iter: 1.4690 sec.\n",
      "Iter 20160 || Loss: 3.1568 || 10iter: 1.4581 sec.\n",
      "Iter 20170 || Loss: 3.7333 || 10iter: 1.4200 sec.\n",
      "Iter 20180 || Loss: 3.6980 || 10iter: 1.4308 sec.\n",
      "Iter 20190 || Loss: 4.2199 || 10iter: 1.4341 sec.\n",
      "Iter 20200 || Loss: 3.5188 || 10iter: 1.3929 sec.\n",
      "Iter 20210 || Loss: 3.8340 || 10iter: 1.4336 sec.\n",
      "Iter 20220 || Loss: 3.5763 || 10iter: 1.4253 sec.\n",
      "Iter 20230 || Loss: 3.8120 || 10iter: 1.4568 sec.\n",
      "Iter 20240 || Loss: 3.6910 || 10iter: 1.4600 sec.\n",
      "Iter 20250 || Loss: 3.4795 || 10iter: 1.5478 sec.\n",
      "Iter 20260 || Loss: 3.7732 || 10iter: 1.4673 sec.\n",
      "Iter 20270 || Loss: 2.6148 || 10iter: 1.4271 sec.\n",
      "Iter 20280 || Loss: 3.8814 || 10iter: 1.4429 sec.\n",
      "Iter 20290 || Loss: 3.4337 || 10iter: 1.4252 sec.\n",
      "Iter 20300 || Loss: 3.3803 || 10iter: 1.4155 sec.\n",
      "Iter 20310 || Loss: 3.0172 || 10iter: 1.4654 sec.\n",
      "Iter 20320 || Loss: 3.0223 || 10iter: 1.4511 sec.\n",
      "Iter 20330 || Loss: 3.7136 || 10iter: 1.4728 sec.\n",
      "Iter 20340 || Loss: 3.4131 || 10iter: 1.4611 sec.\n",
      "Iter 20350 || Loss: 3.4984 || 10iter: 1.4004 sec.\n",
      "Iter 20360 || Loss: 2.6742 || 10iter: 1.4075 sec.\n",
      "Iter 20370 || Loss: 3.4284 || 10iter: 1.4678 sec.\n",
      "Iter 20380 || Loss: 3.9184 || 10iter: 1.4557 sec.\n",
      "Iter 20390 || Loss: 3.0891 || 10iter: 1.3769 sec.\n",
      "Iter 20400 || Loss: 3.4965 || 10iter: 1.4006 sec.\n",
      "Iter 20410 || Loss: 3.6535 || 10iter: 1.4196 sec.\n",
      "Iter 20420 || Loss: 3.8859 || 10iter: 1.4060 sec.\n",
      "Iter 20430 || Loss: 3.5082 || 10iter: 1.4253 sec.\n",
      "Iter 20440 || Loss: 3.3563 || 10iter: 1.4719 sec.\n",
      "Iter 20450 || Loss: 3.3763 || 10iter: 1.4574 sec.\n",
      "Iter 20460 || Loss: 3.1171 || 10iter: 1.4013 sec.\n",
      "Iter 20470 || Loss: 3.3913 || 10iter: 1.4628 sec.\n",
      "Iter 20480 || Loss: 2.6614 || 10iter: 1.4687 sec.\n",
      "Iter 20490 || Loss: 3.3954 || 10iter: 1.4971 sec.\n",
      "Iter 20500 || Loss: 2.8892 || 10iter: 1.5207 sec.\n",
      "Iter 20510 || Loss: 3.4325 || 10iter: 1.4886 sec.\n",
      "Iter 20520 || Loss: 3.4314 || 10iter: 1.4257 sec.\n",
      "Iter 20530 || Loss: 3.6523 || 10iter: 1.4441 sec.\n",
      "Iter 20540 || Loss: 3.6293 || 10iter: 1.4248 sec.\n",
      "Iter 20550 || Loss: 3.2302 || 10iter: 1.4182 sec.\n",
      "Iter 20560 || Loss: 3.6254 || 10iter: 1.4288 sec.\n",
      "Iter 20570 || Loss: 3.5115 || 10iter: 1.4022 sec.\n",
      "Iter 20580 || Loss: 3.3441 || 10iter: 1.4754 sec.\n",
      "Iter 20590 || Loss: 3.6454 || 10iter: 1.4312 sec.\n",
      "Iter 20600 || Loss: 3.9841 || 10iter: 1.4203 sec.\n",
      "Iter 20610 || Loss: 2.6721 || 10iter: 1.4065 sec.\n",
      "Iter 20620 || Loss: 2.9838 || 10iter: 1.4334 sec.\n",
      "Iter 20630 || Loss: 3.8292 || 10iter: 1.4766 sec.\n",
      "Iter 20640 || Loss: 2.9798 || 10iter: 1.4104 sec.\n",
      "Iter 20650 || Loss: 3.9250 || 10iter: 1.4433 sec.\n",
      "Iter 20660 || Loss: 3.9074 || 10iter: 1.4364 sec.\n",
      "Iter 20670 || Loss: 3.2196 || 10iter: 1.4270 sec.\n",
      "Iter 20680 || Loss: 3.0859 || 10iter: 1.4405 sec.\n",
      "Iter 20690 || Loss: 3.4458 || 10iter: 1.3477 sec.\n",
      "Iter 20700 || Loss: 3.1335 || 10iter: 1.2549 sec.\n",
      "-------------\n",
      "(val)\n",
      "-------------\n",
      "epoch 30 || Epoch_TRAIN_Loss:2386.9213 ||Epoch_VAL_Loss:703.9960\n",
      "timer:  120.5998 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 31/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 20710 || Loss: 3.5817 || 10iter: 2.8201 sec.\n",
      "Iter 20720 || Loss: 3.3328 || 10iter: 1.3524 sec.\n",
      "Iter 20730 || Loss: 3.3199 || 10iter: 1.4549 sec.\n",
      "Iter 20740 || Loss: 2.8765 || 10iter: 1.4139 sec.\n",
      "Iter 20750 || Loss: 4.0769 || 10iter: 1.4588 sec.\n",
      "Iter 20760 || Loss: 3.5060 || 10iter: 1.4160 sec.\n",
      "Iter 20770 || Loss: 3.3551 || 10iter: 1.4042 sec.\n",
      "Iter 20780 || Loss: 3.7992 || 10iter: 1.4111 sec.\n",
      "Iter 20790 || Loss: 3.2055 || 10iter: 1.4510 sec.\n",
      "Iter 20800 || Loss: 3.1273 || 10iter: 1.4194 sec.\n",
      "Iter 20810 || Loss: 3.1649 || 10iter: 1.4698 sec.\n",
      "Iter 20820 || Loss: 3.4962 || 10iter: 1.4359 sec.\n",
      "Iter 20830 || Loss: 3.5666 || 10iter: 1.4204 sec.\n",
      "Iter 20840 || Loss: 3.4066 || 10iter: 1.3941 sec.\n",
      "Iter 20850 || Loss: 3.4202 || 10iter: 1.4821 sec.\n",
      "Iter 20860 || Loss: 3.6806 || 10iter: 1.4035 sec.\n",
      "Iter 20870 || Loss: 3.5398 || 10iter: 1.4749 sec.\n",
      "Iter 20880 || Loss: 3.2931 || 10iter: 1.4536 sec.\n",
      "Iter 20890 || Loss: 3.1948 || 10iter: 1.4117 sec.\n",
      "Iter 20900 || Loss: 2.9894 || 10iter: 1.4309 sec.\n",
      "Iter 20910 || Loss: 3.0694 || 10iter: 1.4484 sec.\n",
      "Iter 20920 || Loss: 2.9035 || 10iter: 1.4493 sec.\n",
      "Iter 20930 || Loss: 3.3719 || 10iter: 1.4749 sec.\n",
      "Iter 20940 || Loss: 3.4944 || 10iter: 1.3891 sec.\n",
      "Iter 20950 || Loss: 3.3086 || 10iter: 1.4057 sec.\n",
      "Iter 20960 || Loss: 3.6583 || 10iter: 1.3797 sec.\n",
      "Iter 20970 || Loss: 3.5858 || 10iter: 1.3829 sec.\n",
      "Iter 20980 || Loss: 3.9383 || 10iter: 1.4756 sec.\n",
      "Iter 20990 || Loss: 3.4007 || 10iter: 1.4434 sec.\n",
      "Iter 21000 || Loss: 4.0224 || 10iter: 1.4417 sec.\n",
      "Iter 21010 || Loss: 3.4492 || 10iter: 1.4668 sec.\n",
      "Iter 21020 || Loss: 3.7304 || 10iter: 1.4544 sec.\n",
      "Iter 21030 || Loss: 3.5532 || 10iter: 1.4565 sec.\n",
      "Iter 21040 || Loss: 3.4692 || 10iter: 1.4104 sec.\n",
      "Iter 21050 || Loss: 3.5897 || 10iter: 1.4936 sec.\n",
      "Iter 21060 || Loss: 3.3609 || 10iter: 1.4351 sec.\n",
      "Iter 21070 || Loss: 3.3307 || 10iter: 1.4224 sec.\n",
      "Iter 21080 || Loss: 3.2767 || 10iter: 1.3921 sec.\n",
      "Iter 21090 || Loss: 3.2265 || 10iter: 1.4045 sec.\n",
      "Iter 21100 || Loss: 3.7195 || 10iter: 1.4460 sec.\n",
      "Iter 21110 || Loss: 3.7143 || 10iter: 1.3757 sec.\n",
      "Iter 21120 || Loss: 3.7247 || 10iter: 1.4522 sec.\n",
      "Iter 21130 || Loss: 4.3228 || 10iter: 1.4661 sec.\n",
      "Iter 21140 || Loss: 3.7097 || 10iter: 1.4716 sec.\n",
      "Iter 21150 || Loss: 3.2849 || 10iter: 1.4513 sec.\n",
      "Iter 21160 || Loss: 3.6181 || 10iter: 1.5033 sec.\n",
      "Iter 21170 || Loss: 3.3007 || 10iter: 1.4102 sec.\n",
      "Iter 21180 || Loss: 2.9406 || 10iter: 1.4578 sec.\n",
      "Iter 21190 || Loss: 3.5663 || 10iter: 1.4318 sec.\n",
      "Iter 21200 || Loss: 4.0342 || 10iter: 1.4372 sec.\n",
      "Iter 21210 || Loss: 3.7767 || 10iter: 1.4230 sec.\n",
      "Iter 21220 || Loss: 3.4013 || 10iter: 1.4655 sec.\n",
      "Iter 21230 || Loss: 3.5104 || 10iter: 1.4587 sec.\n",
      "Iter 21240 || Loss: 3.9873 || 10iter: 1.4073 sec.\n",
      "Iter 21250 || Loss: 3.1842 || 10iter: 1.3964 sec.\n",
      "Iter 21260 || Loss: 3.3306 || 10iter: 1.4174 sec.\n",
      "Iter 21270 || Loss: 3.6100 || 10iter: 1.4250 sec.\n",
      "Iter 21280 || Loss: 3.4007 || 10iter: 1.4515 sec.\n",
      "Iter 21290 || Loss: 3.4484 || 10iter: 1.4427 sec.\n",
      "Iter 21300 || Loss: 3.1829 || 10iter: 1.4098 sec.\n",
      "Iter 21310 || Loss: 2.8557 || 10iter: 1.3994 sec.\n",
      "Iter 21320 || Loss: 3.5415 || 10iter: 1.4324 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 21330 || Loss: 3.7154 || 10iter: 1.4107 sec.\n",
      "Iter 21340 || Loss: 3.3825 || 10iter: 1.5209 sec.\n",
      "Iter 21350 || Loss: 3.2818 || 10iter: 1.4882 sec.\n",
      "Iter 21360 || Loss: 3.4244 || 10iter: 1.4301 sec.\n",
      "Iter 21370 || Loss: 3.4515 || 10iter: 1.4441 sec.\n",
      "Iter 21380 || Loss: 3.0089 || 10iter: 1.3329 sec.\n",
      "Iter 21390 || Loss: 3.4864 || 10iter: 1.2548 sec.\n",
      "-------------\n",
      "epoch 31 || Epoch_TRAIN_Loss:2384.7828 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.2685 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 32/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 21400 || Loss: 3.3839 || 10iter: 2.7535 sec.\n",
      "Iter 21410 || Loss: 3.0419 || 10iter: 1.3967 sec.\n",
      "Iter 21420 || Loss: 3.0637 || 10iter: 1.4241 sec.\n",
      "Iter 21430 || Loss: 3.7290 || 10iter: 1.4410 sec.\n",
      "Iter 21440 || Loss: 3.7062 || 10iter: 1.4310 sec.\n",
      "Iter 21450 || Loss: 3.5017 || 10iter: 1.3722 sec.\n",
      "Iter 21460 || Loss: 3.3623 || 10iter: 1.4024 sec.\n",
      "Iter 21470 || Loss: 3.1142 || 10iter: 1.4100 sec.\n",
      "Iter 21480 || Loss: 3.6819 || 10iter: 1.4195 sec.\n",
      "Iter 21490 || Loss: 3.5266 || 10iter: 1.4116 sec.\n",
      "Iter 21500 || Loss: 3.3676 || 10iter: 1.4337 sec.\n",
      "Iter 21510 || Loss: 3.5958 || 10iter: 1.4057 sec.\n",
      "Iter 21520 || Loss: 3.2791 || 10iter: 1.4539 sec.\n",
      "Iter 21530 || Loss: 2.8962 || 10iter: 1.3897 sec.\n",
      "Iter 21540 || Loss: 3.6669 || 10iter: 1.4758 sec.\n",
      "Iter 21550 || Loss: 3.5999 || 10iter: 1.4497 sec.\n",
      "Iter 21560 || Loss: 2.7059 || 10iter: 1.4150 sec.\n",
      "Iter 21570 || Loss: 3.3977 || 10iter: 1.4205 sec.\n",
      "Iter 21580 || Loss: 2.5765 || 10iter: 1.3700 sec.\n",
      "Iter 21590 || Loss: 3.1935 || 10iter: 1.4008 sec.\n",
      "Iter 21600 || Loss: 3.2014 || 10iter: 1.4572 sec.\n",
      "Iter 21610 || Loss: 3.1649 || 10iter: 1.4727 sec.\n",
      "Iter 21620 || Loss: 3.7041 || 10iter: 1.4750 sec.\n",
      "Iter 21630 || Loss: 4.3248 || 10iter: 1.4102 sec.\n",
      "Iter 21640 || Loss: 3.8951 || 10iter: 1.4452 sec.\n",
      "Iter 21650 || Loss: 2.7695 || 10iter: 1.3920 sec.\n",
      "Iter 21660 || Loss: 3.3193 || 10iter: 1.4473 sec.\n",
      "Iter 21670 || Loss: 3.5528 || 10iter: 1.4528 sec.\n",
      "Iter 21680 || Loss: 3.0726 || 10iter: 1.4918 sec.\n",
      "Iter 21690 || Loss: 3.4654 || 10iter: 1.4638 sec.\n",
      "Iter 21700 || Loss: 4.0118 || 10iter: 1.5415 sec.\n",
      "Iter 21710 || Loss: 3.9403 || 10iter: 1.4693 sec.\n",
      "Iter 21720 || Loss: 3.0515 || 10iter: 1.4174 sec.\n",
      "Iter 21730 || Loss: 3.6438 || 10iter: 1.4605 sec.\n",
      "Iter 21740 || Loss: 3.1733 || 10iter: 1.4743 sec.\n",
      "Iter 21750 || Loss: 3.7548 || 10iter: 1.4492 sec.\n",
      "Iter 21760 || Loss: 3.2388 || 10iter: 1.4136 sec.\n",
      "Iter 21770 || Loss: 2.8686 || 10iter: 1.3971 sec.\n",
      "Iter 21780 || Loss: 3.3669 || 10iter: 1.4236 sec.\n",
      "Iter 21790 || Loss: 2.7090 || 10iter: 1.4003 sec.\n",
      "Iter 21800 || Loss: 3.9653 || 10iter: 1.4578 sec.\n",
      "Iter 21810 || Loss: 3.6619 || 10iter: 1.4028 sec.\n",
      "Iter 21820 || Loss: 4.1286 || 10iter: 1.4052 sec.\n",
      "Iter 21830 || Loss: 3.0012 || 10iter: 1.4499 sec.\n",
      "Iter 21840 || Loss: 3.0367 || 10iter: 1.4864 sec.\n",
      "Iter 21850 || Loss: 4.4212 || 10iter: 1.4410 sec.\n",
      "Iter 21860 || Loss: 3.4811 || 10iter: 1.4341 sec.\n",
      "Iter 21870 || Loss: 3.2788 || 10iter: 1.4777 sec.\n",
      "Iter 21880 || Loss: 3.4203 || 10iter: 1.4073 sec.\n",
      "Iter 21890 || Loss: 3.5068 || 10iter: 1.4289 sec.\n",
      "Iter 21900 || Loss: 3.6192 || 10iter: 1.4931 sec.\n",
      "Iter 21910 || Loss: 3.2502 || 10iter: 1.4732 sec.\n",
      "Iter 21920 || Loss: 3.4324 || 10iter: 1.4435 sec.\n",
      "Iter 21930 || Loss: 3.7998 || 10iter: 1.4939 sec.\n",
      "Iter 21940 || Loss: 3.4935 || 10iter: 1.4094 sec.\n",
      "Iter 21950 || Loss: 3.6341 || 10iter: 1.4795 sec.\n",
      "Iter 21960 || Loss: 3.3780 || 10iter: 1.4405 sec.\n",
      "Iter 21970 || Loss: 3.3504 || 10iter: 1.4269 sec.\n",
      "Iter 21980 || Loss: 3.5409 || 10iter: 1.4179 sec.\n",
      "Iter 21990 || Loss: 3.5396 || 10iter: 1.4199 sec.\n",
      "Iter 22000 || Loss: 3.2512 || 10iter: 1.3690 sec.\n",
      "Iter 22010 || Loss: 3.7305 || 10iter: 1.4769 sec.\n",
      "Iter 22020 || Loss: 3.6331 || 10iter: 1.4266 sec.\n",
      "Iter 22030 || Loss: 3.1240 || 10iter: 1.4433 sec.\n",
      "Iter 22040 || Loss: 3.2832 || 10iter: 1.4276 sec.\n",
      "Iter 22050 || Loss: 3.1904 || 10iter: 1.4345 sec.\n",
      "Iter 22060 || Loss: 3.3865 || 10iter: 1.4611 sec.\n",
      "Iter 22070 || Loss: 3.9069 || 10iter: 1.3643 sec.\n",
      "Iter 22080 || Loss: 3.5284 || 10iter: 1.2665 sec.\n",
      "-------------\n",
      "epoch 32 || Epoch_TRAIN_Loss:2379.1285 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.2925 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 33/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 22090 || Loss: 3.5570 || 10iter: 2.7419 sec.\n",
      "Iter 22100 || Loss: 2.8444 || 10iter: 1.4092 sec.\n",
      "Iter 22110 || Loss: 3.5512 || 10iter: 1.4076 sec.\n",
      "Iter 22120 || Loss: 3.0474 || 10iter: 1.4177 sec.\n",
      "Iter 22130 || Loss: 3.4727 || 10iter: 1.3978 sec.\n",
      "Iter 22140 || Loss: 3.2694 || 10iter: 1.4052 sec.\n",
      "Iter 22150 || Loss: 2.8610 || 10iter: 1.4264 sec.\n",
      "Iter 22160 || Loss: 3.6411 || 10iter: 1.3935 sec.\n",
      "Iter 22170 || Loss: 4.1677 || 10iter: 1.3993 sec.\n",
      "Iter 22180 || Loss: 3.4253 || 10iter: 1.4201 sec.\n",
      "Iter 22190 || Loss: 2.5943 || 10iter: 1.4606 sec.\n",
      "Iter 22200 || Loss: 2.6433 || 10iter: 1.4135 sec.\n",
      "Iter 22210 || Loss: 3.5780 || 10iter: 1.4069 sec.\n",
      "Iter 22220 || Loss: 3.2586 || 10iter: 1.4600 sec.\n",
      "Iter 22230 || Loss: 3.2366 || 10iter: 1.4356 sec.\n",
      "Iter 22240 || Loss: 3.9773 || 10iter: 1.4063 sec.\n",
      "Iter 22250 || Loss: 3.2785 || 10iter: 1.4752 sec.\n",
      "Iter 22260 || Loss: 3.4240 || 10iter: 1.4455 sec.\n",
      "Iter 22270 || Loss: 3.9574 || 10iter: 1.3919 sec.\n",
      "Iter 22280 || Loss: 3.7533 || 10iter: 1.4476 sec.\n",
      "Iter 22290 || Loss: 2.9340 || 10iter: 1.4636 sec.\n",
      "Iter 22300 || Loss: 4.0345 || 10iter: 1.5108 sec.\n",
      "Iter 22310 || Loss: 3.6136 || 10iter: 1.4346 sec.\n",
      "Iter 22320 || Loss: 2.9136 || 10iter: 1.4196 sec.\n",
      "Iter 22330 || Loss: 3.1857 || 10iter: 1.4862 sec.\n",
      "Iter 22340 || Loss: 3.3161 || 10iter: 1.3942 sec.\n",
      "Iter 22350 || Loss: 2.9479 || 10iter: 1.4547 sec.\n",
      "Iter 22360 || Loss: 3.5217 || 10iter: 1.4827 sec.\n",
      "Iter 22370 || Loss: 3.3934 || 10iter: 1.4536 sec.\n",
      "Iter 22380 || Loss: 3.8940 || 10iter: 1.4251 sec.\n",
      "Iter 22390 || Loss: 3.5746 || 10iter: 1.4615 sec.\n",
      "Iter 22400 || Loss: 3.2917 || 10iter: 1.4098 sec.\n",
      "Iter 22410 || Loss: 3.2106 || 10iter: 1.4223 sec.\n",
      "Iter 22420 || Loss: 3.9574 || 10iter: 1.4329 sec.\n",
      "Iter 22430 || Loss: 4.0107 || 10iter: 1.4268 sec.\n",
      "Iter 22440 || Loss: 3.0534 || 10iter: 1.4484 sec.\n",
      "Iter 22450 || Loss: 3.2086 || 10iter: 1.4503 sec.\n",
      "Iter 22460 || Loss: 3.4251 || 10iter: 1.4301 sec.\n",
      "Iter 22470 || Loss: 3.6432 || 10iter: 1.3768 sec.\n",
      "Iter 22480 || Loss: 2.5479 || 10iter: 1.3805 sec.\n",
      "Iter 22490 || Loss: 3.5548 || 10iter: 1.4326 sec.\n",
      "Iter 22500 || Loss: 3.3204 || 10iter: 1.4665 sec.\n",
      "Iter 22510 || Loss: 2.9018 || 10iter: 1.4557 sec.\n",
      "Iter 22520 || Loss: 3.7033 || 10iter: 1.4496 sec.\n",
      "Iter 22530 || Loss: 3.5674 || 10iter: 1.4691 sec.\n",
      "Iter 22540 || Loss: 3.1249 || 10iter: 1.4314 sec.\n",
      "Iter 22550 || Loss: 3.0864 || 10iter: 1.4587 sec.\n",
      "Iter 22560 || Loss: 3.9081 || 10iter: 1.5268 sec.\n",
      "Iter 22570 || Loss: 3.7568 || 10iter: 1.4822 sec.\n",
      "Iter 22580 || Loss: 2.6738 || 10iter: 1.4367 sec.\n",
      "Iter 22590 || Loss: 3.5105 || 10iter: 1.4373 sec.\n",
      "Iter 22600 || Loss: 3.7451 || 10iter: 1.4405 sec.\n",
      "Iter 22610 || Loss: 3.5944 || 10iter: 1.4495 sec.\n",
      "Iter 22620 || Loss: 3.4800 || 10iter: 1.4404 sec.\n",
      "Iter 22630 || Loss: 3.3766 || 10iter: 1.4065 sec.\n",
      "Iter 22640 || Loss: 3.4535 || 10iter: 1.4156 sec.\n",
      "Iter 22650 || Loss: 3.9043 || 10iter: 1.4483 sec.\n",
      "Iter 22660 || Loss: 3.1182 || 10iter: 1.4176 sec.\n",
      "Iter 22670 || Loss: 3.4096 || 10iter: 1.3788 sec.\n",
      "Iter 22680 || Loss: 3.2274 || 10iter: 1.4480 sec.\n",
      "Iter 22690 || Loss: 2.9663 || 10iter: 1.4379 sec.\n",
      "Iter 22700 || Loss: 3.2942 || 10iter: 1.3738 sec.\n",
      "Iter 22710 || Loss: 3.6883 || 10iter: 1.4314 sec.\n",
      "Iter 22720 || Loss: 3.4583 || 10iter: 1.4510 sec.\n",
      "Iter 22730 || Loss: 3.4819 || 10iter: 1.4472 sec.\n",
      "Iter 22740 || Loss: 3.5349 || 10iter: 1.4623 sec.\n",
      "Iter 22750 || Loss: 3.1995 || 10iter: 1.4711 sec.\n",
      "Iter 22760 || Loss: 3.6334 || 10iter: 1.3656 sec.\n",
      "Iter 22770 || Loss: 2.6911 || 10iter: 1.2628 sec.\n",
      "-------------\n",
      "epoch 33 || Epoch_TRAIN_Loss:2356.0651 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.3126 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 34/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 22780 || Loss: 3.7777 || 10iter: 2.7738 sec.\n",
      "Iter 22790 || Loss: 3.7459 || 10iter: 1.4093 sec.\n",
      "Iter 22800 || Loss: 2.7043 || 10iter: 1.4020 sec.\n",
      "Iter 22810 || Loss: 3.1053 || 10iter: 1.4214 sec.\n",
      "Iter 22820 || Loss: 2.4970 || 10iter: 1.4480 sec.\n",
      "Iter 22830 || Loss: 3.3806 || 10iter: 1.4674 sec.\n",
      "Iter 22840 || Loss: 3.5779 || 10iter: 1.4005 sec.\n",
      "Iter 22850 || Loss: 2.9724 || 10iter: 1.3843 sec.\n",
      "Iter 22860 || Loss: 3.8471 || 10iter: 1.4345 sec.\n",
      "Iter 22870 || Loss: 3.6371 || 10iter: 1.4262 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 22880 || Loss: 3.7956 || 10iter: 1.5252 sec.\n",
      "Iter 22890 || Loss: 3.6096 || 10iter: 1.4504 sec.\n",
      "Iter 22900 || Loss: 2.9143 || 10iter: 1.4856 sec.\n",
      "Iter 22910 || Loss: 3.4555 || 10iter: 1.4295 sec.\n",
      "Iter 22920 || Loss: 2.9262 || 10iter: 1.4382 sec.\n",
      "Iter 22930 || Loss: 3.6756 || 10iter: 1.3857 sec.\n",
      "Iter 22940 || Loss: 3.3816 || 10iter: 1.4370 sec.\n",
      "Iter 22950 || Loss: 3.3522 || 10iter: 1.4360 sec.\n",
      "Iter 22960 || Loss: 3.6501 || 10iter: 1.3920 sec.\n",
      "Iter 22970 || Loss: 3.0724 || 10iter: 1.4833 sec.\n",
      "Iter 22980 || Loss: 3.6974 || 10iter: 1.5151 sec.\n",
      "Iter 22990 || Loss: 3.6840 || 10iter: 1.4808 sec.\n",
      "Iter 23000 || Loss: 3.4196 || 10iter: 1.4138 sec.\n",
      "Iter 23010 || Loss: 3.0384 || 10iter: 1.4526 sec.\n",
      "Iter 23020 || Loss: 3.6917 || 10iter: 1.4462 sec.\n",
      "Iter 23030 || Loss: 3.3259 || 10iter: 1.3772 sec.\n",
      "Iter 23040 || Loss: 3.1784 || 10iter: 1.4259 sec.\n",
      "Iter 23050 || Loss: 2.6568 || 10iter: 1.4727 sec.\n",
      "Iter 23060 || Loss: 3.4303 || 10iter: 1.4556 sec.\n",
      "Iter 23070 || Loss: 3.5965 || 10iter: 1.4907 sec.\n",
      "Iter 23080 || Loss: 3.3113 || 10iter: 1.4863 sec.\n",
      "Iter 23090 || Loss: 3.6815 || 10iter: 1.4749 sec.\n",
      "Iter 23100 || Loss: 3.7057 || 10iter: 1.4624 sec.\n",
      "Iter 23110 || Loss: 3.5867 || 10iter: 1.4074 sec.\n",
      "Iter 23120 || Loss: 3.7216 || 10iter: 1.4145 sec.\n",
      "Iter 23130 || Loss: 3.3729 || 10iter: 1.4486 sec.\n",
      "Iter 23140 || Loss: 3.7789 || 10iter: 1.4032 sec.\n",
      "Iter 23150 || Loss: 2.8873 || 10iter: 1.4119 sec.\n",
      "Iter 23160 || Loss: 3.1644 || 10iter: 1.4093 sec.\n",
      "Iter 23170 || Loss: 3.0644 || 10iter: 1.4250 sec.\n",
      "Iter 23180 || Loss: 3.5482 || 10iter: 1.4272 sec.\n",
      "Iter 23190 || Loss: 3.5381 || 10iter: 1.5033 sec.\n",
      "Iter 23200 || Loss: 3.3654 || 10iter: 1.4394 sec.\n",
      "Iter 23210 || Loss: 3.5717 || 10iter: 1.4712 sec.\n",
      "Iter 23220 || Loss: 3.4847 || 10iter: 1.4347 sec.\n",
      "Iter 23230 || Loss: 3.9281 || 10iter: 1.4633 sec.\n",
      "Iter 23240 || Loss: 3.5579 || 10iter: 1.4338 sec.\n",
      "Iter 23250 || Loss: 3.8349 || 10iter: 1.4335 sec.\n",
      "Iter 23260 || Loss: 3.8587 || 10iter: 1.4125 sec.\n",
      "Iter 23270 || Loss: 3.5418 || 10iter: 1.4279 sec.\n",
      "Iter 23280 || Loss: 3.3525 || 10iter: 1.4593 sec.\n",
      "Iter 23290 || Loss: 3.6515 || 10iter: 1.4298 sec.\n",
      "Iter 23300 || Loss: 3.3191 || 10iter: 1.4340 sec.\n",
      "Iter 23310 || Loss: 3.3075 || 10iter: 1.4339 sec.\n",
      "Iter 23320 || Loss: 3.4109 || 10iter: 1.4529 sec.\n",
      "Iter 23330 || Loss: 3.5661 || 10iter: 1.5257 sec.\n",
      "Iter 23340 || Loss: 3.5994 || 10iter: 1.4558 sec.\n",
      "Iter 23350 || Loss: 3.4996 || 10iter: 1.4124 sec.\n",
      "Iter 23360 || Loss: 3.3460 || 10iter: 1.4672 sec.\n",
      "Iter 23370 || Loss: 3.2860 || 10iter: 1.4058 sec.\n",
      "Iter 23380 || Loss: 3.6381 || 10iter: 1.3982 sec.\n",
      "Iter 23390 || Loss: 3.7408 || 10iter: 1.4634 sec.\n",
      "Iter 23400 || Loss: 3.3224 || 10iter: 1.3989 sec.\n",
      "Iter 23410 || Loss: 3.6810 || 10iter: 1.4326 sec.\n",
      "Iter 23420 || Loss: 3.5483 || 10iter: 1.5283 sec.\n",
      "Iter 23430 || Loss: 3.2152 || 10iter: 1.4124 sec.\n",
      "Iter 23440 || Loss: 3.6108 || 10iter: 1.4349 sec.\n",
      "Iter 23450 || Loss: 3.1926 || 10iter: 1.3488 sec.\n",
      "Iter 23460 || Loss: 2.8509 || 10iter: 1.2619 sec.\n",
      "-------------\n",
      "epoch 34 || Epoch_TRAIN_Loss:2367.6204 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.6586 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 35/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 23470 || Loss: 3.0070 || 10iter: 2.6899 sec.\n",
      "Iter 23480 || Loss: 3.6506 || 10iter: 1.3816 sec.\n",
      "Iter 23490 || Loss: 3.4899 || 10iter: 1.4706 sec.\n",
      "Iter 23500 || Loss: 3.3825 || 10iter: 1.4134 sec.\n",
      "Iter 23510 || Loss: 3.1922 || 10iter: 1.3963 sec.\n",
      "Iter 23520 || Loss: 2.8690 || 10iter: 1.3923 sec.\n",
      "Iter 23530 || Loss: 3.4604 || 10iter: 1.4172 sec.\n",
      "Iter 23540 || Loss: 3.1296 || 10iter: 1.3982 sec.\n",
      "Iter 23550 || Loss: 3.8933 || 10iter: 1.4044 sec.\n",
      "Iter 23560 || Loss: 3.3835 || 10iter: 1.3885 sec.\n",
      "Iter 23570 || Loss: 2.9784 || 10iter: 1.4356 sec.\n",
      "Iter 23580 || Loss: 3.2528 || 10iter: 1.4365 sec.\n",
      "Iter 23590 || Loss: 3.4891 || 10iter: 1.4036 sec.\n",
      "Iter 23600 || Loss: 3.3018 || 10iter: 1.4328 sec.\n",
      "Iter 23610 || Loss: 3.2698 || 10iter: 1.4620 sec.\n",
      "Iter 23620 || Loss: 3.5268 || 10iter: 1.4392 sec.\n",
      "Iter 23630 || Loss: 3.6868 || 10iter: 1.4228 sec.\n",
      "Iter 23640 || Loss: 3.4058 || 10iter: 1.3879 sec.\n",
      "Iter 23650 || Loss: 3.3520 || 10iter: 1.4306 sec.\n",
      "Iter 23660 || Loss: 3.0226 || 10iter: 1.4473 sec.\n",
      "Iter 23670 || Loss: 3.0783 || 10iter: 1.4889 sec.\n",
      "Iter 23680 || Loss: 3.7147 || 10iter: 1.4264 sec.\n",
      "Iter 23690 || Loss: 3.7489 || 10iter: 1.4286 sec.\n",
      "Iter 23700 || Loss: 3.2773 || 10iter: 1.4214 sec.\n",
      "Iter 23710 || Loss: 3.2155 || 10iter: 1.4144 sec.\n",
      "Iter 23720 || Loss: 3.1765 || 10iter: 1.4179 sec.\n",
      "Iter 23730 || Loss: 3.4874 || 10iter: 1.5075 sec.\n",
      "Iter 23740 || Loss: 3.4807 || 10iter: 1.4939 sec.\n",
      "Iter 23750 || Loss: 4.0929 || 10iter: 1.3635 sec.\n",
      "Iter 23760 || Loss: 3.3308 || 10iter: 1.5685 sec.\n",
      "Iter 23770 || Loss: 3.3927 || 10iter: 1.5563 sec.\n",
      "Iter 23780 || Loss: 3.5204 || 10iter: 1.4472 sec.\n",
      "Iter 23790 || Loss: 3.4064 || 10iter: 1.4138 sec.\n",
      "Iter 23800 || Loss: 2.7630 || 10iter: 1.4238 sec.\n",
      "Iter 23810 || Loss: 3.9275 || 10iter: 1.4608 sec.\n",
      "Iter 23820 || Loss: 2.9542 || 10iter: 1.4060 sec.\n",
      "Iter 23830 || Loss: 3.7163 || 10iter: 1.4297 sec.\n",
      "Iter 23840 || Loss: 3.3147 || 10iter: 1.3727 sec.\n",
      "Iter 23850 || Loss: 3.1477 || 10iter: 1.3870 sec.\n",
      "Iter 23860 || Loss: 3.3797 || 10iter: 1.4403 sec.\n",
      "Iter 23870 || Loss: 3.7066 || 10iter: 1.4449 sec.\n",
      "Iter 23880 || Loss: 3.4499 || 10iter: 1.4383 sec.\n",
      "Iter 23890 || Loss: 3.4895 || 10iter: 1.4262 sec.\n",
      "Iter 23900 || Loss: 2.7719 || 10iter: 1.4651 sec.\n",
      "Iter 23910 || Loss: 2.9865 || 10iter: 1.5230 sec.\n",
      "Iter 23920 || Loss: 3.5437 || 10iter: 1.4094 sec.\n",
      "Iter 23930 || Loss: 3.6850 || 10iter: 1.4200 sec.\n",
      "Iter 23940 || Loss: 3.1480 || 10iter: 1.4102 sec.\n",
      "Iter 23950 || Loss: 3.3548 || 10iter: 1.4729 sec.\n",
      "Iter 23960 || Loss: 2.7680 || 10iter: 1.4196 sec.\n",
      "Iter 23970 || Loss: 3.5588 || 10iter: 1.4410 sec.\n",
      "Iter 23980 || Loss: 3.8667 || 10iter: 1.4502 sec.\n",
      "Iter 23990 || Loss: 2.7621 || 10iter: 1.4591 sec.\n",
      "Iter 24000 || Loss: 3.4020 || 10iter: 1.5286 sec.\n",
      "Iter 24010 || Loss: 3.3351 || 10iter: 1.4140 sec.\n",
      "Iter 24020 || Loss: 3.3098 || 10iter: 1.4612 sec.\n",
      "Iter 24030 || Loss: 2.8238 || 10iter: 1.4473 sec.\n",
      "Iter 24040 || Loss: 3.5621 || 10iter: 1.4080 sec.\n",
      "Iter 24050 || Loss: 3.1086 || 10iter: 1.3877 sec.\n",
      "Iter 24060 || Loss: 3.5473 || 10iter: 1.4139 sec.\n",
      "Iter 24070 || Loss: 3.4864 || 10iter: 1.4181 sec.\n",
      "Iter 24080 || Loss: 3.9162 || 10iter: 1.4248 sec.\n",
      "Iter 24090 || Loss: 4.0720 || 10iter: 1.4295 sec.\n",
      "Iter 24100 || Loss: 3.9037 || 10iter: 1.4844 sec.\n",
      "Iter 24110 || Loss: 3.3660 || 10iter: 1.4482 sec.\n",
      "Iter 24120 || Loss: 3.5761 || 10iter: 1.4371 sec.\n",
      "Iter 24130 || Loss: 3.2070 || 10iter: 1.4410 sec.\n",
      "Iter 24140 || Loss: 3.4454 || 10iter: 1.3788 sec.\n",
      "Iter 24150 || Loss: 2.8311 || 10iter: 1.2544 sec.\n",
      "-------------\n",
      "epoch 35 || Epoch_TRAIN_Loss:2347.1107 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.2394 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 36/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 24160 || Loss: 3.5067 || 10iter: 2.8892 sec.\n",
      "Iter 24170 || Loss: 3.7077 || 10iter: 1.3386 sec.\n",
      "Iter 24180 || Loss: 4.2365 || 10iter: 1.4909 sec.\n",
      "Iter 24190 || Loss: 3.3675 || 10iter: 1.4151 sec.\n",
      "Iter 24200 || Loss: 3.5115 || 10iter: 1.4570 sec.\n",
      "Iter 24210 || Loss: 3.0770 || 10iter: 1.4781 sec.\n",
      "Iter 24220 || Loss: 3.0743 || 10iter: 1.4127 sec.\n",
      "Iter 24230 || Loss: 3.5729 || 10iter: 1.4021 sec.\n",
      "Iter 24240 || Loss: 4.1046 || 10iter: 1.4864 sec.\n",
      "Iter 24250 || Loss: 3.1962 || 10iter: 1.4289 sec.\n",
      "Iter 24260 || Loss: 3.0431 || 10iter: 1.4382 sec.\n",
      "Iter 24270 || Loss: 3.3894 || 10iter: 1.4524 sec.\n",
      "Iter 24280 || Loss: 3.0751 || 10iter: 1.3898 sec.\n",
      "Iter 24290 || Loss: 3.3124 || 10iter: 1.4551 sec.\n",
      "Iter 24300 || Loss: 3.7839 || 10iter: 1.4088 sec.\n",
      "Iter 24310 || Loss: 3.1514 || 10iter: 1.4512 sec.\n",
      "Iter 24320 || Loss: 4.0965 || 10iter: 1.4775 sec.\n",
      "Iter 24330 || Loss: 3.5083 || 10iter: 1.4142 sec.\n",
      "Iter 24340 || Loss: 3.6960 || 10iter: 1.4218 sec.\n",
      "Iter 24350 || Loss: 3.0368 || 10iter: 1.4270 sec.\n",
      "Iter 24360 || Loss: 3.3961 || 10iter: 1.4678 sec.\n",
      "Iter 24370 || Loss: 3.5838 || 10iter: 1.5042 sec.\n",
      "Iter 24380 || Loss: 2.8761 || 10iter: 1.4469 sec.\n",
      "Iter 24390 || Loss: 3.4815 || 10iter: 1.3892 sec.\n",
      "Iter 24400 || Loss: 3.8452 || 10iter: 1.4370 sec.\n",
      "Iter 24410 || Loss: 3.6266 || 10iter: 1.3792 sec.\n",
      "Iter 24420 || Loss: 3.0888 || 10iter: 1.4249 sec.\n",
      "Iter 24430 || Loss: 3.3991 || 10iter: 1.4815 sec.\n",
      "Iter 24440 || Loss: 4.0482 || 10iter: 1.4085 sec.\n",
      "Iter 24450 || Loss: 3.0873 || 10iter: 1.4560 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 24460 || Loss: 3.3945 || 10iter: 1.4558 sec.\n",
      "Iter 24470 || Loss: 3.5500 || 10iter: 1.4281 sec.\n",
      "Iter 24480 || Loss: 2.6730 || 10iter: 1.4279 sec.\n",
      "Iter 24490 || Loss: 3.2336 || 10iter: 1.3957 sec.\n",
      "Iter 24500 || Loss: 3.1592 || 10iter: 1.4244 sec.\n",
      "Iter 24510 || Loss: 3.6971 || 10iter: 1.4125 sec.\n",
      "Iter 24520 || Loss: 3.1116 || 10iter: 1.3935 sec.\n",
      "Iter 24530 || Loss: 3.6193 || 10iter: 1.3951 sec.\n",
      "Iter 24540 || Loss: 3.9835 || 10iter: 1.3621 sec.\n",
      "Iter 24550 || Loss: 3.5488 || 10iter: 1.4176 sec.\n",
      "Iter 24560 || Loss: 2.9170 || 10iter: 1.4775 sec.\n",
      "Iter 24570 || Loss: 3.3394 || 10iter: 1.4267 sec.\n",
      "Iter 24580 || Loss: 3.3847 || 10iter: 1.4038 sec.\n",
      "Iter 24590 || Loss: 2.7259 || 10iter: 1.4888 sec.\n",
      "Iter 24600 || Loss: 3.7070 || 10iter: 1.5194 sec.\n",
      "Iter 24610 || Loss: 3.6668 || 10iter: 1.4323 sec.\n",
      "Iter 24620 || Loss: 3.6539 || 10iter: 1.4278 sec.\n",
      "Iter 24630 || Loss: 3.6356 || 10iter: 1.4065 sec.\n",
      "Iter 24640 || Loss: 3.7232 || 10iter: 1.4457 sec.\n",
      "Iter 24650 || Loss: 3.8788 || 10iter: 1.4432 sec.\n",
      "Iter 24660 || Loss: 3.9294 || 10iter: 1.4410 sec.\n",
      "Iter 24670 || Loss: 3.9410 || 10iter: 1.4308 sec.\n",
      "Iter 24680 || Loss: 3.4315 || 10iter: 1.4002 sec.\n",
      "Iter 24690 || Loss: 2.6373 || 10iter: 1.4259 sec.\n",
      "Iter 24700 || Loss: 3.2691 || 10iter: 1.4528 sec.\n",
      "Iter 24710 || Loss: 3.7016 || 10iter: 1.4291 sec.\n",
      "Iter 24720 || Loss: 2.8265 || 10iter: 1.4677 sec.\n",
      "Iter 24730 || Loss: 3.5665 || 10iter: 1.4378 sec.\n",
      "Iter 24740 || Loss: 4.2787 || 10iter: 1.4291 sec.\n",
      "Iter 24750 || Loss: 3.5163 || 10iter: 1.3917 sec.\n",
      "Iter 24760 || Loss: 3.2147 || 10iter: 1.3934 sec.\n",
      "Iter 24770 || Loss: 3.4943 || 10iter: 1.4573 sec.\n",
      "Iter 24780 || Loss: 3.8575 || 10iter: 1.4527 sec.\n",
      "Iter 24790 || Loss: 3.4984 || 10iter: 1.4264 sec.\n",
      "Iter 24800 || Loss: 2.9177 || 10iter: 1.3818 sec.\n",
      "Iter 24810 || Loss: 3.1229 || 10iter: 1.4559 sec.\n",
      "Iter 24820 || Loss: 3.3728 || 10iter: 1.4305 sec.\n",
      "Iter 24830 || Loss: 3.2388 || 10iter: 1.3534 sec.\n",
      "Iter 24840 || Loss: 3.0860 || 10iter: 1.2587 sec.\n",
      "-------------\n",
      "epoch 36 || Epoch_TRAIN_Loss:2337.2574 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.1631 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 37/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 24850 || Loss: 3.3521 || 10iter: 2.6737 sec.\n",
      "Iter 24860 || Loss: 3.3812 || 10iter: 1.4451 sec.\n",
      "Iter 24870 || Loss: 3.0168 || 10iter: 1.3926 sec.\n",
      "Iter 24880 || Loss: 3.2792 || 10iter: 1.4532 sec.\n",
      "Iter 24890 || Loss: 3.7325 || 10iter: 1.3943 sec.\n",
      "Iter 24900 || Loss: 3.1951 || 10iter: 1.4649 sec.\n",
      "Iter 24910 || Loss: 3.6270 || 10iter: 1.4395 sec.\n",
      "Iter 24920 || Loss: 3.3040 || 10iter: 1.4240 sec.\n",
      "Iter 24930 || Loss: 3.3327 || 10iter: 1.4558 sec.\n",
      "Iter 24940 || Loss: 3.3752 || 10iter: 1.4466 sec.\n",
      "Iter 24950 || Loss: 3.8135 || 10iter: 1.4774 sec.\n",
      "Iter 24960 || Loss: 3.5827 || 10iter: 1.4242 sec.\n",
      "Iter 24970 || Loss: 3.3350 || 10iter: 1.4777 sec.\n",
      "Iter 24980 || Loss: 3.1125 || 10iter: 1.5145 sec.\n",
      "Iter 24990 || Loss: 2.8926 || 10iter: 1.4519 sec.\n",
      "Iter 25000 || Loss: 2.7900 || 10iter: 1.4347 sec.\n",
      "Iter 25010 || Loss: 2.5427 || 10iter: 1.4504 sec.\n",
      "Iter 25020 || Loss: 3.4097 || 10iter: 1.4318 sec.\n",
      "Iter 25030 || Loss: 3.3026 || 10iter: 1.4048 sec.\n",
      "Iter 25040 || Loss: 3.8708 || 10iter: 1.4425 sec.\n",
      "Iter 25050 || Loss: 3.3549 || 10iter: 1.4021 sec.\n",
      "Iter 25060 || Loss: 2.6861 || 10iter: 1.4478 sec.\n",
      "Iter 25070 || Loss: 3.1476 || 10iter: 1.4406 sec.\n",
      "Iter 25080 || Loss: 3.2819 || 10iter: 1.4340 sec.\n",
      "Iter 25090 || Loss: 3.3876 || 10iter: 1.4486 sec.\n",
      "Iter 25100 || Loss: 3.0342 || 10iter: 1.4139 sec.\n",
      "Iter 25110 || Loss: 3.2923 || 10iter: 1.4592 sec.\n",
      "Iter 25120 || Loss: 3.5549 || 10iter: 1.4514 sec.\n",
      "Iter 25130 || Loss: 2.9743 || 10iter: 1.4802 sec.\n",
      "Iter 25140 || Loss: 4.0131 || 10iter: 1.4042 sec.\n",
      "Iter 25150 || Loss: 3.8270 || 10iter: 1.4821 sec.\n",
      "Iter 25160 || Loss: 3.2135 || 10iter: 1.4736 sec.\n",
      "Iter 25170 || Loss: 3.7784 || 10iter: 1.4526 sec.\n",
      "Iter 25180 || Loss: 3.5925 || 10iter: 1.3977 sec.\n",
      "Iter 25190 || Loss: 3.3148 || 10iter: 1.4562 sec.\n",
      "Iter 25200 || Loss: 3.3747 || 10iter: 1.4244 sec.\n",
      "Iter 25210 || Loss: 3.1342 || 10iter: 1.4332 sec.\n",
      "Iter 25220 || Loss: 3.2975 || 10iter: 1.4552 sec.\n",
      "Iter 25230 || Loss: 3.3353 || 10iter: 1.4409 sec.\n",
      "Iter 25240 || Loss: 3.5640 || 10iter: 1.4090 sec.\n",
      "Iter 25250 || Loss: 3.4259 || 10iter: 1.4063 sec.\n",
      "Iter 25260 || Loss: 3.3303 || 10iter: 1.4411 sec.\n",
      "Iter 25270 || Loss: 2.7700 || 10iter: 1.4066 sec.\n",
      "Iter 25280 || Loss: 3.5484 || 10iter: 1.3721 sec.\n",
      "Iter 25290 || Loss: 3.7976 || 10iter: 1.4881 sec.\n",
      "Iter 25300 || Loss: 3.6669 || 10iter: 1.4728 sec.\n",
      "Iter 25310 || Loss: 2.9008 || 10iter: 1.5088 sec.\n",
      "Iter 25320 || Loss: 3.8007 || 10iter: 1.4441 sec.\n",
      "Iter 25330 || Loss: 3.4098 || 10iter: 1.4089 sec.\n",
      "Iter 25340 || Loss: 2.8102 || 10iter: 1.4443 sec.\n",
      "Iter 25350 || Loss: 3.2555 || 10iter: 1.4430 sec.\n",
      "Iter 25360 || Loss: 3.3499 || 10iter: 1.4120 sec.\n",
      "Iter 25370 || Loss: 3.1199 || 10iter: 1.4499 sec.\n",
      "Iter 25380 || Loss: 3.4054 || 10iter: 1.4560 sec.\n",
      "Iter 25390 || Loss: 3.3704 || 10iter: 1.4587 sec.\n",
      "Iter 25400 || Loss: 3.3156 || 10iter: 1.4835 sec.\n",
      "Iter 25410 || Loss: 3.8677 || 10iter: 1.4659 sec.\n",
      "Iter 25420 || Loss: 3.1347 || 10iter: 1.4557 sec.\n",
      "Iter 25430 || Loss: 3.2763 || 10iter: 1.3974 sec.\n",
      "Iter 25440 || Loss: 3.1523 || 10iter: 1.4213 sec.\n",
      "Iter 25450 || Loss: 3.0635 || 10iter: 1.4332 sec.\n",
      "Iter 25460 || Loss: 2.8650 || 10iter: 1.4419 sec.\n",
      "Iter 25470 || Loss: 3.5258 || 10iter: 1.4156 sec.\n",
      "Iter 25480 || Loss: 3.0096 || 10iter: 1.3771 sec.\n",
      "Iter 25490 || Loss: 3.8818 || 10iter: 1.4730 sec.\n",
      "Iter 25500 || Loss: 3.3696 || 10iter: 1.4857 sec.\n",
      "Iter 25510 || Loss: 3.1012 || 10iter: 1.4060 sec.\n",
      "Iter 25520 || Loss: 3.1748 || 10iter: 1.3608 sec.\n",
      "Iter 25530 || Loss: 3.3432 || 10iter: 1.2543 sec.\n",
      "-------------\n",
      "epoch 37 || Epoch_TRAIN_Loss:2314.8977 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.5385 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 38/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 25540 || Loss: 3.3952 || 10iter: 2.8404 sec.\n",
      "Iter 25550 || Loss: 2.9168 || 10iter: 1.3991 sec.\n",
      "Iter 25560 || Loss: 3.3917 || 10iter: 1.4370 sec.\n",
      "Iter 25570 || Loss: 2.7564 || 10iter: 1.4065 sec.\n",
      "Iter 25580 || Loss: 3.5256 || 10iter: 1.4454 sec.\n",
      "Iter 25590 || Loss: 3.2167 || 10iter: 1.4006 sec.\n",
      "Iter 25600 || Loss: 3.5038 || 10iter: 1.4411 sec.\n",
      "Iter 25610 || Loss: 2.5666 || 10iter: 1.4121 sec.\n",
      "Iter 25620 || Loss: 3.0118 || 10iter: 1.4142 sec.\n",
      "Iter 25630 || Loss: 2.7519 || 10iter: 1.4768 sec.\n",
      "Iter 25640 || Loss: 3.0943 || 10iter: 1.4852 sec.\n",
      "Iter 25650 || Loss: 3.3928 || 10iter: 1.4134 sec.\n",
      "Iter 25660 || Loss: 3.4024 || 10iter: 1.3777 sec.\n",
      "Iter 25670 || Loss: 3.0326 || 10iter: 1.4031 sec.\n",
      "Iter 25680 || Loss: 2.7544 || 10iter: 1.4566 sec.\n",
      "Iter 25690 || Loss: 3.2198 || 10iter: 1.4740 sec.\n",
      "Iter 25700 || Loss: 3.5726 || 10iter: 1.4709 sec.\n",
      "Iter 25710 || Loss: 3.8596 || 10iter: 1.4200 sec.\n",
      "Iter 25720 || Loss: 2.9442 || 10iter: 1.3923 sec.\n",
      "Iter 25730 || Loss: 3.5410 || 10iter: 1.3975 sec.\n",
      "Iter 25740 || Loss: 3.6115 || 10iter: 1.4346 sec.\n",
      "Iter 25750 || Loss: 3.3637 || 10iter: 1.4962 sec.\n",
      "Iter 25760 || Loss: 3.1802 || 10iter: 1.4481 sec.\n",
      "Iter 25770 || Loss: 3.3490 || 10iter: 1.4367 sec.\n",
      "Iter 25780 || Loss: 2.7114 || 10iter: 1.4038 sec.\n",
      "Iter 25790 || Loss: 3.4063 || 10iter: 1.3723 sec.\n",
      "Iter 25800 || Loss: 3.6343 || 10iter: 1.4376 sec.\n",
      "Iter 25810 || Loss: 3.1430 || 10iter: 1.4523 sec.\n",
      "Iter 25820 || Loss: 3.1585 || 10iter: 1.4354 sec.\n",
      "Iter 25830 || Loss: 3.5857 || 10iter: 1.4013 sec.\n",
      "Iter 25840 || Loss: 3.1862 || 10iter: 1.5130 sec.\n",
      "Iter 25850 || Loss: 3.3806 || 10iter: 1.4079 sec.\n",
      "Iter 25860 || Loss: 3.4310 || 10iter: 1.3983 sec.\n",
      "Iter 25870 || Loss: 3.6505 || 10iter: 1.4730 sec.\n",
      "Iter 25880 || Loss: 3.1733 || 10iter: 1.5081 sec.\n",
      "Iter 25890 || Loss: 3.3299 || 10iter: 1.4416 sec.\n",
      "Iter 25900 || Loss: 3.2634 || 10iter: 1.4266 sec.\n",
      "Iter 25910 || Loss: 3.4489 || 10iter: 1.3620 sec.\n",
      "Iter 25920 || Loss: 3.4436 || 10iter: 1.4161 sec.\n",
      "Iter 25930 || Loss: 3.2673 || 10iter: 1.4169 sec.\n",
      "Iter 25940 || Loss: 3.3842 || 10iter: 1.3889 sec.\n",
      "Iter 25950 || Loss: 3.8112 || 10iter: 1.4694 sec.\n",
      "Iter 25960 || Loss: 3.1081 || 10iter: 1.4110 sec.\n",
      "Iter 25970 || Loss: 2.8530 || 10iter: 1.4152 sec.\n",
      "Iter 25980 || Loss: 3.0326 || 10iter: 1.4607 sec.\n",
      "Iter 25990 || Loss: 3.5099 || 10iter: 1.4376 sec.\n",
      "Iter 26000 || Loss: 4.0787 || 10iter: 1.4319 sec.\n",
      "Iter 26010 || Loss: 3.1103 || 10iter: 1.4178 sec.\n",
      "Iter 26020 || Loss: 3.2941 || 10iter: 1.4701 sec.\n",
      "Iter 26030 || Loss: 3.3169 || 10iter: 1.4389 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 26040 || Loss: 3.5247 || 10iter: 1.4479 sec.\n",
      "Iter 26050 || Loss: 3.4741 || 10iter: 1.4352 sec.\n",
      "Iter 26060 || Loss: 3.3761 || 10iter: 1.4317 sec.\n",
      "Iter 26070 || Loss: 3.2763 || 10iter: 1.4052 sec.\n",
      "Iter 26080 || Loss: 3.7198 || 10iter: 1.4712 sec.\n",
      "Iter 26090 || Loss: 2.8506 || 10iter: 1.4592 sec.\n",
      "Iter 26100 || Loss: 3.4990 || 10iter: 1.4301 sec.\n",
      "Iter 26110 || Loss: 3.5279 || 10iter: 1.4547 sec.\n",
      "Iter 26120 || Loss: 4.6572 || 10iter: 1.3985 sec.\n",
      "Iter 26130 || Loss: 3.5475 || 10iter: 1.4435 sec.\n",
      "Iter 26140 || Loss: 3.3135 || 10iter: 1.4078 sec.\n",
      "Iter 26150 || Loss: 3.2343 || 10iter: 1.4244 sec.\n",
      "Iter 26160 || Loss: 3.1445 || 10iter: 1.4054 sec.\n",
      "Iter 26170 || Loss: 2.5993 || 10iter: 1.4333 sec.\n",
      "Iter 26180 || Loss: 3.6560 || 10iter: 1.4488 sec.\n",
      "Iter 26190 || Loss: 3.1434 || 10iter: 1.4806 sec.\n",
      "Iter 26200 || Loss: 3.2791 || 10iter: 1.5201 sec.\n",
      "Iter 26210 || Loss: 3.6920 || 10iter: 1.3659 sec.\n",
      "Iter 26220 || Loss: 3.2069 || 10iter: 1.2664 sec.\n",
      "-------------\n",
      "epoch 38 || Epoch_TRAIN_Loss:2319.3299 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  102.2820 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 39/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 26230 || Loss: 3.6705 || 10iter: 2.6939 sec.\n",
      "Iter 26240 || Loss: 3.1969 || 10iter: 1.3908 sec.\n",
      "Iter 26250 || Loss: 3.4558 || 10iter: 1.4492 sec.\n",
      "Iter 26260 || Loss: 2.5196 || 10iter: 1.4020 sec.\n",
      "Iter 26270 || Loss: 3.1093 || 10iter: 1.4417 sec.\n",
      "Iter 26280 || Loss: 2.8797 || 10iter: 1.4823 sec.\n",
      "Iter 26290 || Loss: 3.5845 || 10iter: 1.4625 sec.\n",
      "Iter 26300 || Loss: 3.3373 || 10iter: 1.4114 sec.\n",
      "Iter 26310 || Loss: 3.5224 || 10iter: 1.3889 sec.\n",
      "Iter 26320 || Loss: 3.0574 || 10iter: 1.4664 sec.\n",
      "Iter 26330 || Loss: 2.7354 || 10iter: 1.4816 sec.\n",
      "Iter 26340 || Loss: 2.8776 || 10iter: 1.4049 sec.\n",
      "Iter 26350 || Loss: 3.5857 || 10iter: 1.3725 sec.\n",
      "Iter 26360 || Loss: 3.1509 || 10iter: 1.4363 sec.\n",
      "Iter 26370 || Loss: 4.0109 || 10iter: 1.4144 sec.\n",
      "Iter 26380 || Loss: 3.8295 || 10iter: 1.3800 sec.\n",
      "Iter 26390 || Loss: 3.3305 || 10iter: 1.3732 sec.\n",
      "Iter 26400 || Loss: 4.3930 || 10iter: 1.4267 sec.\n",
      "Iter 26410 || Loss: 4.0175 || 10iter: 1.3664 sec.\n",
      "Iter 26420 || Loss: 3.3106 || 10iter: 1.4534 sec.\n",
      "Iter 26430 || Loss: 3.5313 || 10iter: 1.4876 sec.\n",
      "Iter 26440 || Loss: 3.1289 || 10iter: 1.4270 sec.\n",
      "Iter 26450 || Loss: 3.5084 || 10iter: 1.4215 sec.\n",
      "Iter 26460 || Loss: 3.3880 || 10iter: 1.4586 sec.\n",
      "Iter 26470 || Loss: 3.4993 || 10iter: 1.4238 sec.\n",
      "Iter 26480 || Loss: 2.9136 || 10iter: 1.4432 sec.\n",
      "Iter 26490 || Loss: 3.3595 || 10iter: 1.4395 sec.\n",
      "Iter 26500 || Loss: 3.4936 || 10iter: 1.4224 sec.\n",
      "Iter 26510 || Loss: 2.6878 || 10iter: 1.4273 sec.\n",
      "Iter 26520 || Loss: 3.4636 || 10iter: 1.4248 sec.\n",
      "Iter 26530 || Loss: 3.4048 || 10iter: 1.5082 sec.\n",
      "Iter 26540 || Loss: 3.6098 || 10iter: 1.4107 sec.\n",
      "Iter 26550 || Loss: 2.9573 || 10iter: 1.4542 sec.\n",
      "Iter 26560 || Loss: 3.2405 || 10iter: 1.4373 sec.\n",
      "Iter 26570 || Loss: 3.7081 || 10iter: 1.4404 sec.\n",
      "Iter 26580 || Loss: 3.6919 || 10iter: 1.4523 sec.\n",
      "Iter 26590 || Loss: 3.4754 || 10iter: 1.4407 sec.\n",
      "Iter 26600 || Loss: 2.9986 || 10iter: 1.3772 sec.\n",
      "Iter 26610 || Loss: 3.5569 || 10iter: 1.3923 sec.\n",
      "Iter 26620 || Loss: 3.0000 || 10iter: 1.4004 sec.\n",
      "Iter 26630 || Loss: 3.5208 || 10iter: 1.3989 sec.\n",
      "Iter 26640 || Loss: 3.8743 || 10iter: 1.4823 sec.\n",
      "Iter 26650 || Loss: 3.2783 || 10iter: 1.4331 sec.\n",
      "Iter 26660 || Loss: 3.5271 || 10iter: 1.4129 sec.\n",
      "Iter 26670 || Loss: 3.2709 || 10iter: 1.4564 sec.\n",
      "Iter 26680 || Loss: 3.7044 || 10iter: 1.4699 sec.\n",
      "Iter 26690 || Loss: 3.5340 || 10iter: 1.4321 sec.\n",
      "Iter 26700 || Loss: 3.5101 || 10iter: 1.3863 sec.\n",
      "Iter 26710 || Loss: 3.6651 || 10iter: 1.4078 sec.\n",
      "Iter 26720 || Loss: 3.9399 || 10iter: 1.3956 sec.\n",
      "Iter 26730 || Loss: 3.4983 || 10iter: 1.3977 sec.\n",
      "Iter 26740 || Loss: 3.0228 || 10iter: 1.4980 sec.\n",
      "Iter 26750 || Loss: 2.9666 || 10iter: 1.4235 sec.\n",
      "Iter 26760 || Loss: 3.2709 || 10iter: 1.4419 sec.\n",
      "Iter 26770 || Loss: 3.4636 || 10iter: 1.4899 sec.\n",
      "Iter 26780 || Loss: 4.2567 || 10iter: 1.4811 sec.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
